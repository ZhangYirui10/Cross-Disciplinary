# The Metaverse Data Deluge: What Can We Do About It?

# Beng Chin Ooi1 Gang Chen2 Mike Zheng Shou1 Kian-Lee Tan1

# Anthony Tung1 Xiaokui Xiao1 James Wei Luen Yip3 Meihui Zhang4

# 1National University of Singapore 2Zhejiang University

# 3National University Hospital 4Beijing Institute of Technology

# {ooibc, tankl, atung, xiaoxk}@comp.nus.edu.sg cg@zju.edu.cn

# mikeshou@nus.edu.sg james_yip@nuhs.edu.sg meihui_zhang@bit.edu.cn

# Abstract

In the metaverse the physical space and the virtual space co-exist, and interact simultaneously. While the physical space is virtually enhanced with information, the virtual space is continuously refreshed with real-time, real-world information. To allow users to process and manipulate information seamlessly between the real and digital spaces, novel technologies must be developed. These include smart interfaces, new augmented realities, and efficient data storage, management, and dissemination techniques. In this paper, we first discuss some promising co-space applications. These applications offer opportunities that neither of the spaces can realize on its own. We then discuss challenges. Finally, we discuss and envision what are likely to be required from the database and system perspectives.

# Index Terms

metaverse, data centricity, databases

# I. INTRODUCTION

Traditionally, the physical space and the virtual space are disjoint and distinct. Users in each space operate within the scope of the space, i.e., they may communicate among themselves but do not cross the boundary to the other space. However, technological advances in hardware (e.g., GPUs, FPGAs, NVM), Internet of Things (IoT), 5G, AI, ubiquitous computing, smart interfaces, and new augmented realities have made it possible for these two spaces to co-exist within a unified space, namely, the metaverse. In a recent investment report, it is projected that "the metaverse represents a potential $8 trillion to $13 trillion opportunity by 2030, that could boast as many as 5 billion users." Companies such as Meta and Microsoft are already investing a significant amount of resources on the metaverse.

In the metaverse (or cyber-physical system), the physical space and the virtual space interact simultaneously in real-time. Locations and events in the physical world are captured through the use of large numbers of sensors and mobile devices, and could be materialized within a virtual world. Correspondingly, certain actions or events within the virtual domain can affect the physical world (e.g., shopping or product promotion and experiential computer gaming). Thus, on one hand, the physical space is virtually enhanced with information; on the other hand, the virtual space is continuously refreshed with real-time, real-world inputs. Figure 1 shows the information flow within a co-space environment: data flow within a single space, but more importantly, data also flow into the other space. This distinguishes the metaverse from the mixed reality (or augmented reality or augmented virtuality): the mixed reality integrates the real and virtual worlds (e.g., augmenting live video imagery with computer generated graphics), but it is done in a rigid and static manner, without capturing real-time changes and their effects on either of the spaces. By design, the metaverse will also be more interactive and immersive than digital twins and co-space.

Within such a context, it is easy to see that a large amount of data and information must flow within the metaverse and between the real and virtual spaces to ensure that the two worlds are synchronized. This brings new challenges such as a need to process heterogeneous data streams to materialize real-world events in the virtual world, and to disseminate information about interesting events in the virtual space to users in the physical world. In addition, new technologies are needed to enable users to manage information seamlessly between the real and digital spaces. These include smart interfaces, new augmented realities, efficient storage management, and large-scale data dissemination.

In this paper, we present a number of promising data-rich metaverse applications for which we believe that the database community has much to offer to drive the growth of.

the metaverse field. Then, we identify several challenges that we, as data system researchers and engineers, can contribute to managing the large amount of data, the huge number of events, and the massive number of concurrent users within the metaverse. On one hand, there is a need to re-examine conventional research themes such as data fusion, data streaming, data storage and indexing, data processing engines, distributed architectures, and data privacy and security, for the metaverse; on the other hand, we have to embrace new research directions to develop novel technologies that facilitate intelligent decision making, and cope with AR/VR data streaming and learning.

The organization of the paper is as follows. In Section II, we present five data-rich metaverse applications as examples to drive the discussion on the required database supports. In Section III, we describe some key characteristics engendered by metaverse applications. We discuss challenges and opportunities given rise by the metaverse in Section IV. We conclude in Section V.

# II. DATA-RICH METAVERSE USE CASES

The co-existence of the physical and digital spaces offers opportunities for novel applications. In what follows, we shall highlight five of these that are data-rich.

Person wearing smart glass in physical space

Real-time feed of the sensed data to the virtual world

Fig. 2. Military Exercise and Modern War

# Military Mission Exercises

Traditionally, military exercises are carried out in either the physical realm or the virtual domain. In the physical realm, soldiers and military vehicles are mobilized for operations in some physical terrain. In the virtual domain, commanders “sweat out” in air-conditioned rooms in a simulated warfare over 3D virtual world models of the physical entities. While the former is realistic, it is limited by scale (in terms of both the number of personnel and the size of the physical space); the latter, however, handles large-scale warfare at the expense of actual ground happenings. For example, it may take much longer time to cross a river physically than estimated in a model because of ground constraints and the fitness of the soldiers. Moreover, in a model, soldiers can walk through a building destroyed by artillery with ease, whereas in the physical-space exercise, it may take much longer time to bypass the building.

With the metaverse, we can now conduct a more realistic military exercise that takes on a completely new experience and flavor. Consider an exercise that involves both a small scale military exercise (in the physical space) and a virtual model of a large scale military exercise. The physical space essentially forms a small part of the entire military exercise (e.g., a physical exercise over a physical space of 5 km by 5 km compared to a virtual model that simulates a war over 100 km by 100 km space). Now, on the physical ground itself, soldiers and vehicles are equipped with location tracking devices to monitor their movement as well as other information such as fire-power, casualties, etc. Then, at the command center, based on real-time feed of the sensed data, the virtual model can accurately reflect the ground situations. Moreover, actions taken within the virtual world (e.g., simulating reinforcement, enemy counter-attack, etc) will be relayed to the ground troops, which may then be taken into account in the ground decisions. For example, if a region in the ground occupied by troops were air-raided, then the troops should “perish”. Figure 2 illustrates possible scenarios of employing metaverse in military training and modern wars. Unfortunately, with the advancement of satellite systems, unmanned aerial vehicles, supersonic drones and defence technology, modern warfares involving intensive cyber-physical simulation and deployment are likely to be more destructive.

Cake: 3 0

520 Cookie: 52

Buy =2 get 1 free Stock:10

Lucky Draw: Donut Expire at 6.1 25% discount Expire at 5.18

# My own shopping List

Communicate with physical shoppers: Lemon Juice

This looks delicious Cake

Fig. 3. Market Place

# The Marketplace

In today’s marketplace, we either shop in a mall or buy our products online. A physical shop may have a web page (a very primitive form of the virtual model), but there is very limited real-time interaction between the two spaces.

In tomorrow’s metaverse shop, a physical space may be “expanded” to display more items. Figure 3 illustrates a co-space shopping scenario in a metaverse pastry shop. Similarly, in tomorrow’s metaverse marketplace, a physical mall will be “expanded” into a mall (virtually) that houses many more shops than the physical mall. In addition to the virtual correspondence of the physical shops, the virtual mall can rent out virtual space for virtual shop owners. In the physical mall, screens (large displays) can be set up within each physical shop for cyber shoppers to communicate with physical shoppers within the same shop (e.g., through simple text messages and/or more sophisticated immersive technologies). While a physical shopper is restricted to the shops that are physically located in the mall, the online shopper has a wider selection of

shops (and products). The virtual mall needs to be kept up-to-date with real-time information from the physical mall, e.g., live programs that are happening in the physical mall, ongoing lucky draws, updates on the availability of products, etc. The same concept may be used to “expand” the space for exhibits in a museum, or even “expand” a stadium’s sitting capacity for the global audience: sports enthusiasts may view a game through the “eyes” of the player, and concert audiences may have close-up immersive experience.

It would be interesting to see how the multi-billion dollar industry of e-commerce, games, and social networking will grow as advances in technologies to support the metaverse become mature.

“Let’s go to fight the monstertogether; Sure, it's upstairs”

Ben

Alex

Knowledge sharing & Training remote hospitals

Real-time user sensed physical data:

- Movement
- GPS

Fig. 4. Gaming and Social Networking

Gaming, Social Networking and E-commerce

One class of gaming in the metaverse environment is location-based gaming (LBG). LBG is gaining popularity and is believed to be the future of video gaming where a player’s everyday experience (e.g., of moving around the city) is interleaved with the extraordinary experience of a game. These games deliver an experience that changes according to the player’s locations and actions.

In LBG, a user equipped with a GPS-enabled handset (e.g., a mobile phone) can play a video game that combines a player’s real world (i.e., his physical location) with a virtual world on the handset. The physical location becomes part of the game board, and the player’s movement directly influences the gaming progress (and may affect the game character and/or environment). Pokémon GO and Zombies, Run! are examples of LBG.

Another form of metaverse games integrates a physical environment with a corresponding virtual model. Here, RFIDs and sensors are used to capture the information about the players’ current context, which is transmitted to a server. The server (which may be controlled by another player) follows the game rules and relays back to the physical players some information that helps them to proceed (e.g., locations of enemies in the vicinity). Examples of this category of games include Tourality and Wanderer.

Social networking can also be conducted in the metaverse. A person in a certain location in the physical space can detect a friend at the same location in the virtual space, and they may fight together against some enemies in the virtual space. Similarly, two “comrades” who fight together in the virtual space can detect each other when they are near to each other in the physical space, giving opportunity for more social interaction. Users may form interest groups to...

Healthcare has been improving over the years, with the use of AI, sensors, and improved hardware and network bandwidth, etc. With the onslaught of the pandemic, Covid-19, we have seen increasing acceptance of telemedicine, remote consultation, and online collaboration. Telemedicine, or part of the examination process if not totally, has improved the efficiency and comfort of patients. Clinicians are able to monitor and diagnose many chronic cases or minor illnesses or understand the conditions efficiently.

With the metaverse, virtual healthcare could be improved with virtual reality (VR). In fact, holography-guided heart surgery is already used at National University Hospital to enable more precise and speedier incisions. As illustrated in Figure 5, remote assistive surgery can become a real possibility with VR, thereby improving knowledge sharing and training in remote hospitals and clinics. Psychologists and psychiatrists can use VR in aversion therapy to help resolve anxiety issues or overcome delusions. It may be used to replay the situation to overcome the fear or guilt, and treat post-traumatic stress disorder (PTSD). Metaverse enables treatment in private and an environment where interactions can be captured for analysis.

Radiology enables the clinicians to pinpoint the critical spot of the affected organ that requires medical attention or treatment. Its scanning technology, augmented with AI technology, has made great advancements in terms of quality and precision, which has resulted in more accurate diagnosis and better healthcare outcome. As “side effects”, early detection of some diseases such as cataracts may be made possible through image capturing with the headset and AI-enabled analysis of eye images, without bulky and expensive devices and going to the hospital. Metaverse, with more advanced visualization and...

# Smart City

Smart city refers to a technologically modern urban area that makes use of technology for technological-aided living and city planning and management. Sensors, cameras, VR/AR and fast network connectivity are needed to enable such a living condition. In metaverse, interactive platforms support urban environments modeling in 3D and with huge amounts of point cloud and infrastructure data, thereby enabling better city planning for efficiency and comfort. This is somewhat related to the concept of Digital Twin. However, metaverse, to a great extent, has “life” of its own, with data being created and exchanged by human beings in the physical world.

Metaverse not only improves the quality of living, making life a lot more convenient and richer, but also, enables efficient management of various resources which helps reduce carbon footprints based on data-driven decision making in tweaking our infrastructure to account for changes in human behavior. In a smart city, tourists may retrieve information with visualization, and preview the daily events on offer before making decisions. Likewise, people can choose to work from home, and the morning commute may become a thing of the past. In summary, smart healthcare, marketplace, transportation, environmental, social and governance (ESG) implementation, together with advanced infrastructure, form the fabric of a smart city.

# III. OBSERVATIONS FROM DATA-CENTRIC PERSPECTIVES

From the above discussions, we have the following observations of the data-rich metaverse:

- There is a large amount of data/information generated within the metaverse. Some of these are static (e.g., maps, quantity-on-hand), while others are dynamic (e.g., locations, sensor data) and frequently changing. Moreover, the data may come in different formats (e.g., non-structured like video and textual and structured like personal data). These data may also come from multiple different data sources (e.g., static data from a relational database, video data from a video streaming service). In addition, the large amount of data may have to be streamed from one space to another, particularly from the physical to the virtual to ensure real-time tracking of the environment. To a great extent, the data, generated and collected in real time, may break the 3Vs (volume, variety, and velocity) properties of the Big Data.
- There is a large number of sensors that are used to capture the data from the physical environment. In-network processing may be needed to aggregate data before transmission.
- There is a large number of events generated within the metaverse. These have to be monitored, and may trigger further actions/events both in the physical and virtual worlds.

# IV. THE METAVERSE CHALLENGES

Being an integration of the physical and virtual spaces, it is certain that the metaverse brings with it the research issues within each space. In the physical domain, we need to design efficient and effective methods to sense the physical environment (through extensive use of RFIDs or sensing devices), to transform these data into a form that users will appreciate (through data cleansing, data mining, aggregation or interpolation), and to process queries in-network, and so on. While some work have been done (e.g., [32], [46], [60], [78], [77], [43]), we are only scratching the surface to realize practical deployment.

In the virtual space, with the popularity of Massively Multiplayer Online Games, there has been a tremendous amount of interests in recent years to design techniques to support interactive virtual environments for users to communicate with each other in real-time [35], [79], [80], [94]. As pointed out in [80], there are a number of research challenges that need attention, including designing database engines for games workloads and methods to guarantee consistency across multiple virtual views. Techniques for caching and indexing virtual environments (e.g., [70], [71]) need further study to scale to the large number of users.

For the rest of this section, we shall focus on challenges that arise as a result of the integration between the two spaces that may be of interests to the database community. Some non-database related issues, which we have left out, include:

- (a) novel interface technologies that can seamlessly link the physical and cyber spaces to support real-time interaction between users within the two spaces;
- (b) innovative visualization and presentation of output (events and data) within the metaverse on a wide range of devices and platforms (small vs large displays, fixed vs mobile);
- (c) techniques, tools and devices for capturing data from the physical environment (input methods fusing voice and gesture via a head- and hand-piece in place), and for creating content (high-fidelity digitization of humans, scenes and interactions, animation and effects, immersive experience) for the virtual environment;
- (d) language translation, transcription and mediation methods to support social networking and learning, and many others (e.g., security and networking infrastructure).

Camera on smart glass: Info from the Web:

User picks up this book M Related Books:

Augmented Computer Reality Science

Info from RFID reader: Physical Database location:

Alex
04-15-02
An amazing book_
Best book for beginners
XXX
Fig. 6. The Co-space of a Library

data insights. However, data misuse and unlawful data collection have led to precautionary measures being imposed by individual organizations to guide against data leakage and abuse. Privacy-preserving data and knowledge sharing mechanisms with fair contributions of useful data have to be designed. To promote data collaboration and to discourage free-riders from intentionally obtaining the others’ data and parameters without doing their part, effective and computationally efficient incentive models have to be designed. In the metaverse, the users are likely to be heterogeneous in data qualities and quantities, possibly with non-independently and identically distribution (Non-IID), and computational powers. Such heterogeneities complicate the design space of collaboration strategies and mechanisms.

# A. Data Fusion over Heterogeneous Data Sources

Data fusion is generally defined as the use of techniques that combine data from multiple sources through inferences in order to produce data that is potentially more accurate than if they were obtained from a single source [36]. While data fusion has been studied in the context of sensor networks, data fusion in the metaverse is more challenging as the inputs may come from a wide variety of sources including blogs, video/audio clips, and photographs about events that took place in the digital and physical worlds.

As an example, consider the metaverse of a library in Figure 6, information from both video camera and RFID readers will be needed to ensure that the location of books are represented accurately in the digital space. Furthermore, reviews and opinions on the books can also be drawn from both the Web and the social networks of the users to enhance their browsing experience. Such fusion of information on a single entity requires a substantial amount of inference over semantics that are extracted from multiple data sources.

From the above discussion, we note that the metaverse data management is related to the well studied fields of data stream processing [95], sensors network [60] and data integration [54], [53]. However, it also differs in at least two ways. First, unlike the relatively simple aggregation that is being done over data streams and sensors presently, managing data in the metaverse requires more complex logic inferences over these data sources. Second, unlike data integration which aims to derive a common schema for a set of heterogeneous databases, the metaverse data management detects events that had taken place based on these data sources and depicts these events accurately and efficiently in the metaverse.

# B. Data Collaboration

Data collaboration should be more prevailing in the metaverse, as multiple parties may pool data for more meaningful insights. In the metaverse, new kinds of cybercrime and frauds are likely to emerge, and these definitely need to be addressed in the future.

# C. Data Consistency

In networked virtual environments, it is important that users have a consistent view of the virtual world. This requires transmitting data within the virtual world. Unfortunately, there is to-date no solutions that can scale well. Now, in the metaverse, the requirement of consistency becomes even more challenging - the virtual world must also reflect what is happening in the real world. Given the constraints in bandwidth and the large amount of data to be transmitted, we do not expect to see a truly consistent view in both worlds. However, we can try to keep the virtual world as close to the real world as possible. One solution is to tolerate some degree of discrepancies - for numerical data, they may be within certain coherency requirements; for multimedia data, a low resolution image/video may be used instead. Some recent works have looked at how to disseminate streaming data to a large number of clients while preserving data coherency [13], [67], [96].

These techniques assume a small number of distinct objects, and so do not scale to a large number of objects. A closely related approach is to study how data to be transmitted should be prioritized. For example, more critical data can be transmitted first before less critical data. We can learn from methods developed for intermittently-connected and disruptive networks [92]. We believe there is much needed avenue to be explored in this aspect, e.g., to study different scheduling schemes. Besides prioritizing data, it may also be necessary to develop techniques to schedule multiple (continuous) queries that meet different Quality of Service (QoS) metrics. While techniques developed in [69] provided some insights on how this can be effectively handled, we believe this direction deserves further investigation.

# D. Security and Data Privacy

In the metaverse, the increasingly interconnected and complex systems and networks increase our exposure to various threats, such as the loss of data, the loss of control over the software systems and networks, the mistrust due to ill-intended contents and actions, and so on. As a consequence, data security and privacy are major concerns. To enhance data security in the metaverse, there exist various emerging technologies that could enable trusted collaboration.

tions and interactions, through secure communication, transfer and exchange of digital documents and assets, verifiability, and auditability. For example, commercial secure hardware can be used to establish trusted execution environments (TEE) where data and computation cannot be modified by any other parties, including cloud vendors or service providers; then, encryption techniques can be used to protect the data and models in communication channels and on untrusted storage on the cloud. However, despite the promise of a trusted execution environment, current implementations like Intel SGX fall short of security (vulnerable to side channel attacks) and performance (large overhead). As another example, Blockchains can serve as the basis for connectivity in the metaverse to make it open and decentralized. Transactions among different parties in the metaverse can be permanently recorded and verifiable in blockchains, thus fostering a wider acceptance of the metaverse. These new applications require a re-design of data management and processing systems. For instance, decentralization requires the computation to be byzantine faulty tolerance, which introduces a huge cost in replication and consensus modeling. One possible solution is to use verifiable ledger database systems with a trusted third party serving as the auditor. To design an efficient verifiable ledger database, we should consider three factors: abstraction, threat model, and performance. The system may combine efficient cryptographic techniques, often found in authenticated data structures such as the Merkle Tree, and transparency logs, with trusted hardware, and distributed ledgers. Such a system must support distributed transactions and have efficient proof sizes, and be flexible, so that it can be configured to achieve different trade-offs in the design space to fit specific use.

Meanwhile, protecting data privacy in the metaverse requires a delicate balance between minimizing privacy risk and maximizing data utility. On one hand, mitigating privacy risks requires restricting access to sensitive data and conforming to the privacy regulations introduced by the governments. On the other hand, data-centric applications in the metaverse may rely on the availability of various types of data pertinent to users. To address this tension between data privacy and utility, it is important to develop new algorithms and paradigms to enable data analysis in a privacy-preserving manner. Towards this end, there are emerging technologies such as federated learning and differential privacy, but major research effort is still needed to make them applicable for the metaverse applications. In addition, incentivizing users to share information for privacy-preserving analytics is a challenging issue.

# E. Database System Architecture

With a large number of cyber users, and physical users with handheld devices, the metaverse platform naturally forms a highly distributed (peer-to-peer) system. The system is highly complex because of the heterogeneity of the devices. Moreover, there is an enormity of static and dynamic data that flow within each space and across spaces. The database has to ensure better efficiency, flexibility, resiliency, and elasticity than it has today for the metaverse. We now discuss design considerations for metaverse.

# Metaverse

# Device-side Computing

# Cyber Users

|WAN Network|Txn/Query|Resource Pool|
|---|---|---|
|Cloud Computing|Executor|Buffer Pool|
|High-speed Network|Heterogeneous|Data|
|Cloud Storage|Blob Store| |

Fig. 7. Disaggregated Architecture of a Metaverse Database

database architectures by examining the emerging areas such as decentralization, disaggregation, and serverless.

# 1) Decentralized:

The data volume today is far more than a single database instance can handle. Hence, decentralized databases, storing data across a network of distributed servers, possibly owned by autonomous individuals, become increasingly popular due to the movement on Web3. Some application specific metaverse databases, that demand high degree of transparency, are expected to explore peer-to-peer based and decentralized architecture for highly scalable data services. In the metaverse, users are increasingly interconnected, no matter within a region, across countries, or even across continents. We envision that metaverse databases would be worldwide decentralized.

Due to the decentralization, distributed transactions are essential for accessing data across multiple data centers. However, distributed transactions are hard to process at scale to ensure high throughput, high availability and yet low latency due to the network partition and non-negligible inter-data-center network latency. Although existing works [51], [86] on reducing network overhead for inter-data-center transactions can potentially help, horizontal scalability in decentralized metaverse databases remains a challenging issue. This may consequently further spawn new research areas, such as design of high-speed networks, efficient database sharding and high availability, and decentralized transaction protocols.

# 2) Disaggregated:

In recent years, with the evolution of cloud infrastructures, cloud-native databases have become mainstream. The foremost innovation of cloud-native databases is to disaggregate the computation and storage into two distinct components, enabling each to scale independently. Such disaggregation facilitates efficiency and elasticity, which are pivotal for managing metaverse data. Following this trend, metaverse databases can be designed as cloud-native with disaggregation. Besides, we observe that device-side computation is not considered in today’s disaggregation architecture. Unlike traditional users, cyber users enter into and fully immerse themselves in the metaverse world through specific metaverse devices, such as virtual reality goggles. These devices are equipped with increasingly powerful processors to collaborate with cloud metaverse databases, enabling part of the computation to be further separated from the cloud side to the device side. Hence, we envision a new disaggregation architecture, namely device-cloud-storage disaggregation, for tomorrow’s metaverse databases.

Figure 7 illustrates a design of device-cloud-storage architecture for metaverse databases, which consists of the following three components.

# Metaverse devices.

Cyber users access data in the metaverse using metaverse devices. By exploiting the equipped large processors, these devices can afford part of computation tasks like data aggregation and fusion. Some works on processing in portable devices [50], [61] and energy-efficient optimization [10] can be potentially extended for device-side computing.

# Cloud computing.

This layer is responsible for query processing, transaction management, etc. In this layer, the transaction/query executors handle the incoming transactions/queries sent from metaverse devices, and fetch data from the buffer pools. These transaction/query executors and buffer pools can scale elastically based on the workload, by leveraging on-demand resources from the resource pool. With the explosive growth of cloud infrastructures, computing and memory resources are likely to increase further and should be able to efficiently support metaverse databases. To reduce network overhead for transferring the data from the storage layer to the buffer pools, we can cache data in the buffer pool as much as possible, and use high-speed networks such as InfiniBand and remote direct memory access (RDMA) [18].

# Cloud storage.

This layer hosts the data and logs produced from the virtual and physical spaces. To efficiently handle a large amount of diverse types of data, ranging from structured to unstructured and textual to video, this layer contains heterogeneous data stores, including the key-value (KV) store, object store, block store, etc. This layer can be constructed by employing various cloud storage services that ensure scalable, high-performance, and high-available storage. For example, in Microsoft Azure Cloud, it is possible to deploy the KV store on Azure cloud Redis service, while using Azure blob storage and Azure disk storage respectively for the object store and block store.

# 3) Serverless:

Serverless computing [40], [48] has emerged in response to the rise in popularity of cloud architecture. It enables application developers or owners to focus on the application logic and leave the infrastructure-level tasks, such as resource management and auto-scaling, to the cloud vendor. It is therefore an efficient method to scale microservices as well as monolithic applications in the cloud, in line with the principle of workload based resource allocation.

Serverless computing comes with two key requirements: (a) ease of management; and (b) fine-grained pricing model. First, from the clients’ perspective, they only need to upload the execution logic and define the trigger upon which the job is executed, e.g., an HTTP URL [68]. The cloud vendor takes

# G. Query Processing and Optimization

Query processing and optimization in the metaverse will require novel mechanisms. First, new operators may have to be introduced. As an example, sensor data may have to be interpolated (or combined using some user-defined functions) for them to be consumed by the virtual space. In fact, data can be processed and transformed as soon as they are received; alternatively, they can be transformed at runtime. As another example, data in the virtual space may be interpreted in a different way from those in the physical space. These inevitably led to changes to the optimizer to become aware of these operators in order to generate an optimal plan. Earlier work on optimizing queries with expensive predicates may offer a good starting point.

Second, the performance requirements for the two spaces may not be necessarily the same. For example, it is reasonable to prioritize sales for a shopper in a physical mall than for an online shopper (when they both wanted the last available item). As another example, in the case of a cyber user, while real-time information is highly desirable, approximate data may be tolerated (e.g., instead of a high resolution video stream, a low-resolution stream or animation may be acceptable). This calls for query processing or optimization techniques to be “space” aware. Moreover, efficient approximation techniques in the virtual space that do not sacrifice the quality of the output significantly are highly desirable.

Third, besides I/O, CPU and bandwidth considerations, the optimizer may have to be device-aware so that a feasible (and optimal for the device) plan can be generated. Some works on processing in portable devices and energy-efficient optimization can potentially be extended for the metaverse.

Fourth, we are dealing not only with moving objects (some moving in the physical space), we are also dealing with moving queries (a user moving in the virtual environment may need to track all users within his/her views - as he/she moves, his/her views of the space changes). There are very few works on moving queries over moving objects, and this area is certainly worth further exploration.

Fifth, one key challenge in designing a distributed architecture is to ensure that meta-data that are required for optimization can be estimated locally at each site/cluster to minimize information exchange, while at the same time the quality of the generated plan may not be significantly compromised. Designing such a cooperative system is difficult. Techniques from distributed databases may be relevant here.

Finally, the metaverse produces huge amounts of data, in the form of data streams. Stream and in-situ or schema-on-read processing become important. To sustain high stream ingress traffic, data processing operators have to be replicated and run in parallel threads. Stream execution plan optimization and exploitation of appropriate and new hardware are necessary. Parallelism for scalability may be achieved by optimizing the processing on the cores and servers, and efficient remote processing based on remote direct memory access.

# H. Intelligent Decision Making and Self Driving Optimizations

In recent years, we are witnessing a significant amount of effort to integrate database systems and machine learning (ML). On one hand, with ML being more data-centric, there is a need for database support to manage the data efficiently and effectively. On the other hand, incorporating learning into database systems facilitates the design of self-tuning, self-healing, and autonomous DBMS. Given the applications in the metaverse are as complex, if not more, as modern applications, data-centric ML is required for effective predictions and recommendations to support informed decision making. Moreover, to ensure efficient processing, novel ML mechanisms will need to take advantage of the rich data in the metaverse. Regularization, feature interaction, explanation, efficient communication, and many other optimizations can be viewed and addressed from a data-centric perspective [76], [59], [93].

This trend of DBxAI is set to continue for better integration and exploitation of the two technologies [19], [17]. However, to really make the data system scalable and intelligent, we may need to re-examine the needs and requirements for making AI/ML an integral part of the system, instead of putting an AI/ML layer on top of existing systems. In other words, learning from a particular instance of dataset and query patterns may only improve database optimization techniques, such as cost estimation and index design, and their system performance only temporarily. The fact that databases are dynamic in nature may make the AI/ML models and algorithms ineffective due to data and feature drift problems. This is more so in the metaverse, where the users and applications are more diversified and dynamic. From the perspective of AI and machine learning, a recent survey explores the role of AI in the foundation and development of the metaverse [43].

# I. AR/VR Data Streaming and Learning

To build up the metaverse, an integral step is to digitize humans, objects, and scenes from the physical space into the virtual space. Nowadays, many AR/VR applications either only (1) have low-fidelity digital avatars and scenes that we can easily tell they are not real, or (2) still heavily rely on artists to manually create the digital counterparts, which is time-consuming and not feasible for general users to adopt. Recently, a new digital twin technology, i.e. Neural Radiance Fields (NeRF) [62], demonstrates unprecedented high-fidelity in automatically reconstructing human-like avatar [75], realistic objects [56] and large scenes like a city [74] in the metaverse. A metaverse of high-fidelity could provide users immerse experience and unlock some new applications such as watching a basketball game from any viewpoint. Despite being promising, a key challenge towards high-fidelity is data explosion. This is because, in order to look realistic, avatars need to exhibit skin-level details and dynamic objects need to exhibit accurate movements, let alone much larger scenes like cities. In contrast to learning a representation for each avatar or object independently, a promising research direction is to create generalizable representation that can be shared among similar avatars or objects, and develop algorithms to efficiently customise, store, and operate the digital assets given the new representations.

Once the metaverse has been built up, the large amount of data generated in the metaverse offers great opportunities for developing AI models specifically for AR/VR. In particular, different metaverse users may have different tasks that need AI to assist, making it challenging to customize AI model and training data for each use case. A promising solution is to develop foundation deep learning models [14], [15], [77], [16] that are first trained on large-scale data and then can be applied to various downstream tasks with minimal task-specific fine-tuning. As a starting point, the recent work EgoVLP [55] conducted visual-language pretraining on Ego4D [33], a massive egocentric video dataset that targets collecting what smart glasses see throughout human daily activities, and then the pretrained EgoVLP model demonstrates strong performances on various metaverse applications such as action recognition, moment query via a textual description, object state change detection. Due to the large data scale, pretraining often requires considerable compute resources and takes a long time. For example, pretraining in EgoVLP [55] takes two days on 32 A100 GPUs. This is a major roadblock for developing more advanced pretrained models, e.g. continual learning and update of the pretrained model given the newly arrived data stream [82] in the ever-changing metaverse. To overcome this challenge, it is important to optimize data communication between storage and compute nodes, and to exploit parameter-efficient continual learning and transfer learning of large deep learning models.

The conventional workflow of machine learning has limited human-machine interaction. As Figure 8 (a) illustrates, it is mostly unidirectional as only the machine learns from humans on “how to work”. Figure 8 (b) outlines another popular machine learning workflow i.e. self-interactive machine learning, which is used in AlphaGo where an AI agent interacts with itself. A more profound bidirectional interaction may be necessary for both the machines and humans to learn better. We envision a new paradigm of interactive machine learning, namely human-machine co-learning, where humans could learn from the model and the model could learn from humans as shown in Figure 8 (c). For example, in healthcare, clinicians may discover new knowledge or facts from the data through machine learning, and may help the machines to predict more accurately. Interactive learning could be applicable to many applications in the metaverse, in which humans interact with the model in both virtual and physical worlds, convey and discover new knowledge. As a starting point, recent works [81], [52] introduce AI assistants on smart glasses that can instruct novices in using a new device or learning a new skill. Yet, these models still do not form a bidirectional feedback loop between users and learning systems. Such bidirectional

# Self Interaction Learning System

# Learning System Design Insights

|Al Expert|UserISME|
|---|---|
|(a) Conventional Learning|(b) Self Learning|
|(c) Interactive Learning| |

Fig. 8. Learning Workflows

Interactive learning introduces new challenges to be tackled, namely novel interface design, model update, model interpretation and model intervention.

# V. CONCLUSIONS

The advancement in technologies has changed the way we live. In the real world, we can participate in virtual games. In the world of the virtual, we can shop, engage in strategic games that thrill us and receive real-time information and acquire knowledge. The merging of these two spaces will further enhance the user experience. This paper has argued for the co-existence of the two spaces, not as independent entities but as an integrated world where the two spaces interact simultaneously, and users experience an augmented world (either reality or virtuality) seamlessly. We have presented several promising applications of the metaverse, and discussed some research issues that the database community can contribute.

In our discussion, we have focused primarily on the present; with virtual space technology, time no longer “bounds” us - we can, for example, be physically at a historical site experiencing virtually an event that transpired in history on the exact spot that we are standing; likewise, we can have a virtual futuristic view of the current location.

As researchers, we look forward to the exciting challenges in this field, and encourage members of our community to join us. Perhaps, by 2030, we will experience the metaverse as end-users and be brought “back to the future”!

# REFERENCES

[1] Citi GPS: Global Perspectives & Solutions 2022 – METAVERSE AND MONEY: Decrypting the Future. Link

[2] NUHCS: Holography-guided heart surgery for more precise, speedier incisions. Link

[3] Pokémon GO. Link

[4] Tourality. Link

[5] Wanderer. Link

[6] Zombies, Run! Link

[7] D. Abadi, A. Ailamaki, D. G. Andersen, P. Bailis, M. Balazinska, P. A. Bernstein, P. A. Boncz, S. Chaudhuri, A. Cheung, A. Doan, L. Dong, M. J. Franklin, J. Freire, A. Y. Halevy, J. M. Hellerstein, S. Idreos, D. Kossmann, T. Kraska, S. Krishnamurthy, V. Markl, S. Melnik, T. Milo, C. Mohan, T. Neumann, B. C. Ooi, F. Ozcan, J. M. Patel, A. Pavlo, R. A. Popa, R. Ramakrishnan, C. R´ e, M. Stonebraker, and D. Suciu. The seattle report on database research. Commun. ACM, 65(8):72–79, 2022.

[8] D. J. Abadi, Y. Ahmad, M. Balazinska, U. Cetintemel, M. Cherniack, J.-H. Hwang, W. Lindner, A. Maskey, A. Rasin, E. Ryvkina, N. Tatbul, Y. Xing, and S. B. Zdonik. The design of the borealis stream processing engine. In CIDR, pages 277–289, 2005.

[9] D. Agrawal, S. Chawla, B. Contreras-Rojas, A. K. Elmagarmid, Y. Idris, Z. Kaoudi, S. Kruse, J. Lucas, E. Mansour, M. Ouzzani, P. Papotti, J. Quian´ e-Ruiz, N. Tang, S. Thirumuruganathan, and A. Troudi. RHEEM: enabling cross-platform data processing: May the big data be with you! Proc. VLDB Endow., 11(11):1414–1427, 2018.

[10] R. Alonso and S. Ganguly. Query optimization for energy efficiency in mobile environments. In FMLDO, pages 1–17, 1993.

[11] E. Bao, Y. Yang, X. Xiao, and B. Ding. CGM: an enhanced mechanism for streaming data collection with local differential privacy. Proc. VLDB Endow., 14(11):2258–2270, 2021.

[12] B. R. Barricelli, E. Casiraghi, and D. Fogli. A survey on digital twin: Definitions, characteristics, applications, and design implications. IEEE Access, 7:167653–167671, 2019.

[13] M. Bhide, K. Ramamritham, and M. Agrawal. Efficient execution of continuous incoherency bounded queries over multi-source streaming data. In ICDCS, page 11, 2007.

[14] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.

[15] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 2020.

[16] G. Cai, Y. Ge, A. J. Wang, R. Yan, X. Lin, Y. Shan, L. He, X. Qie, J. Wu, and M. Z. Shou. Revitalize region feature for democratizing video-language pre-training. arXiv preprint arXiv:2203.07720, 2022.

[17] Q. Cai, C. Cui, Y. Xiong, W. Wang, Z. Xie, and M. Zhang. A survey on deep reinforcement learning for data processing and analytics. IEEE Transactions on Knowledge and Data Engineering, 2022.

[18] Q. Cai, W. Guo, H. Zhang, D. Agrawal, G. Chen, B. C. Ooi, K. Tan, Y. M. Teo, and S. Wang. Efficient distributed memory management with RDMA and caching. Proc. VLDB Endow., 11(11):1604–1617, 2018.

[19] S. Cai, K. Zheng, G. Chen, H. V. Jagadish, B. C. Ooi, and M. Zhang. Arm-net: Adaptive relation modeling network for structured data. In SIGMOD ’21: International Conference on Management of Data, pages 207–220, 2021.

[20] S. Chandrasekaran, O. Cooper, A. Deshpande, M. J. Franklin, J. M. Hellerstein, W. Hong, S. Krishnamurthy, S. Madden, V. Raman, F. Reiss, and M. A. Shah. Telegraphcq: Continuous dataflow processing for an uncertain world. In CIDR, 2003.

# References

[21] L. Chen, S. Shang, C. S. Jensen, J. Xu, P. Kalnis, B. Yao, and L. Shao. An adaptive rfid Top-k term publish/subscribe for geo-textual data streams. VLDB J., 29(5):1101–1128, 2020.

[22] S. Chen, B. C. Ooi, K. L. Tan, and M. A. Nascimento. St2 b-tree: a self-tunable spatio-temporal b+-tree index for moving objects. In SIGMOD Conference, pages 29–42, 2008.

[23] N. H. Chu, D. T. Hoang, D. N. Nguyen, K. T. Phan, and E. Dutkiewicz. Metaslicing: A novel resource allocation framework for metaverse, 2022.

[24] J. Dean and S. Ghemawat. Mapreduce: simplified data processing on large clusters. Commun. ACM, 51(1):107–113, 2008.

[25] D. J. DeWitt, E. Paulson, E. Robinson, J. F. Naughton, J. Royalty, S., and A. Krioukov. Clustera: an integrated computation and data management system. Proc. VLDB Endow., 1(1):28–41, 2008.

[26] J. Duggan, A. J. Elmore, M. Stonebraker, M. Balazinska, B. Howe, J. Kepner, S. Madden, D. Maier, T. Mattson, and S. B. Zdonik. The bigdawg polystore system. SIGMOD Rec., 44(2):11–16, 2015.

[27] C. Dwork, F. McSherry, K. Nissim, and A. D. Smith. Calibrating noise to sensitivity in private data analysis. In TCC, pages 265–284, 2006.

[28] P. T. Eugster, P. Felber, R. Guerraoui, and A.-M. Kermarrec. The many faces of publish/subscribe. ACM Comput. Surv., 35(2):114–131, 2003.

[29] B. Gedik and L. Liu. Mobieyes: A distributed location monitoring service using moving location queries. IEEE Trans. Mob. Comput., 5(10):1384–1402, 2006.

[30] B. Gedik, K.-L. Wu, P. S. Yu, and L. Liu. Processing moving queries over moving objects using motion-adaptive indexes. IEEE Trans. Knowl. Data Eng., 18(5):651–668, 2006.

[31] D. Glake, F. Kiehn, M. Schmidt, F. Panse, and N. Ritter. Towards polyglot data stores - overview and open research questions. CoRR, abs/2204.05779, 2022.

[32] H. Gonzalez, J. Han, and X. Shen. Cost-conscious cleaning of massive rfid data sets. In ICDE, pages 1268–1272, 2007.

[33] K. Grauman, A. Westbury, E. Byrne, Z. Chavis, A. Furnari, R. Girdhar, J. Hamburger, H. Jiang, M. Liu, X. Liu, et al. Ego4d: Around the world in 3,000 hours of egocentric video. In CVPR, 2022.

[34] A. Gupta, O. D. Sahin, D. Agrawal, and A. Abbadi. Meghdoot: Content-based publish/subscribe over p2p networks. In Middleware, pages 254–273, 2004.

[35] N. Gupta, A. J. Demers, and J. Gehrke. Semmo: a scalable engine for massively multiplayer online games. In SIGMOD Conference, pages 1235–1238, 2008.

[36] D. Hall and S. McMullen. Mathematical Techniques in Multisensor Data Fusion. Artech House, 2004.

[37] J. T. P. D. Hallinan, L. Zhu, K. Yang, A. Makmur, D. A. R. Algazwi, Y. L. Thian, S. Lau, Y. S. Choo, S. E. Eide, Q. V. Yap, Y. H. Chan, J. H. Tan, N. Kumar, B. C. Ooi, H. Yoshioka, and S. T. Quek. Classification of central canal, lateral recess, and neural foraminal stenosis at lumbar spine mr. Radiology, 300(1):130–138, 2021.

[38] B. Haynes, A. Mazumdar, A. Alaghi, M. Balazinska, L. Ceze, and A. Cheung. Lightdb: A DBMS for virtual reality video. Proc. VLDB Endow., 11(10):1192–1205, 2018.

[39] J. M. Hellerstein. Optimization techniques for queries with expensive methods. ACM Trans. Database Syst., 23(2):113–157, 1998.

[40] J. M. Hellerstein, J. Faleiro, J. E. Gonzalez, J. Schleier-Smith, V. Sreekanti, A. Tumanov, and C. Wu. Serverless computing: One step forward, two steps back. In CIDR, 2019.

[41] H. Hu, Y. Liu, G. Li, J. Feng, and K. L. Tan. A location-aware publish/subscribe framework for parameterized spatio-textual subscriptions. In 31st IEEE International Conference on Data Engineering, ICDE 2015, Seoul, South Korea, April 13-17, 2015, pages 711–722. IEEE Computer Society, 2015.

[42] R. Huebsch, B. N. Chun, J. M. Hellerstein, B. T. Loo, P. Maniatis, T. Roscoe, S. Shenker, I. Stoica, and A. R. Yumerefendi. The architecture of pier: an internet-scale query processor. In CIDR, pages 28–43, 2005.

[43] T. Huynh-The, Q. Pham, X. Pham, T. T. Nguyen, Z. Han, and D. Kim. Artificial intelligence for the metaverse: A survey. CoRR, abs/2202.10336, 2022.

[44] J.-H. Hwang, U. Cetintemel, and S. B. Zdonik. Fast and highly-available stream processing over wide area networks. In ICDE, pages 804–813, 2008.

[45] H. V. Jagadish, B. C. Ooi, K. L. Tan, Q. H. Vu, and R. Zhang. Speeding up search in peer-to-peer networks with a multi-way tree structure. In SIGMOD Conference, pages 1–12, 2006.

[46] S. R. Jeffery, M. J. Franklin, and M. N. Garofalakis. A middleware for supporting metaphysical data independence. VLDB J., 17(2):265–289, 2008.

[47] C. S. Jensen, D. Lin, and B. C. Ooi. Query and update efficient b+-tree based indexing of moving objects. In VLDB, pages 768–779, 2004.

[48] E. Jonas, J. Schleier-Smith, V. Sreekanti, C.-C. Tsai, A. Khandelwal, Q. Pu, V. Shankar, J. Carreira, K. Krauth, N. Yadwadkar, J. E. Gonzalez, R. A. Popa, I. Stoica, and D. A. Patterson. Cloud programming simplified: A berkeley view on serverless computing. Technical report, UC Berkeley, 2019.

[49] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. A. Bonawitz, Z. Charles, G. C. Cormode, R. Cummings, R. G. L. D’Oliveira, H. Eichner, S. E. Rouayheb, D. Evans, J. Gardner, Z. Garrett, A. Gascón, B. Ghazi, P. B. Gibbons, M. Gruteser, Z. Harchaoui, C. He, L. He, Z. Huo, B. Hutchinson, J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak, J. Konečný, A. Korolova, F. Koushanfar, S. Koyejo, T. Lepoint, Y. Liu, P. Mittal, M. Mohri, R. Nock, A. Özgeç, R. Pagh, H. Qi, D. Ramage, R. Raskar, M. Raykova, D. Song, W. Song, S. U. Stich, Z. Sun, A. T. Suresh, F. Tramèr, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu, H. Yu, and S. Zhao. Advances and open problems in federated learning. Found. Trends Mach. Learn., 14(1-2):1–210, 2021.

[50] P. Kalnis, N. Mamoulis, S. Bakiras, and X. Li. Ad-hoc distributed spatial joins on mobile devices. In IPDPS, 2006.

[51] T. Kraska, G. Pang, M. J. Franklin, S. Madden, and A. D. Fekete. MDCC: multi-data center consistency. In EuroSys, pages 113–126. ACM, 2013.

[52] S. W. Lei, Y. Wang, D. Mao, D. Gao, and M. Z. Shou. Assistsr: Task-oriented video segment retrieval for personal ai assistant. In Findings of Empirical Methods in Natural Language Processing, 2022.

[53] M. Lenzerini. Data integration: a theoretical perspective, 2002.

[54] A. Levy. Logic-based techniques in data integration. Kluwer International Series In Engineering And Computer Science, pages 575–595, 2000.

[55] K. Q. Lin, A. J. Wang, M. Soldan, M. Wray, R. Yan, E. Z. Xu, D. Gao, R. Tu, W. Zhao, W. Kong, C. Cai, H. Wang, D. Damen, B. Ghanem, W. Liu, and M. Z. Shou. Egocentric video-language pretraining. In Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS), 2022.

[56] J.-W. Liu, Y.-P. Cao, W. Mao, W. Zhang, D. J. Zhang, J. Keppo, Y. Shan, X. Qie, and M. Z. Shou. Devrf: Fast deformable voxel radiance fields for dynamic scenes. In Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS), 2022.

[57] D. Loghin, S. Cai, G. Chen, T. T. A. Dinh, F. Fan, Q. Lin, J. Ng, B. C. Ooi, X. Sun, Q. Ta, W. Wang, X. Xiao, Y. Yang, M. Zhang, and Z. Zhang. The disruptions of 5g on data-driven technologies and applications. IEEE Trans. Knowl. Data Eng., 32(6):1179–1198, 2020.

[58] X. Luo, Y. Wu, X. Xiao, and B. C. Ooi. Feature inference attack on model predictions in vertical federated learning. In 37th IEEE International Conference on Data Engineering, ICDE 2021, Chania, Greece, April 19-22, 2021, pages 181–192, 2021.

[59] Z. Luo, S. Cai, C. Cui, B. C. Ooi, and Y. Yang. Adaptive knowledge driven regularization for deep neural networks. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, pages 8810–8818, 2021.

[60] S. Madden, M. J. Franklin, J. M. Hellerstein, and W. Hong. Tinydb: an acquisitional query processing system for sensor networks. ACM Trans. Database Syst., 30(1):122–173, 2005.

[61] N. Mamoulis, P. Kalnis, S. Bakiras, and X. Li. Optimization of spatial joins on mobile devices. In SSTD, pages 233–251, 2003.

[62] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi, and R. Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. In European conference on computer vision, pages 405–421. Springer, 2020.

[63] B. C. Ooi, K. L. Tan, and A. K. H. Tung. Sense the physical, walkthrough the virtual, manage the co (existing) spaces: a database perspective. SIGMOD Rec., 38(3):5–10, 2009.

[64] R. Pingcheng, T. T. A. Dinh, D. Loghin, M. Zhang, and G. Chen. Blockchains: Decentralized and verifiable data systems. 2022.

[65] W. Rödiger, T. Müllerbauer, A. Kemper, and T. Neumann. High-speed query processing over high-speed networks. Proc. VLDB Endow., 9(4):228–239, 2015.

# References

1. S. Rokhsaritalemi, A. Sadeghi-Niaraki, and S.-M. Choi. A review on mixed reality: Current trends, challenges and prospects. Applied Sciences, 10(2), 2020.
2. M. Zhang, C. Yue, C. Zhu, and Z. Zhong. LergerBench: A framework for benchmarking ledger databases. IEEE Data Engineering Bulletin, 2022.
3. S. Shah, S. Dharmarajan, and K. Ramamritham. An efficient and resilient approach to filtering and disseminating streaming data. In VLDB, pages 57–68, 2003.
4. M. Shahrad, R. Fonseca, I. Goiri, G. Chaudhry, P. Batum, J. Cooke, E. Laureano, C. Tresness, M. Russinovich, and R. Bianchini. Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider. In 2020 USENIX Annual Technical Conference (USENIX ATC 20), pages 205–218. USENIX Association, July 2020.
5. M. A. Sharaf, P. K. Chrysanthis, A. Labrinidis, and K. Pruhs. Algorithms and metrics for processing multiple heterogeneous continuous queries. ACM Trans. Database Syst., 33(1):5:1–5:44, 2008.
6. L. Shou, J. Chionh, Z. Huang, Y. Ruan, and K.-L. Tan. Walking through a very large virtual environment in real-time. In VLDB, pages 401–410, 2001.
7. L. Shou, Z. Huang, and K. L. Tan. The hierarchical degree-of-visibility tree. IEEE Trans. Knowl. Data Eng., 16(11):1357–1369, 2004.
8. M. Stonebraker, P. M. Aoki, W. Litwin, A. Pfeffer, A. Sah, J. Sidell, C. Staelin, and A. Yu. Mariposa: A wide-area distributed database system. VLDB J., 5(1):48–63, 1996.
9. K. Tan, Q. Cai, B. C. Ooi, W. Wong, C. Yao, and H. Zhang. In-memory databases: Challenges and opportunities from software and hardware perspectives. SIGMOD Rec., 44(2):35–40, 2015.
10. M. Tancik, V. Casser, X. Yan, S. Pradhan, B. Mildenhall, P. Srinivasan, J. T. Barron, and H. Kretzschmar. Block-NeRF: Scalable large scene neural view synthesis. arXiv, 2022.
11. S. Tsutsui, W. Mao, S. Lin, Y. Zhu, M. Ma, and M. Z. Shou. Novel view synthesis for high-fidelity headshot scenes. arXiv preprint arXiv:2205.15595, 2022.
12. W. Wang, M. Zhang, G. Chen, H. V. Jagadish, B. C. Ooi, and K. Tan. Database meets deep learning: Challenges and opportunities. SIGMOD Rec., 45(2):17–22, 2016.
13. Y. Wang, Z. Su, N. Zhang, D. Liu, R. Xing, T. H. Luan, and X. Shen. A survey on metaverse: Fundamentals, security, and privacy, 2022.
14. E. Welbourne, M. Balazinska, G. Borriello, and W. Brunette. Challenges for pervasive rfid-based infrastructures. In PerCom Workshops, pages 388–394, 2007.
15. W. M. White, A. J. Demers, C. Koch, J. Gehrke, and R. Rajagopalan. Scaling games to epic proportion. In SIGMOD Conference, pages 31–42, 2007.
16. W. M. White, C. Koch, N. Gupta, J. Gehrke, and A. J. Demers. Database research opportunities in computer games. SIGMOD Record, 36(3):7–13, 2007.
17. B. Wong, J. Chen, Y. Wu, S. W. Lei, D. Mao, D. Gao, and M. Z. Shou. Assistq: Affordance-centric question-driven task completion for egocentric assistant. In European Conference on Computer Vision, 2022.
18. J. Z. Wu, D. J. Zhang, W. Hsu, M. Zhang, and M. Z. Shou. Label-efficient online continual object detection in streaming video. arXiv preprint arXiv:2206.00309, 2022.
19. S. Wu, J. Li, B. C. Ooi, and K. L. Tan. Just-in-time query retrieval over partially indexed data on structured p2p overlays. In SIGMOD Conference, pages 279–290, 2008.
20. Y. Wu, S. Cai, X. Xiao, G. Chen, and B. C. Ooi. Privacy preserving vertical federated learning for tree-based models. Proc. VLDB Endow., 13(11):2090–2103, 2020.
21. Y. Wu, T. T. A. Dinh, G. Hu, M. Zhang, Y. M. Chee, and B. C. Ooi. Serverless data science-are we there yet? a case study of model serving. In ACM SIGMOD International Conference on Management of Data, 2022.
22. X. Yan, L. Yang, H. Zhang, X. C. Lin, B. Wong, K. Salem, and T. Brecht. Carousel: Low-latency transaction processing for globally-distributed data. In SIGMOD Conference, pages 231–243. ACM, 2018.
23. C. Yue, T. T. A. Dinh, Z. Xie, M. Zhang, G. Chen, B. C. Ooi, and X. Xiao. Glassdb: Practical verifiable ledger database through transparency. CoRR, abs/2207.00944, 2022.
24. F. Zhang, C. Zhang, L. Yang, S. Zhang, B. He, W. Lu, and X. Du. Fine-grained multi-query stream processing on integrated architectures. IEEE Trans. Parallel Distributed Syst., 32(9):2303–2320, 2021.
25. H. Zhang, G. Chen, B. C. Ooi, K. Tan, and M. Zhang. In-memory big data management and processing: A survey. IEEE Trans. Knowl. Data Eng., 27(7):1920–1948, 2015.

