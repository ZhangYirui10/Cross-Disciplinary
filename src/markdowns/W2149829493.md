# Multi-Channel Correlation Filters

Hamed Kiani Galoogahi

National University of Singapore

Singapore

hkiani@comp.nus.edu.sg

Terence Sim

National University of Singapore

Singapore

tsim@comp.nus.edu.sg

Simon Lucey

CSIRO

Australia

simon.lucey@csiro.au

# Abstract

Modern descriptors like HOG and SIFT are now commonly used in vision for pattern detection within image and video. From a signal processing perspective, this detection process can be efficiently posed as a correlation/convolution between a multi-channel image and a multi-channel detector/filter which results in a single-channel response map indicating where the pattern (e.g. object) has occurred. In this paper, we propose a novel framework for learning a multi-channel detector/filter efficiently in the frequency domain, both in terms of training time and memory footprint, which we refer to as a multi-channel correlation filter. To demonstrate the effectiveness of our strategy, we evaluate it across a number of visual detection/localization tasks where we: (i) exhibit superior performance to current state of the art correlation filters, and (ii) superior computational and memory efficiencies compared to state of the art spatial detectors.

# 1. Introduction

In computer vision it is now rare for tasks like convolution/correlation to be performed on single channel image signals (e.g. 2D array of intensity values). With the advent of advanced descriptors like HOG and SIFT convolution/correlation across multi-channel signals has become the norm rather than the exception in most visual detection tasks. Most of these image descriptors can be viewed as multi-channel images/signals with multiple measurements (such the oriented edge energies) associated with each pixel location. We shall herein refer to all image descriptors as multi-channel images. An example of multi-channel correlation can be seen in Figure 1 where a multi-channel image is convolved/correlated with a multi-channel filter/detector in order to obtain a single-channel response. The peak of the response (in white) indicating where the pattern of interest is located.

Like single channel signals, correlation between two multi-channel signals is rarely performed naively in the spatial domain. Instead, the fast Fourier transform (FFT) affords the efficient application of correlating a desired template/filter with a signal. Contrastingly, however, most techniques for estimating a detector for such a purpose (i.e. detection/tracking through convolution) are performed in the spatial domain. It is this dilemma that is at the heart of our paper.

This has not always been the case. Correlation filters, developed initially in the seminal work of Hester and Casasent, are a method for learning a template/filter in the frequency domain that rose to some prominence in the 80s and 90s. Although many variants have been proposed, the approach’s central tenet is to learn a filter, that when correlated with a set of training signals, gives a desired response (typically a peak at the origin of the object, with all other regions of the correlation response map being suppressed). Like correlation itself, one of the central advantages of the single channel approach is that it attempts to learn the filter in the frequency domain due to the efficiency of correlation/convolution in that domain. Learning multi-channel filters in the frequency domain, however, comes at the high cost of computation and memory usage. In this paper we present an efficient strategy for learning multi-channel signals/filters that has numerous applications throughout vision and learning.

# Contributions

In this paper we make the following contributions:

- We propose an extension to canonical correlation filter theory that is able to efficiently handle multi-channel signals. Specifically, we show how when posed in the frequency domain the task of multi-channel correlation filter estimation forms a sparse banded linear system. Further, we demonstrate how our system can be solved much more efficiently than spatial domain methods.
- We characterize theoretically and demonstrate empirically how our multi-channel correlation approach affords substantial memory savings when learning on multi-channel signals. Specifically, we demonstrate how our approach does not have a memory cost that is linear in the number of samples, allowing for substantial savings when learning detectors across large amounts of data.
- We apply our approach across a myriad of detection and localization tasks including: eye localization, car detection and pedestrian detection. We demonstrate: (i) superior performance to current state of the art single-channel correlation filters, and (ii) superior computational and memory efficiency in comparison to spatial detectors (e.g. linear SVM) with comparable detection performance.

# Notation

Vectors are always presented in lower-case bold (e.g., a), Matrices are in upper-case bold (e.g., A) and scalars in italicized (e.g. a or A). a(i) refers to the ith element of the vector a. All M-mode array signals shall be expressed in vectorized form a. M-mode arrays are also known as M-mode matrices, multidimensional matrices, or tensors. We shall be assuming M = 2 mode matrix signals (e.g. 2D image arrays) in nearly all our discussions throughout this paper. This does not preclude, however, the application of our approach to other M = 2 signals.

A M-mode convolution operation is represented as the * operator. One can express a M-dimensional discrete circular shift ∆τ to a vectorized M-mode matrix a through the notation a[∆τ]. The matrix I denotes a D × D identity matrix and 1 denotes a D dimensional vector of ones. A applied to any vector denotes the M-mode Discrete Fourier Transform (DFT) of a vectorized M-mode matrix signal a such that A ← F(a) = DFa. Where F() is the Fourier transforms operator and F is the orthonormal D × D matrix of complex basis vectors for mapping to the Fourier domain for any D dimensional vectorized image/signal. We have chosen to employ a Fourier representation in this paper due to its particularly useful ability to represent circular convolutions as a Hadamard product in the Fourier domain. Additionally, we take advantage of the fact that diag(ˆh)ˆa = h◦a, where ◦ represents the Hadamard product, and diag() is an operator that transforms a D dimensional vector into a D × D dimensional diagonal matrix. The role of filter h or signal a can be interchanged with this property. Any transpose operator T on a complex vector or matrix in this paper additionally takes the complex conjugate in a similar fashion to the Hermitian adjoint [12]. The operator conj(ˆ) applies the complex conjugate to the complex vector a.

# 2. Related Work

# Multi-Channel Detectors

The most notable approach to multi-channel detection in computer vision can be found in the seminal work of Dalal & Triggs [5] where the authors employ a HOG descriptor in conjunction with a linear SVM to learn a detector for pedestrian detection. This same multi-channel detection pipeline has gone on to be employed in a myriad of other detection tasks in vision ranging from facial landmark localization/detection [19] to general object detection [7].

Computational and memory efficiency, however, are issues for Dalal & Triggs style multi-channel detectors. A central advantage of using a linear SVM, over kernel SVMs, for learning a multi-channel detector is the ability to treat that detector as a multi-channel linear filter during evaluation. Instead of inefficiently moving the detector spatially across a multi-channel image, one can take advantage of the fast Fourier transform (FFT) for the efficient application of correlating a desired template/filter with a signal. During training, however, all learning is done in the spatial domain. This can be a slow and inefficient process. The strategy involves the extraction of positive (aligned) and negative (misaligned) multi-channel image patches of the object/pattern of interest across large amounts of data. From a learning perspective, much of this storage can be viewed as inefficient as it often involves shifted versions of the same multi-channel image. We argue in this paper, that this is a real strength of correlation filters as the objective provides a way for naturally modeling shifted versions of an image without the burden of explicitly storing all the shifted image patches.

# Multi-Channel Descriptors

Motivation for working with multi-channel image signals (i.e. descriptors) rather than raw single channel pixel intensities stems from seminal work on the mammalian primary visual cortex (V1) [9].

Here, local object appearance and shape can be well categorized by the distribution of local edge directions, without precise knowledge of their spatial location. It has been noted [10] that V1-inspired descriptors obtain superior photometric and geometric invariance in comparison to raw intensities giving strong motivation for their use in many modern vision applications.

Jarrett et al. [10] showed that many V1-inspired features follow a similar pipeline of filtering an image through a large filter bank, followed by a nonlinear rectification.

# 3. Correlation Filters

Due to the efficiency of correlation in the frequency domain, correlation filters have canonically been posed in the frequency domain. There is nothing, however, stopping one (other than computational expense) from expressing a correlation filter in the spatial domain. In fact, we argue that viewing a correlation filter in the spatial domain can give: (i) important links to existing spatial methods for learning templates/detectors, and (ii) crucial insights into fundamental problems in current correlation filter methods.

Bolme et. al’s [3] MOSSE correlation filter can be expressed in the spatial domain as solving the following ridge regression problem,

|E(h) =|1|∑|∑|||yi(j) − hTxi[∆τj]||² + ||h||²|
|---|---|---|---|---|
| |2|i=1|j=1| |

where yi ∈ RD is the desired response for the i-th observation x ∈ RD and λ is a regularization term. C = [∆τ1, . . . , ∆τD] represents the set of all circular shifts for a signal of length D. Bolme et al. advocated the use of a 2D Gaussian of small variance (2-3 pixels) for yi centered at the location of the object (typically the centre of the image).

The solution to this objective becomes,

|h* = H-1 ∑ ∑ yi(j)xi[∆τj]| | |
|---|---|---|
| |N|D|
| |i=1|j=1|

where,

|H = λI + ∑ ∑ xi[∆τj]xi[∆τj]T| | |
|---|---|---|
| |N|D|
| |i=1|j=1|

Solving a correlation filter in the spatial domain quickly becomes intractable as a function of the signal length D, as the cost of solving Equation 2 becomes O(D3 + N D2).

# Efficiency in the Frequency Domain

It is well understood in the signal processing community that circular convolution in the spatial domain can be expressed as a Hadamard product in the frequency domain. This allows one to express the objective in Equation 1 more succinctly and equivalently as,

|E(ˆh) = ||yˆ − xˆ ◦ conj(ˆh)||² + 2||h||²| | | | | |
|---|---|---|---|---|---|
| |N| | | | |
| |1|∑|ˆ|2|λ ||h||²|
| |i=1| | | | |

where ˆh, ˆx, ˆy are the Fourier transforms of h, x, y. The complex conjugate of ˆh is employed to ensure the operation is correlation not convolution. The equivalence between Equations 1 and 4 also borrows heavily upon another well-known property from signal processing namely, Parseval’s theorem which states that

xTx = D-1 ∑i,j ˆxi ˆxj ∀i, j, where x ∈ RD.
The solution to Equation 4 becomes

|ˆh* = [diag(ˆs) + λI] diag(ˆx) ˆy| | | | | |
|---|---|---|---|---|---|
| |N| | | | |
| |i=1| | | | |

where ◦-1 denotes element-wise division, and

|s = ˆx ◦ conj(ˆx) & ˆs = ˆy ◦ conj(ˆy)| | | | | |
|---|---|---|---|---|---|
| |N| | | | |
| |i=1|i=1|i=1| | |

are the average auto-spectral and cross-spectral energies respectively of the training observations. The solution for ˆh in Equations 1 and 4 are identical (other than that one is posed in the spatial domain, and the other is in the frequency domain). The power of this method lies in its computational efficiency. In the frequency domain a solution to ˆh can be

found with a cost of O(N D log D). The primary cost is associated with the DFT on the ensemble of training signals {xi}N and desired responses {yi}N.

Memory Efficiency: Inspecting Equation 7 one can see an additional advantage of correlation filters when posed in the frequency domain. Specifically, memory efficiency. One does not need to store the training examples in memory before learning. As Equation 7 suggests one needs to simply store a summation of the auto-spectral ˆsxx and cross-spectral ˆsxy energies. This is a powerful result not often discussed in correlation filter literature as unlike other spatial strategies for learning detectors (e.g. linear SVM) whose memory usage grows as a function of the number of training examples O(N D), correlation filters have fixed memory overheads O(D) irrespective of the number of training examples.

Fortunately, ˆX is sparse banded and inspecting Equation 10 one can see that the jth element of each correlation response y ˆ∗ is dependent only on the K values of V(ˆh(j)) and V(ˆx(j)), where V is a concatenation operator that returns a K × 1 vector when applied on the jth element of a K-channel vectors {a(k)}K, i.e. V(a(j)) = [conj(a(1)(j)), ..., conj(a(K)(j))]T.

# 4. Our Approach

Inspired by single-channel correlation filters we shall explore a multi-channel strategy for learning a correlation filter. We can express the multi-channel objective in the spatial domain as:

E(h) = 1/2 ∑i=1 N ∑j=1 D ||yi(j) − ∑k=1 K h(k)T x(k)[∆τj]||2 + λ/2 ∑k=1 K ||h(k)||2 (8)

where x(k) and h(k) refers to the kth channel of the vectorized image and filter respectively where K represents the number of filters. As with a canonical filter the desired response is single channel y = [y(1), . . . , y(D)]T even though both the filter and the signal are multi-channel. Solving this multi-channel form in the spatial domain is even more intractable than the single channel form with a cost of O(D K3 + N D K2) since we now have to solve a KD × KD linear system.

Fourier Efficiency: Inspired by the efficiencies of posing single channel correlation filters in the Fourier domain we can express Equation 8 equivalently and more succinctly:

E(ˆh) = 1/2 ||y ˆ − diag(ˆxk) h||2 + λ/2 ∑k=1 K ||hk||2 (9)

where ˆh = [h1, . . . , hK] is a KD dimensional supervector of the Fourier transforms of each channel. This can be simplified further.

compute the auto-spectral ˆ s and cross-spectral ˆ xx sxy energies respectively of the training observations (see Equation 7). The memory saving become sizable as the number of training examples increase as the memory overhead remains constant O(D) instead of O(N D) if one was to employ a spatial objective. A similar strategy can be taken advantage of in our multi-channel correlation form. For multi-channel correlation filters this saving becomes even more dramatic as the memory overhead remains constant O(K2D) as opposed to O(N DK). This property stems from the sparse banded structure of multi-channel correlation filters such that the problem can be posed as D independent K × K linear systems.

# 5. Experiments

We evaluated our method across a number of challenging localization and detection tasks: facial landmark localization, car detection, and pedestrian detection. For all our experiments we used the same parametric form for the desired correlation response, which we defined as a 2D Gaussian function with a spatial variance of two pixels whose the peak is centered at the location of the target of interest (facial landmarks, cars, pedestrians, etc.). Across all our experiments we used the same multi-channel image representation, specifically HOG [5]. All correlation filters, both single-channel and multi-channel, employed in this paper used a 2D cosine window (as suggested by Bolme et al. [3]) to reduce boundary effects.

# 5.1. Facial Landmark Localization

We evaluated our method for facial landmark localization on the Labeled Faces in the Wild (LFW) database1, including 13,233 face images stemming from 5749 subjects. The images were captured in the wild with challenging variations in illumination, pose, quality, age, gender, race, expression, occlusion and makeup. For each image, there are ground truth annotations for 10 facial landmarks as well as the bounding box of the face. We used the bounding box to crop a 128×128 face image enclosing all the landmarks. We then employed a 10-fold cross validation procedure to compute evaluation results across folds. 10% of images were approximately used for testing, with the remaining 90% being used for learning/training the detectors. The folds were constructed carefully to have no subjects in common.

All the cropped images were first pre-processed using Gamma correction and Difference of Gaussian (DoG) filtering to compensate for the large variations in illumination. Multi-channel HOG descriptors were computed using 9 orientation bins normalized by cell and block sizes of 6×6 and 3×3, respectively. Localization occurred by correlating each landmark detector across the cropped face image where the peak response location was used as the predicted landmark location. The facial landmark localization was evaluated using normalized distance between the desired location and the predicted coordinate of the landmarks:

‖pi − mi‖2

d = ‖ml − mr‖2

where mr and ml respectively indicate the ground truth of the right and left eye, and mi and pi are respectively the true and predicted locations of the landmark of interest. A localization with d < τ was considered successful where τ is a threshold defined as a fraction of the inter-ocular distance (the denominator of the above equation).

Results and Analysis: Inspecting Figure 2 one can see the superiority of our multi-channel approach compared to state of the art single-channel correlation filter methods MOSSE and ASEF. Further, we compare our performance to leading non-correlation filter methods: specifically Everingham et al. [6] and Valstar et al. [18] which also show the superiority of our approach. Some visual examples of the output from our approach employed for facial landmark localization can be seen in Figure 3. It should be noted that this approach to landmark localization employs no shape prior, relying instead solely on the landmark detectors making a fair comparison with more recent methods in facial landmark localization such as Zhu and Ramanan [19] difficult.

# 5.2. Car Detection

The objective of this experiment is to evaluate our proposed multi-channel correlation filter (MCCF) strategy for car localization in street scene images. We selected 1000 images from the MIT StreetScene2 database, each image contains one car taken from an approximate left-half-frontal view. All the selected images were first cropped to a size of 360×360, and then power normalized to have zero-mean and unit norm. Our MCCF was trained and evaluated in the same manner to the previous experiment using 100 × 180 car patches cropped from training images (excluding street scenes). The peak of the Gaussian desired responses was located at the center of the car patches. We selected the peak of the correlation output as the predicted location of a car in street scene of the testing images. Figure 5.2 depicts our localization performance in comparison to leading single-channel correlation filters MOSSE and ASEF where we obtain superior performance across all thresholds. Visual examples of our car detection results can be seen in Figure 5.

# 5.3. Pedestrian Detection

We evaluated our method for pedestrian detection using Daimler pedestrian dataset [14] containing five disjoint images.

1 http://vis-www.cs.umass.edu/lfw

2 http://cbcl.mit.edu/software-datasets/

# Figure 2. The performance of facial features localization: localization rate versus threshold (best viewed in color).

| |Our method|Human|
|---|---|---|
|Localization rate|0.4|0.4|
|0.2|MOSSE|0.2|
| |ASEF| |
| |Everingham et al.| |

Threshold (fraction of interocular distance)

(a)

(b)

# Figure 3. Visualizing facial features localization, first and second rows show successful localizations, and the third row show wrong localizations.

# Figure 4. Car detection rate as a function of threshold (pixels).

Detection rate

| | | |Our method|MOSSE| |
|---|---|---|---|---|---|
| |0.4| | | | |
| |0.2| | | | |
|0|10|20|30|40|50|

In this experiment we chose to compare our MCCF directly with a spatial detector learned using a linear SVM (as originally performed by Dalal and Triggs [5]). The linear SVM was trained in almost exactly the same fashion as our MCCF so as to keep the comparison as fair as possible. Inspecting Figure 6 (a) one can see our MCCF obtains similar detection results to linear SVM in terms of detection performance as a function of different false positive rates. This result is not that surprising as the linear SVM objective is quite similar to the MCCF objective (which can be interpreted as a ridge regression when posed in the spatial domain). It is well understood that the linear SVM objective enjoys better tolerance to outliers than ridge regression, but in practice we have found that advantage to be only marginal when learning multi-channel detectors.

Peak-to-Sidelobe Ratio (PSR) is a common metric used in correlation filter literature for detection/verification tasks. It is the ratio of the peak response to the local surrounding response, more details on this measure can be found in [12].

# Figure 5. Car detection results.

The first and second rows: true detections, and the third row: wrong detections. The red, blue and green boxes represent detection by our method, MOSSE and ASEF, respectively.

| |250|500|1000|2000|4000|8000|16000|24000|
|---|---|---|---|---|---|---|---|---|
|MCCF|0.02|0.02|0.02|0.02|0.02|0.02|0.02|0.02|
|SVM|6.17|12.35|24.68|49.36|98.87|197.44|395.88|592.32|

Table 1. Comparing minimum required memory (MB) of our method with SVM as a function of number of training images.

Inspecting Figure 6 (b) one can see detection performance as a function of number of training data. It is interesting to note that our MCCF objective can achieve good detection performance with substantially smaller amounts of training data when compared to linear SVM. This superior performance can be attributed to how correlation filters implicitly use synthetic circular shifted versions of images within the learning process without having to explicitly create the images. As a result our MCCF objective can do “more with less” by achieving good detection performance with substantially less training data.

# Computation and Memory Efficiency:

Figure 6(c) depicts one of the major advantages of MCCF, and that is its superior scalability with respect to training set size. One can see how training time starts to increase dramatically for linear SVM4 whereas our training time only increases modestly as a function of training set size. The central advantage of our proposed approach here is that the solving of the multi-channel linear system in the frequency domain is independent to the number of images. Therefore the only component of MCCF that is dependent on training set size.

We employed the efficient and widely used LibLinear linear SVM package http://www.csie.ntu.edu.tw/˜cjlin/liblinear in all our experiments.

# 6. Conclusion

In this paper, we propose a novel extension to correlation filter theory which allows for the employment of multi-channel signals with the efficient use of memory and computations. We demonstrate the advantages of our new approach across a variety of detection and localization tasks.

Figure 6. Comparing our method with SVM + HOG (a) ROC curve of detection rate as a function of false positive rate (8000 training images), (b) pedestrian detection rate at FPR = 0.10 versus number of training images, and (c) training time versus the number of training images.

Figure 7. Some samples of (top) true detection of pedestrian (true positive), (middle) false detection of non-pedestrian (false negative), and (bottom) false detection of pedestrian (false positive).

# References

1. [1] B. Babenko, M. H. Yang, and S. Belongie. Visual tracking with online multiple instance learning. In CVPR, 2009.
2. [2] V. N. Boddeti, T. Kanade, and B. V. K. V. Kumar. Correlation filters for object alignment. In CVPR, 2013.
3. [3] D. S. Bolme, J. R. Beveridge, B. A. Draper, and Y. M. Lui. Visual object tracking using adaptive correlation filters. In CVPR, 2010.
4. [4] D. S. Bolme, B. A. Draper, and J. R. Beveridge. Average of synthetic exact filters. In CVPR, 2009.
5. [5] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR, 2005.
6. [6] M. Everingham, J. Sivic, and A. Zisserman. “hello! my name is... buffy”–automatic naming of characters in tv video. In BMVC, 2003.
7. [7] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part-based models. PAMI, 32(9):1627–1645, 2010.
8. [8] C. F. Hester and D. Casasent. Multivariant technique for multiclass pattern recognition. Appl. Opt., 19(11):1758–1761, 1980.
9. [9] D. Hubel and T. Wiesel. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. The Journal of Physiology, 160(1):106, 1962.
10. [10] K. Jarrett, K. Kavukcuoglu, M. A. Ranzato, and Y. LeCun. What is the best multi-stage architecture for object recognition? ICCV, pages 2146–2153, 2009.
11. [11] B. V. K. V. Kumar. Minimum-variance synthetic discriminant functions. J. Opt. Soc. Am. A, 3(10):1579–1584, 1986.
12. [12] B. V. K. V. Kumar, A. Mahalanobis, and R. D. Juday. Correlation Pattern Recognition. Cambridge University Press, 2005.
13. [13] D. Lowe. Object recognition from local scale-invariant features. ICCV, pages 1150–1157, 1999.
14. [14] S. Munder and D. M. Gavrila. An experimental study on pedestrian classification. PAMI, 28(11):1863–1868, 2006.
15. [15] P. Refregier. Optimal trade-off filters for noise robustness, sharpness of the correlation peak, and horner efficiency. Optics Letters, 16:829–832, 1991.
16. [16] D. Ross, J. Lim, R. Lin, and M. Yang. Incremental learning for robust visual tracking. IJCV, 77(1):125–141, 2008.
17. [17] M. Savvides and B. V. K. V. Kumar. Efficient design of advanced correlation filters for robust distortion-tolerant face recognition. In AVSS, pages 45–52, 2003.
18. [18] M. Valstar, B. Martinez, X. Binefa, and M. Pantic. Facial point detection using boosted regression and graph models. In CVPR, 2010.
19. [19] X. Zhu and D. Ramanan. Face detection, pose estimation, and landmark localization in the wild. In CVPR, 2012.

