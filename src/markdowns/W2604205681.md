# Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)

# Coupled Multi-Layer Attentions for Co-Extraction of Aspect and Opinion Terms

# Wenya Wang,†‡ Sinno Jialin Pan,† Daniel Dahlmeier,‡ Xiaokui Xiao†

# †Nanyang Technological University, Singapore

# ‡SAP Innovation Center Singapore

# †{wa0001ya, sinnopan, xkxiao}@ntu.edu.sg, ‡{d.dahlmeier}@sap.com

# Abstract

The task of aspect and opinion terms co-extraction aims to explicitly extract aspect terms describing features of an entity and opinion terms expressing emotions from user-generated texts. To achieve this task, one effective approach is to exploit relations between aspect terms and opinion terms by parsing syntactic structure for each sentence. However, this approach requires expensive effort for parsing and highly depends on the quality of the parsing results. In this paper, we offer a novel deep learning model, named coupled multi-layer attentions. The proposed model provides an end-to-end solution and does not require any parsers or other linguistic resources for preprocessing. Specifically, the proposed model is a multi-layer attention network, where each layer consists of a couple of attentions with tensor operators. One attention is for extracting aspect terms, while the other is for extracting opinion terms. They are learned interactively to dually propagate information between aspect terms and opinion terms. Through multiple layers, the model can further exploit indirect relations between terms for more precise information extraction. Experimental results on three benchmark datasets in SemEval Challenge 2014 and 2015 show that our model achieves state-of-the-art performances compared with several baselines.

# Introduction

Aspect and opinion terms co-extraction, which aims at identifying aspect terms and opinion terms from texts, is an important task in fine-grained sentiment analysis (Pang and Lee 2008). An aspect term refers to a word or a phrase (a sequence of words) describing an attribute or feature of an entity, e.g., a product. An opinion term refers to the expression carrying subjective emotions. For example, in the review “This little place has a cute interior decor and affordable prices”, interior decor and prices are aspects, with cute and affordable as their corresponding opinions. In the literature, there exist many lines of work for aspect and/or opinion terms extraction which can be categorized as rule-based, feature-engineering-based, or deep-learning-based approaches. For rule-based approaches (Hu and Liu 2004a; 2004b; Qiu et al. 2011), the idea is to manually design some rules based on syntactic or dependency structure of each sentence to expand the extracted information.

In summary, our contributions are two-fold: 1) We propose an end-to-end deep learning model for aspect and opinion terms co-extraction without requiring any syntactic/dependency parsers or linguistic resources to generate additional information as input. 2) We conduct extensive experiments on three benchmark datasets to verify that our model achieves state-of-the-art performance for aspect and opinion terms co-extraction.

Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.

# Related Work

For extracting aspect/opinion terms from texts, Hu and Liu (2004a) proposed to use association rule mining for extracting aspect terms and synonyms/antonyms from WordNet for identifying opinion terms. Qiu et al. (2011) used a dependency parser to augment a seed collection of aspect and opinion terms through double-propagation, similar for (Popescu and Etzioni 2005; Wu et al. 2009). The above methods are unsupervised, but depend on pre-defined rules and linguistic resources. For supervised methods, the task is treated as a sequence labeling problem. Li et al. (2010) and Jin and Ho (2009) implemented CRF and HMM with extensive human-designed features to solve the problem, respectively. Liu et al. (2012; 2013) applied a word alignment model in order to capture relations among opinion words, which requires large amount of training data to obtain desired relations. Topic models were also applied for aspect extraction (Chen, Mukherjee, and Liu 2014; Zhao et al. 2010). Recently, deep learning methods have been proposed for this task. Liu et al. (2015) applied recurrent neural network on top of pre-trained word embeddings for aspect extraction. Yin et al. (2016) proposed an unsupervised embedding method to encode dependency path into a recurrent neural network to learn high-level features for words, which are taken as input features for CRFs for aspect extraction. Wang et al. (2016) proposed a joint model of recursive neural networks and CRFs for aspect and opinion terms co-extraction. The neural network is constructed from the dependency parse tree to capture dual-propagation among aspect and opinion terms. Note that most existing deep models require a syntactic/dependency parser and auxiliary linguistic features to boost their extraction accuracy. As a comparison, our proposed model does not need any linguistic features, or any pre-constructed syntactic structure as input.

# Attention & Memory Network

Attentions (Mnih et al. 2014) and memory networks (Weston, Chopra, and Bordes 2015) have recently been used for various machine learning tasks, including image generation (Gregor et al. 2015), machine translation (Bahdanau, Cho, and Bengio 2014), sentence summarization (Rush, Chopra, and Weston 2015), document sentiment classification (Yang et al. 2016), and question answering (Hermann et al. 2015). The attention mechanism aims to select and attend to relevant parts of the input which could be thought of as a soft-alignment process. A memory network generally consists of multiple layers of attentions, which has shown superior performance in many NLP tasks (Kumar et al. 2016; Sukhbaatar et al. 2015). In this paper, we aim to develop a multi-layer attention network to replace the role of a syntactic/dependency parser to capture the relations among words in a sentence for information extraction.

# Coupled Multi-layer Attentions

Our proposed model is named Coupled Multi-layer Attentions (CMLA) which consists of the following features:

- For each sentence, we construct a pair of attentions, one for aspect terms extraction, and the other for opinion terms extraction. Each attention aims to learn a prototype vector for aspect or opinion, a high-level feature vector for each token, and an attention score for each token in the sentence. The feature vector and attention score measure the extent of correlation between each input token and the prototype using a tensor operator, which captures different contexts of a given token when measuring its correlation.

Fish burger is the best dish; tastes fresh as multiple bilinear terms that could model more complicated compositions between 2 units. As shown in the bottom of Figure 2(a), Ga could be decomposed into K slices, where each slice Ga ∈ Rd×d is a bilinear term that interacts with 2 vectors and captures one type of composition, e.g., a specific syntactic relation. Hence h⊤Gaua ∈ RK inherits K different kinds of compositions between hi and ua that indicates complicated correlations between each input token and the aspect prototype. By adding a non-linear transformation tanh(·), βa encodes more abstract and high-level correlation features. Then ra is obtained from βi via a GRU network:

ra = (1 − za) ⊙ rai−1 + za ⊙ ∼ai,

where ga = σ(Warai + Uaβa), za = σ(Warai−1 + Uaβa), and ra = tanh(Wg(g ⊙ rai−1) + Ugβa). Here, g and z are reset and update gates respectively that control the information flow from the previous timestamp. Wa, Ua, Wg, and Ug are weight matrices to be learned for transforming rai−1 and βa to gate units. By applying GRU on βa, the attention vector ri ∈ RK becomes context-dependent with the ability to inherit past information. For example, as shown in Figure 2(a), if Fish has high correlations with aspect prototype, its next token burger also has high chance of being active, because ra inherits information from ra1. Indeed, many aspect terms consist of multiple tokens, and exploiting context information helps their predictions. For simplicity, we use ra = GRU(fa(hi, ua), θa) to denote (2), where θa = {Wa, Uai, Wg, Ua, Wz, Ua}.

An attention score ea for token wi is then computed as ea = va⊤rai. Since rai is a correlation feature vector, va ∈ RK can be deemed as a weight vector that weighs each feature accordingly. Hence, ea becomes a scalar score, where a higher score indicates higher correlation with the prototype, and higher chance of being attended. For example, as shown in Figure 2(a), ua helps the model to attend to Fish and burger which indicates their high chance of being aspect terms. Note that the output attention vector ra is also used as the final feature representation for wai. Thus, a prediction on each token can be generated by li = softmax(Carai), where Ca ∈ Rc×K is a classification matrix for converting final feature vectors to labels, and c is the number of classes.

The procedure for opinion attention is similar. In the subsequent sections, we use a superscript p to denote the opinion attention. In the final prediction, each token only belongs to 1 of the 5 classes in L mentioned previously. After la and lp are obtained for each token, we pick the largest value from each vector. If both of them correspond to O, then the final prediction is O. If only one of them is O, we pick the other one as final prediction. When neither of them are O, the two values are compared and the largest one is chosen.

# Coupled Attentions for Dual Propagation

As discussed in previous sections, a crucial issue for co-extraction of aspect and opinion terms is how to fully exploit the relations between aspect terms and opinion terms.

# Multi-Layer Coupled Attentions

Aspect attention  Opinion attention

| |0.3|0.4|0.1|0.2|0.9|0.1| | | | | | |
|---|---|---|---|---|---|---|---|---|---|---|---|---|
|et+1|Layer t+1|t+l|# + l|h1|h2|ha|ha|hs|hs|hz|he|hg|
|hs|h4|hs|Fis|hiz|Fts| | | | | | | |
| |0.3|0.5| |0.2| | | | | | | | |
| |Layer t|uP| |uP| | | | | | | | |
| |h1|h2|ha|h4|hs|hs|nz|he|hg|88.3|0.3| |
| |Fish|burger|is|the|best dish|tastes fresh|hz|h6|hg| | | |

(a) A single-layer attention model with tensor. (b) Multi-layer Coupled attentions. (c) Attention prototype.

Figure 2: Illustration of the proposed model.

such that the information can be propagated to each other to assist final predictions. However, independent learning of the aspect or opinion attention fails to utilize their relations. Therefore, we propose to couple the learning of the two attentions such that information of each attention can be dually propagated to the other. Specifically, as shown in Figure 2(b), solid lines and dashed lines denote aspect attention and opinion attention, respectively. The two attentions share the same feature vector h for each input token w.

Different from a single attention, the prototype to be fed into each attention module becomes a pair of vectors {ua, up}, and the tensor operator in (1) becomes a pair of tensors {Gm, Dm}: fm(h, ua, up) = tanh([h⊤Gmum: h⊤Dmum]), where [:] denotes concatenation of vectors, and m∈ {a, p} is the index of the two attentions, m = a if m = p, and m = p if m = a. The new tensor Dm ∈ RK×d×d is used to model the correlations of hi with the prototype u from the conjugate attention, which captures the dual-propagation between aspect terms and opinion terms.

For example, if h for tastes is already attended through the aspect attention and incorporated in ua, it will help to attend fresh for opinion attention focusing attention on tastes, which in turn assists strong correlation between h in the next layer, because of the term tastes and h8. In this case, the aspect is extracted indirectly through two layers of the coupled attentions. This shows that the multi-layer attention network is able to progressively attend the aspect or opinion words that are non-obvious and have indirect relations.

Similar to the single-layer coupled attention model, the proposed network first accumulates high-level representations rm in (5) for each token i at each layer t to generate the prediction vectors l = softmax(C r), and then outputs a final prediction for each token.

# Experiments

# Datasets & Experimental Setup

We evaluate and compare our proposed model on three benchmark datasets, as described in Table 1. They are taken from SemEval Challenge 2014 task 4 subtask 1 (Pontiki et al. 2014) and SemEval Challenge 2015 task 12 subtask 1 (Pontiki et al. 2015). Note that the original datasets in the challenges only contain labels for aspect terms.

# Dataset Description

|Dataset|Description|Training|Test|Total|
|---|---|---|---|---|
|S1|SemEval-14 Restaurant|3,041|800|3,841|
|S2|SemEval-14 Laptop|3,045|800|3,845|
|S3|SemEval-15 Restaurant|1,315|685|2,000|

Table 1: Dataset description with number of sentences

For S2, we use the labels on opinion terms provided by (Wang et al. 2016), and manually label all the opinion terms for S3. The pre-trained word embeddings are obtained using the word2vec tool on two different corpora, as the three datasets belong to two domains: restaurant and laptop. Following the setup in (Wang et al. 2016), for restaurant domain, we apply word2vec on Yelp Challenge dataset consisting of 2.2M restaurant reviews with 54K vocabulary size. For laptop domain, we use the corpus from electronic domain in Amazon reviews (McAuley et al. 2015), which contains 1M reviews with 590K vocabulary size. The dimensions of word embeddings are 200 for restaurant domain and 150 for laptop domain in our experiments.

For the input feature vectors to the attention network, we convert the pre-trained word embeddings to hidden representations through GRU implemented with the Theano library. The size of the hidden units for each layer is 50 for all three datasets. We use a 2-layer attention network for experiments. For each layer, the first dimension K of tensors is set to be 20 for S1 and S3 (15 for S2). We use a fixed learning rate for all experiments: 0.07 for S1, S3, and 0.1 for S2. To avoid overfitting, the network is regularized with dropout. We follow the idea of (Zaremba, Sutskever, and Vinyals 2014) which shows that partial dropout (only apply dropout to non-recurrent parameters) is better than applying dropout to all parameters for RNN. The dropout rate is set to be 0.5 for non-recurrent parameters of GRU. Note that all the above parameters are chosen through cross-validation.

# Experimental Results

We compare CMLA with the following baseline models:

- DLIREC, IHS RD, EliXa: the top performing systems for S1, S2 in SemEval Challenge 2014, and S3 in SemEval Challenge 2015, respectively.
- LSTM: an LSTM network built on top of word embeddings proposed by (Liu, Joty, and Meng 2015). The settings are the same as (Wang et al. 2016).
- WDEmb: the model proposed by (Yin et al. 2016) using word and dependency path embeddings combined with linear context embedding features, dependency context embedding features as CRF input.
- RNCRF: the joint model with CRF and recursive neural network proposed by (Wang et al. 2016), which has been shown to outperform CRFs with hand-crafted features.

Table 2: Comparison results in terms of F1 scores. AS (OS) refers to aspect (opinion) terms extraction.

|Model|AS S1 OP|AS S2 OP|AS S3 OP|
|---|---|---|---|
|DLIREC|84.01|-|73.78|
|IHS RD|79.62|-|74.55|
|EliXa|-|-|70.04|
|LSTM|81.15|80.22|72.73|
|WDEmb|84.31|-|74.68|
|WDEmb*|84.97|-|75.16|
|RNCRF|84.05|80.93|76.83|
|RNCRF*|84.93|84.11|78.42|
|CMLA|85.29|83.18|77.80|

WDEmb*, RNCRF*: the corresponding models with additional human-engineered linguistic features.

The comparison results in terms of F1 scores are shown in Table 2. We report results for both aspect terms extraction (AS) and opinion terms extraction (OP) for all the three datasets. To make fair comparisons, we use the same corpus as in LSTM, RNCRF, RNCRF* for training word embeddings, and same training set with both aspect and opinion labels. Among deep-learning-based models, the models that combine neural network with CRF (i.e., WDEmb and RNCRF) perform better than LSTM because of the incorporation of dependency structure. It is clear that CMLA achieves the state-of-the-art results for most of the time without any pre-extracted linguistic/syntactic information. Specifically, CMLA outperforms WDEmb by 0.98%, 3.12% and 1.61%, and RNCRF by 1.24%, 0.97% and 3.67% for aspect extraction on S1, S2 and S3, respectively. Even compared with the deep models with additional hand-crafted features, i.e., WDEmb* and RNCRF*, CMLA still gets 0.32%, 2.64% and 1.00% improvement over WDEmb* for aspect extraction on S1, S2 and S3, and 0.36% and 2.99% increase over RNCRF* for aspect extraction on S1 and S3, respectively. Moreover, the improvements over RNCRF and RNCRF* are all significant (p <0.01), except for the aspects extraction on S1 and S2 over RNCRF*. Note that besides linguistic features, WDEmb* and RNCRF* also require dependency parsers to perform the task. Therefore, CMLA is more effective and simpler to implement.

To show the effect of the number of layers, we present experimental results varying the number of layers in Table 4. The best results are obtained with 2 layers. With only one layer, the results for aspect extraction are 0.39%, 0.52% and 1.46% inferior than the best scores on S1, S2 and S3, respectively, but they are still comparable with other baselines shown in Table 2. Similar observations can be found for the results with 3 layers. This shows that CMLA with 2 layers is enough to exploit most of the relations among input tokens.

We also conducted experiments to explicitly show the advantage of coupling the learning of aspect and opinion attentions. The second part in Table 4 specifies different setups of the model. ASL refers to the multi-layer network with only aspect attention and is trained with aspect labels only. We can see that even without opinion labels, the network still proves comparable and even superior than deep models.

the bread is top notch as well while there’s a decent menu, it shouldn’t take ten minutes to get your drinks and 30 for a dessert pizza

best spicy tuna roll, great asian salad. I highly recommend it for not just its superb cuisine, but also for its friendly owners and staff

# Figure 3: Visualization of attention weights for different tokens within a sequence.

# Prediction with CMLA

also stunning “colors” and speedy

# Prediction with RNCRF

also stunning colors and speedy

Only 2 “usb ports” ... seems kind of limited

strong “build” though which really adds to its “durability”

Save room for “deserts” - they’re to die for

You must try “Odessa stew” or “Rabbit stew”; “salads” - all good

# Table 3: Prediction comparison between CMLA and RNCRF

| | | |S1| |S2|S3| | | |
|---|---|---|---|---|---|---|---|---|---|
|AS|OP|AS|OP|AS|OP| | | | |
| |Layer|1|84.90| |81.85|77.28|78.12|69.27|69.56|
| | |2|85.29| |83.18|77.80|80.17|70.73|73.68|
| | |3|84.41| |82.38|77.24|79.29|69.78|71.95|
| | |ASL|84.38|-|76.45|-|69.53|-| |
| |Setup|ASL+OPL|84.14|-|82.10|77.05|79.66|69.49|72.73|
| | |CMLA|85.29| |83.18|77.80|80.17|70.73|73.68|

without linguistic features for aspect terms extraction shown in Table 2. This shows that multi-layer attentions with ten- sors is advantageous for exploiting interactions. ASL+OPL in Table 4 trains the aspect attention and opinion attention independently using (1) where each attention predicts one of the three labels. The results of ASL+OPL in terms of aspect extraction are similar to ASL, which shows that the additional opinion labels have little effect on aspect extraction if they are not interactively trained. By coupling the aspect and opinion attentions, CMLA achieves the best performance.

As a core component, an attention computes a score for each token to indicate its correlation with the corresponding prototype. We visualize the actual attention scores for the tokens of 4 sentences in Figure 3. The y-axis represents the scores before normalization which can be positive or negative, but only the magnitude matters. Higher scores mean larger correlations with the aspect/opinion prototype. As the aspect and opinion attention have different sets of parameters, the scores can correspond to different ranges of the values. Tokens in purple (blue) are the ground-truth aspect (opinion) terms. Obviously, purple tokens correspond to large scores for aspect extraction (purple bars with large values), and blue tokens correspond to large scores for opinion extraction (blue bars with large values). All the other non-relevant terms have lower scores. This shows that our model is able to extract terms of interest.

As mentioned previously, CMLA is able to extract target terms without any dependency parser, and hence does not depend on the quality of the parsing results. To show that, we pick a few example reviews from the test datasets as presented in Table 3. The left and right column show the prediction results from the proposed model and RNCRF (Wang et al. 2016), respectively, where predicted opinions are made italic, and aspects are “quoted”. Obviously, the listed reviews are not formal enough to be parsed correctly. Hence, RNCRF fails to extract some of the targets, unlike CMLA which identifies all possible target terms.

To show the robustness of CMLA, we provide two sensitivity studies on word embedding dimensions and the number of different interactions within a 3-dimensional tensor on S1 in Figure 4. From the plot, we can see that the performances for both aspect and opinion terms extraction are relatively stable when varying word embedding dimensions, with the highest scores achieved at 200. For the number of tensor interactions, the model attains the best performance at 20 for aspect extraction and 10 for opinion extraction.

# Conclusion

We present a novel end-to-end network with coupled multi-layer attentions, CMLA, for aspect-opinion co-extraction, which does not require any parsers or linguistic resources. Different from traditional attention network, we propose coupled attentions to exploit the correlations among input tokens, especially between aspect and opinion terms, through tensor operators. Moreover, the multi-layer structure helps to extract non-obvious targets with indirect relations. Experimental results on 3 benchmark datasets verify the effectiveness of CMLA.

# Acknowledgements

This research is partially funded by the Economic Development Board and the National Research Foundation of Singapore. Sinno J. Pan thanks the support from the NTU Singapore Nanyang Assistant Professorship (NAP) grant M4081532.020.

# References

Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. In CoRR abs/1409.0473.

Chen, Z.; Mukherjee, A.; and Liu, B. 2014. Aspect extraction with automated prior knowledge learning. In ACL, 347–358.

Cho, K.; van Merrienboer, B.; Gulcehre, C.; Bahdanau, D.; Bougares, F.; Schwenk, H.; and Bengio, Y. 2014. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In EMNLP, 1724–1734.

Gregor, K.; Danihelka, I.; Graves, A.; Rezende, D. J.; and Wierstra, D. 2015. DRAW: A recurrent neural network for image generation. In ICML, 1462–1471.

Hermann, K. M.; Kočiský, T.; Grefenstette, E.; Espeholt, L.; Kay, W.; Suleyman, M.; and Blunsom, P. 2015. Teaching machines to read and comprehend. In NIPS.

Hu, M., and Liu, B. 2004a. Mining and summarizing customer reviews. In KDD, 168–177.

Hu, M., and Liu, B. 2004b. Mining opinion features in customer reviews. In AAAI, 755–760.

Jin, W., and Ho, H. H. 2009. A novel lexicalized hmm-based learning framework for web opinion mining. In ICML, 465–472.

Kumar, A.; Irsoy, O.; Ondruska, P.; Iyyer, M.; James Bradbury, I. G.; Zhong, V.; Paulus, R.; and Socher, R. 2016. Ask me anything: Dynamic memory networks for natural language processing. In ICML.

Li, F.; Han, C.; Huang, M.; Zhu, X.; Xia, Y.-J.; Zhang, S.; and Yu, H. 2010. Structure-aware review mining and summarization. In COLING, 653–661.

Liu, K.; Xu, L.; Liu, Y.; and Zhao, J. 2013. Opinion target extraction using partially-supervised word alignment model. In IJCAI, 2134–2140.

Liu, P.; Joty, S.; and Meng, H. 2015. Fine-grained opinion mining with recurrent neural networks and word embeddings. In EMNLP, 1433–1443.

Liu, K.; Xu, L.; and Zhao, J. 2012. Opinion target extraction using word-based translation model. In EMNLP-CoNLL, 1346–1356.

McAuley, J.; Targett, C.; Shi, Q.; and van den Hengel, A. 2015. Image-based recommendations on styles and substitutes. In SIGIR, 43–52.

Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J. 2013. Distributed representations of words and phrases and their compositionality. In NIPS, 3111–3119.

Mnih, V.; Heess, N.; Graves, A.; and Kavukcuoglu, K. 2014. Recurrent models of visual attention. In NIPS. 2204–2212.

Pang, B., and Lee, L. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval 2(1-2).

Pontiki, M.; Galanis, D.; Pavlopoulos, J.; Papageorgiou, H.; Androutsopoulos, I.; and Manandhar, S. 2014. Semeval-2014 task 4: Aspect based sentiment analysis. In SemEval, 27–35.

Pontiki, M.; Galanis, D.; Papageorgiou, H.; Manandhar, S.; and Androutsopoulos, I. 2015. Semeval-2015 task 12: Aspect based sentiment analysis. In SemEval, 486–495.

Popescu, A.-M., and Etzioni, O. 2005. Extracting product features and opinions from reviews. In EMNLP, 339–346.

Qiu, G.; Liu, B.; Bu, J.; and Chen, C. 2011. Opinion word expansion and target extraction through double propagation. Comput. Linguist. 37(1):9–27.

Rush, A. M.; Chopra, S.; and Weston, J. 2015. A neural attention model for abstractive sentence summarization. In EMNLP, 379–389.

Socher, R.; Perelygin, A.; Wu, J.; Chuang, J.; Manning, C. D.; Ng, A. Y.; and Potts, C. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP, 1631–1642.

Sukhbaatar, S.; Szlam, A.; Weston, J.; and Fergus, R. 2015. End-to-end memory networks. In NIPS, 2440–2448.

Wang, W.; Pan, S. J.; Dahlmeier, D.; and Xiao, X. 2016. Recursive neural conditional random fields for aspect-based sentiment analysis. In EMNLP.

Weston, J.; Chopra, S.; and Bordes, A. 2015. Memory networks. In ICLR.

Wu, Y.; Zhang, Q.; Huang, X.; and Wu, L. 2009. Phrase dependency parsing for opinion mining. In EMNLP, 1533–1541.

Yang, Z.; Yang, D.; Dyer, C.; He, X.; Smola, A.; and Hovy, E. 2016. Hierarchical attention networks for document classification. In NAACL, 1480–1489.

Yin, Y.; Wei, F.; Dong, L.; Xu, K.; Zhang, M.; and Zhou, M. 2016. Unsupervised word and dependency path embeddings for aspect term extraction. In IJCAI.

Zaremba, W.; Sutskever, I.; and Vinyals, O. 2014. Recurrent neural network regularization. CoRR abs/1409.2329.

Zhao, W. X.; Jiang, J.; Yan, H.; and Li, X. 2010. Jointly modeling aspects and opinions with a maxent-lda hybrid. In EMNLP, 56–65.

