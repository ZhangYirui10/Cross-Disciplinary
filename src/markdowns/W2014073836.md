# New advances in aircraft MRO services: data mining enhancement

# Conference or Workshop Item

# Accepted Version

Yu, J., Gulliver, S. ORCID: https://orcid.org/0000-0002-4503-5448, Tang, Y. ORCID: https://orcid.org/0000-0002-1134-4170 and Ke, L. (2011) New advances in aircraft MRO services: data mining enhancement. In: Fourth International Workshop on Advanced Computational Intelligence (IWACI2011), 19-21 October 2011, Wuhan, China. Available at https://centaur.reading.ac.uk/24806/

It is advisable to refer to the publisher’s version if you intend to cite from the work. See Guidance on citing.

Published version at: https://doi.org/10.1109/IWACI.2011.6160002

All outputs in CentAUR are protected by Intellectual Property Rights law, including copyright law. Copyright and IPR is retained by the creators or other copyright holders. Terms and conditions for use of this material are defined in the End User Agreement.

www.reading.ac.uk/centaur

CentAUR

# Central Archive at the University of Reading

Reading’s research outputs online

# New Advances in Aircraft MRO Services: Data Mining Enhancement

# J. Yu, S. Gulliver, Y. Tang and L. Ke

Abstract — Aircraft Maintenance, Repair and Overhaul (MRO) agencies rely largely on row-data based quotation systems to select the best suppliers for the customers (airlines). The data quantity and quality becomes a key issue to determining the success of an MRO job, since we need to ensure we achieve cost and quality benchmarks. This paper introduces a data mining approach to create an MRO quotation system that enhances the data quantity and data quality, and enables significantly more precise MRO job quotations.

Regular Expression was utilized to analyse descriptive textual feedback (i.e. engineer’s reports) in order to extract more referable highly normalised data for job quotation. A text mining based key influencer analysis function enables the user to proactively select sub-parts, defects and possible solutions to make queries more accurate. Implementation results show that system data would improve cost quotation in 40% of MRO jobs, would reduce service cost without causing a drop in service quality.

The key issue during this MRO process is the creation of accurate and appropriate quotes. Incorrect quotation significantly impacts the chance of either a quote being granted (i.e. because the quote is too high), or may lead to a reduction in customer trust (i.e. the quote is too low and the bill is therefore perceived to be too high). How can MRO agencies ensure that the ‘cheapest’ price is quoted, as all jobs are uniquely different? Moreover, how can we promise that the ‘best’ supplier is recommended? These issues depend on the historical MRO database containing enough relevant information to answer these questions. Traditionally MRO quotes were based solely on normalized feedback data. Normalized feedback, however, is unable to provide information about the many more descriptive factors; that are important when comparing complex engineering jobs. An engine repair cost may vary from a few hundred USD to more than several hundred thousand USD depending on the sub-parts involved or warranty status. An average price therefore will clearly be very inaccurate. Capture of more precise historical data is clearly important to ensure the best possible quotation for customers. This paper offers a text mining solution to improve capture of both data quality and quantity within the maintenance and service domain.

# I. INTRODUCTION

Maintenance, Repair and Overhaul in the airline industry involves the fixing of out of order or broken mechanical or electrical devices. MRO activity also includes routine scheduled maintenance to minimize the risk of a future fault. A standard MRO process involves: the customer (i.e. an airline) delegating an MRO job to an MRO agency. The agency references a MRO database of completed jobs and quotes two critical pieces of information. Firstly the MRO agency provides information about the ‘cheapest’ price. Secondly the MRO agency provides information about the ‘best’ supplier to fulfil that MRO job. The customer then chooses and grants a quote. Once a quote is granted, the part is sent, checked, repaired, and returned to the MRO agency. The customer is billed for the work and payment is cleared.

# II. A CONCEPTUAL FRAMEWORK

# A. Text Mining

Textual data mining relates to the process of extracting high-quality information from large quantities of textual content. The purpose of Text Mining is to automate the processing of unstructured (textual) information, so that meaningful semantic value can be obtained, i.e. by defining structural patterns within the text, normalized forms of information can be derived. This normalized semantically rich data can be used by common data mining (statistical and machine learning) algorithms to support the identification of clusters, associations and sequences in MRO activity.

In its most basic form, text mining allows words in the text to be catalogued in a dictionary and counted. This allows us to determine a matrix of how many...

Manuscript received July 1, 2011. This work was supported in parts by the Informatics Research Centre and the Knowledge Transfer Centre from University of Reading (UK).

J. Yu is with University of Reading, United Kingdom. His current role is KTP (Knowledge Transfer Partnership) associate, interest includes Business Intelligence, Data Mining and .Net programming (e-mail: yujunuk@gmail.com).

S. Gulliver is a senior lecturer from the University of Reading. His areas of interest include: multimedia perception, usability, pervasive and mobile devices, personalisation, attentive displays, virtual environments, Eye‐tracking and data analysis. (e-mail: s.r.gulliver@henley.reading.ac.uk).

Y. Tang is the deputy director of the Informatics Research Centre, University of Reading, his expertise and research interests include bioinformatics; corporate strategy planning; project management; benchmarking; performance measurement and large scale databases. (e-mail: y.tang@reading.ac.uk).

L. Ke is a head of a professional IT development team. He has more than 15 years’ experience working on the development of improving aircraft MRO service using IT technologies. (e-mail: lisheng_ke@yahoo.co.uk).

ti imes each wor rd has been us sed throughou ut the textual via a normalized fe edback and on nly acts to add d confusion description. This basic proc cess can be extended to to the text m ining process. By remov ing such exclude commo on stop words, for example, non-subject inf ormation, we are trying to limit the in clusion of words that flow w of readable s entences, yet h ave limited irre everent infor mation from m entering t he MRO value to con tent analysi is, e.g. "bec ause" and dic ctionary; which would theref ore subsequen tly require "therefore". Functioned F lists of stop words are mo re regular da ta audit and c leaning proce esses to be publically avail lable to help st op words with out meaning un dertaken. Figure 1 shows th e removal of f irrelevant entering the da tabase. In ad dition stem ch ecking and inf ormation. synonym com mparison can be included to restrict multiple words s being added to the dictiona ry with the Irrelevant same meaning, e.g. ‘jump, jumped and j 'replace, swap jumping’ or Information 3 p and exchang ge’. Inclusion of multiple very similar m eaning words dilutes the im mportance of meaning across words, o often causing g important meaning to be l ost during data a mining proce sses. Common te xtual data m ining techniqu es include: Re levant Inform textual categori mation [3], tex tual clustering g [4], subject / object extraction and sentim ent analysis [1 1]. Text data mining is use d commonly y in online m edia form processing, es pecially in the domain of CRM (Customer Rel lationship Man nagement) [6]. Sentiment Fig. 1. An example d emonstrating the r emoval of extran textual analysi neous textual is used to capture user satisfaction, con tent. often taken as a feedback after media viewing or Secondly, rem maining descrip in ptive text was split at the nterface testin ng [7]. To the best of our kn owledge no sen tence level in order to rem ove additional l irrelevant one has previou sly considered d textual data m ining when tex t. English sen tences comm only start with a h a capital analysing MRO O feedback text t. letter or a punctu ation mark, a and end with a a full-stop. By y identifying sentences, and B. Regular E d by adding a newline d character as requ ired, we were e able to accu Regular exp r essions are p patterns of characters that text paragraphs into distinct sentences (see figure 1 – match or fail to o match, seque ences of charac cters in text; relevant informa ation). Finding g sentence feat a tures relies allowing users to identify the presence of de sired pieces ent irely on de evelopment o f appropriate o Regular of text [8]. In short, a regula ar expression is a specific Ex pression syn k syntax, e.g. [A-Z].*?.!? )|$). A Re gular Express d sion Tester was used to defined using a formalized language, wh ich is then ide entify the sy ntax of sent tence structur in es before nterpreted by a regular ex xpression proc essor. This im mplementing i it into prog grammable c ode (e.g. processor parse es text, and ou tputs substring gs that meet http://www.nrege x.com/nregex x). To increas se process he defined specification. suc cess, inclus sion of synt actic except The formal ionalized pattern-m atching nota ation allows sub sequently con sidered, i.e. s tarting with a u a lowercase users to quick kly parse large amounts of text to find letter or ending w ith a question n/exclamation m s ark etc. specific chara acter patterns. . Textual su bstring are Once the sco e oped text was split into sentences, the extracted, edite ed, replaced or deleted [10]; t hus splitting thi rd stage was s used to spl it these sente d ences into descriptive text into analysab ble individual words. The ind ividual words s; all punctuati on and irrelev M ant marks MS .Net Fram mework libra ry contains classes that (e.g. brackets) were removed. S top words (e.g g. and, but, m implement regu lar expressio on (regex). Mo st MS .Net so) ) are essential in English pro ose to ensure th at writing is natural and d clearly stru uctured, how ever they mplement a string search h by declari ing use of the themselves hold limited meanin S ng. With reference to the System.Text.Re gularExpressi ons [9]. Th is process, MR O glossary d ictionary, stem m checking and h d synonym however, needs to be done str a tegically. com mparison was also undertake en to limit the sharing of me aning across multiple word III. M con ds. Although significant ntent will be l ost at this sta age, key mean E ETHODS ing should rem A main. A. Incorporati ng Regular Exp xpression In our work k we suggest t the use of fou r phases to the e frequency of each word as t the primary va s ariable. The successf ully f acilitate the best use of regular following section n describes the e construction and use of expressions. the e MRO diction nary. Firstly, ex traneous inf ormation suc h as the engineer’s signature, compa ny name, re ply/forward contents, etc. w as removed f from the comp leted report text. This additional informa ation is normal ly available

# B. The Aircraft MRO Glossary Dictionary

The aircraft MRO glossary dictionary is a critical process with strict requirements to safety, security, and quality; therefore its execution is highly standardized by international bodies; including the Air Transport Association [11]. The aircraft MRO glossary dictionary is an alphabetical list of industrial terms extracted from historical engineering reports, which is based on half a million MRO jobs. The dictionary, however, is not only a list of terms, but acts as a network of interlinked influencer describes something that may be realistically included within an engineering report (i.e. engine Terms, Part Number, Repair Type, Suppliers, Customers etc.).

The Aircraft MRO glossary dictionary deposits attributes combined in a certain order ‘smoke crack’ or ‘crack rock’, the sentence against the detailed content in previously processed job reports. According to the frequency of the word should be taken to remove the sentence from analysis. During stage 3, the word frequency in each sentence was also counted, as an important parameter to sentence information can be inferred, e.g. part number, repair meaning. A real example of key influencers is shown in figure 2. This example relates to an ‘Oil Cooler and Relief Bypass Valve Assembly’, and clearly shows structured normalized engineer feedback.

Words influencers, analysed from past engineer reports, which describing the reasons for failure, symptoms of a related to problems, processes or actions involving this broken part and the possible solutions are all of part. The three influencers with the most impact were defined as: seal, clean, replacement. Despite having no considerable value during the cost quotation process.

# C. Key Influencers Analysis

Accordingly, the following section discusses appropriate and relevant engineering experience, we are able to infer from these influencers that the fault might be due to either a blockage or a broken seal. If the part is not dirty or blocked then a replacement part (most likely the ‘seal’) may need to be ordered. Estimation of contextual use of the word and the sentence ‘activity based costing’ is also therefore possible with subsequent analysis.

To determine this, a three stage process was used. The first stage is to define the structure pattern. Krohn [13] noted that English sentences have certain patterns, which relates to how the sentence was constructed, i.e. the order of the elements. In our work we used six sentence structures: i) Subject - Verb, e.g. “The oil cooler has failed”); ii) Verb - Subject, e.g. “There is a strange noise in the conditioner.”; iii) Subject – Verb - Object, e.g. “Seals need modification”; iv) Subject – Verb - Indirect Complement, e.g. “The seat-belt bracket looks tired”; v) Subject – Verb - Object – indirect - Object, e.g. “I left the generator running over night”.

# IV. TESTING

# A. Training and Testing Data

A large industrial data set including 470,449 existing MRO jobs from the last ten years (2000-2010) was created as training data. Each job includes both normalised and unnormalised data. Normalised data is processed, properly classified and stored within a relational database (MS SQL Server); which relates to inappropriate influencers or language is included in information such as job reference number, part number, repair type, service cost, customer, supplier and completion date etc.

descriptive paragraphs. The training data size is kept unchanged to provide referable quote benchmarks.

|WNumber|0105o6-01|Aversde Quote|53390.69|
|---|---|---|---|
|Lowct Quote|4276442|Highest Quote:|55,654.85|
|Highcst Quote|55,65485|Daye|plcte:|

Testing data was taken from the MRO live database, palr Typc:

|Sub Parts:|SPM|Blade|Flange|
|---|---|---|---|
|Hernn|Sub Parte| | |

Defects:

Warranty Protection:
Nick
Scratch
LeakingLelorg
90.00%6 TrainingData

80.0076 Testing Jata

70.0026

Fig. 4. A screen shot for the test environment.

To validate the accuracy of the system, query results, i.e. an average quote price was calculated by the testing system, and compared with the actual service cost for each job. It has been agreed that a deviation of 20% from the quotation price is acceptable. However, as the quotation system improves in the future, the allowed range could be ideally reduced to 10% or less.

Now month later months later If extreme deviation is identified (i.e. over 20%) the reports were manually checked to ensure that the reasons for differences in pricing are revealed; such as the introduction of a new sub-part, or because of high inflation that will make current prices higher than that of historical quotes. In this case, new sub-parts were added to the MRO glossary dictionary and an inflation multiplier was added to the historical cost during the quotation calculations.

Certainly completed testing data will be added to quotation calculations. In our experience, however, there are many cases in which there is no clear reason to support a rise in the service cost above that of the training data set will be treated separately for another system estimated cost. Replacement of the same parts and/or sub-parts, implementation of the same repair type, in the same duration, often led to a cost that is distinctly different from previously completed jobs.

# B. Testing Procedure

The reference number of any suspected broken part validated whether the mining of engineering inspection was fed into the test system. Initial query results reports supports the accuracy of service quotation.

Information extracted from the engineer’s inspection report (i.e. the key influencers) were classified as being one of three categories: sub-parts, defects or suggestions for easy interface reference (see figure 4). As the user selects more influencers, the cost deviation of 30% was reasoned as being acceptable. Only 65.5% of cases fell within the 10% cost deviation range (see Figure 5).

# V. RESULTS

# A. Successes

Overall comparison figures showed that in 97,857 test cases, the system could successfully estimate job costs (within a 20% deviation range) 76.3% of the time. With a 25% deviation range, the figure rose to 84.9%. Jobs were successfully estimated 88.7% of the time, if a figure 4.

# 5. Accuracy based on deviation ranges

|100.00%|curacy with Text Mining| | | | | | |
|---|---|---|---|---|---|---|---|
|90.00%|curacy without Text Mining|1|Jser Inzeracjve| | | | |
|80.00%| | | | | | | |
|70.00%| |inaccurae quote|Keyiniluencers| | | | |
|60.00%| | |Exira Da-abase| | | | |
|50.00%| | |om Iex: Repor:| | | | |
|40.00%| | | | | | | |
|30.00%| |CondeiFional|Conveniional| | | | |
|20.00%| |MRO Drabase|MOR Da-abase| | | | |
|10.00%| | | | | | | |
|0.00%|10%|20%|25%|30%|berore|atzer|Qualil|

# In summary

Our proposed approach, i.e. independent of process has significantly improved business function in deviation range, incorporating mined data from two areas. Firstly text mining has provided more engineer service reports increased estimation accuracy information from the previously unused engineer’s report; to support company analytics and cost results were solely based on normalised data (see estimation. Secondly key influencers were defined as the text-mining outcome, which enables users to proactively narrow down the defect scope, supporting a service cost greater than 10% above the more precise data query. Figure 6 visually illustrates the estimated system quote. Apart from a small portion of improvement gained by solution adoption.

# B. Failures

Despite aircraft MRO processes being highly managed via provision of additional supporting standardised, i.e. supporting unified operations and use of appropriate Business Processes. Testing results showed that most analysis failures were caused because of engineers using highly complex sentence structures, typos or use of irregular English. Selecting the right supplier is the key to achieving cost efficiency and quality benchmarking; so we aim to extend our current work on cost estimation to help further improvement, by adding more comprehensive support supplier selection.

Another positive outcome of implementing this system is the on-going and continuous expansion of the aircraft MRO historical database. The accuracy of quotes depends on the accuracy of the reference dictionary. It is important that we have both i) enough data (i.e. quantity) relating to past jobs; but also ii) that quantity and quality. This allows undiscovered data, the quality of that data is worth referencing. This system adds considerable value by identifying key influences from previously unused engineering reports. This information increases the quantity of data, but also provides key influencer analysis, which should ensure supports appropriate selection of supplier, both for parts data quality. Furthermore, by presenting the key words regarding each specific job (part), customers can proactively specify the job nature, making the quote quoted independent of part number; and allows costing more accurate.

Using our system ‘Activity Based Costing’ (ABC) is also possible. ABC is often used in Customer Relationship Management to allow customers to see both i) the range of possible costs, but also ii) the justification for why variation might occur. Incorporating this approach, i.e. facilitating customers to see both the range of possible costs, but more precise cost quotations, should help the aerospace industry, as well as many other maintenance and service domains, a better levels of quality at lower levels of cost.

# VI. CONCLUSIONS

The approach introduced in this paper can significantly improve both aircraft MRO job data.

# ACKNOWLEDGMENT

This research was funded by a Knowledge Transfer Partnership project connected with an academic body (University of Reading) and an industry company (a leading aircraft MRO Service provider). A particular thank is sent to Mr Paul Taylor (Project adviser) for his support to make the success of this project.

# REFERENCES

1. X. Zhou, Database Systems for Advanced Applications: 14th International Conference, Dasfaa 2009, Brisbane, Australia, April 21-23, 2009; Proceedings. Berlin: Springer, 2009.
2. J. D. Hwang and W. J. Wang, "Application of Icp-Aes to Analysis of Solutions." Applied Spectroscopy Reviews. 30.4 (1995): 231-350. Print.
3. S. Fabrizio, Machine learning in automated text categorization. ACM Computing Surveys, 34(1):1–47, 2002
4. N. O. F. Andrews, and A. Edward, Recent Developments in Document Clustering, October 16, 2007
5. T. Peter, Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. Proceedings of the Association for Computational Linguistics. 2002, pp. 417–424.
6. K. Coussement, and P. den Van, "Integrating the Voice of Customers Through Call Center Emails into a Decision Support System for Churn Prediction." Information and Management. 45.3 (2008): 164-174. Print.
7. B. Pang, B., Lee, L., and S. Vaithyanathan "Thumbs up? Sentiment Classification using Machine Learning Techniques". Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). 2002, pp. 79–86.
8. Watt. Beginning Regular Expressions. Indianapolis, Ind: Wiley, 2005, pp. 2.
9. J. Goyvaerts and L. Steven, Regular Expressions Cookbook. Beijing: Oreilly, 2009. pp. 1.
10. T. Nash. Accelerated C# 2010. New York, NY: Apress, 2010, pp. 232.
11. Microsoft MSDN. NET Framework Regular Expressions, 2011.
12. M. Lutz, M. Alexander and G. Lars, International Workshop on Topic Maps Research and Applications. Leveraging the Semantics of Topic Maps. Berlin: Springer, 2007. pp. 56.
13. R. Krohn, English Sentence Structure. Ann Arbor: University of Michigan Press, 1971.

