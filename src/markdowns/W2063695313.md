# Secure Nearest Neighbor Revisited

# Bin Yao1, Feifei Li2, Xiaokui Xiao3

1Department of Computer Science and Engineering, Shanghai Key Laboratory of Scalable Computing and Systems, Shanghai Jiao Tong University, China

2School of Computing, University of Utah

3School of Computer Engineering, Nanyang Technological University, Singapore

1{yaobin}@cs.sjtu.edu.cn, 2{lifeifei}@cs.utah.edu, 3{xkxiao}@ntu.edu.sg

# Abstract

In this paper, we investigate the secure nearest neighbor (SNN) problem, in which a client issues an encrypted query point E(q) to a cloud service provider and asks for an encrypted data point in E(D) (the encrypted database) that is closest to the query point, without allowing the server to learn the plaintexts of the data or the query (and its result). We show that efficient attacks exist for existing SNN methods, even though they were claimed to be secure in standard security models (such as indistinguishability under chosen plaintext or ciphertext attacks). We also establish a relationship between the SNN problem and the order-preserving encryption (OPE) problem from the cryptography field, and we show that SNN is at least as hard as OPE. Since it is impossible to construct secure OPE schemes in standard security models, our results imply that one cannot expect to find the exact (encrypted) nearest neighbor based on only E(q) and E(D).

Given this hardness result, we design new SNN methods by asking the server, given only E(q) and E(D), to return a relevant (encrypted) partition E(G) from E(D) (i.e., G ⊆ D), such that E(G) is guaranteed to contain the answer for the SNN query. Our methods provide customizable tradeoff between efficiency and communication cost, and they are as secure as the encryption scheme E used to encrypt the query and the database, where E can be any well-established encryption schemes.

# I. INTRODUCTION

The cloud has gained increasing popularity for its flexibility and scalability, which motivates cloud service providers to offer accesses to cloud databases, such as Amazon Relational Database Service (Amazon RDS), Google Cloud SQL, and Microsoft SQL Azure. Data owners outsource their databases to the cloud service providers and rely on their services for storage, management, and query processing of the databases. Clearly, this framework offers great flexibility and scalability to data owners and their clients, and it is especially useful for users with stringent local resources.

However, the remote placement of the data brings security concerns. A data owner may prefer to prevent the server (i.e., the service provider) from learning the content of his/her database D or the contents of queries to D, while still requiring the server to provide database functionality for D in the cloud. For this purpose, the data owner needs to encrypt D with an encryption scheme E and only publishes to the server an encrypted version of D, denoted as E(D). The clients also need to encrypt their queries q and send only E(q) to the server. The server needs to identify the ciphertext in E(D) that corresponds to the answer of q on D, using only E(q) and E(D). We dub a query processing procedure satisfying these constraints as secure query processing.

Our new methods build on this idea for data in one and two dimensions, and they allow customizable tradeoff between communication and computation costs in cloud databases. Our idea leverages on special partitions over D and the Voronoi diagram of D. We dub our new method the secure Voronoi diagram (SVD) method. Since the SVD method does not use any new encryption schemes, rather, it only relies on any well-established encryption schemes.

standard encryption scheme E (e.g., public-key encryption RSA, symmetric-key encryption AES), the SVD method is as secure as E for any standard security model in which E is proven secure (e.g., indistinguishability in either chosen plaintext or chosen ciphertext attacks).

Finally, we use extensive experiments to demonstrate the efﬁciency of our attacks to existing methods, as well as the efﬁciency and the scalability of our new method SVD. Our experiments were conducted over real and large datasets (up to few millions points in multi-dimensional spaces).

The rest of the paper is organized as follows. Section II formulates the problem. Sections III-A and III-B show our construction of two (different) efﬁcient attacks to the SNN schemes in [21] and [15] respectively. Section IV investigates the relationship between SNN and OPE, which establish the hardness of the SNN problem. Section V presents the new, secure Voronoi diagram (SVD) method. Section VI gives our experimental results. Section VII surveys the related work, and Section VIII concludes the paper.

# II. PROBLEM FORMULATION

Formally, the SNN problem involves three parties:

1. A data owner who has a database D with d-dimensional Euclidean objects/points, and would like to outsource D to a server that cannot be fully trusted.
2. A client (or multiple of them) who wants to access and pose queries to the database D.
3. A server that is honest but potentially curious in the tuples in D and/or the queries from the clients. A server could be curious either because he is just curious or he has been compromised to become curious on the behalf of a third party without his explicit knowledge.

Our objective is to enable the client to perform NN queries without letting the server learn contents about the query (and its result) or the tuples in the database. Note that in practice, a data owner could also be a client. Clearly, in order to achieve our objective, the database D has to be encrypted by some encryption scheme E by the data owner. We use E(D) to denote the encrypted version of the database, and E−1 to denote the corresponding decryption function (with the necessary secret). Similarly to the case for the data owner, clients only send to the server the encrypted versions E(q) of their queries q (each of which represents a query point).

We aim to ensure that the SNN method is as secure as the encryption method E used by the data owner. For ease of exposition, we consider that E is proven secure under chosen-plaintext attack, but our method can be straightforwardly extended for other adversary models (e.g., indistinguishability under chosen-ciphertext attack).

The above formulation of the SNN problem is adopted in previous work [15], [21] and is of considerable practical importance for various reasons [11], [12], [14]–[16], [19], [21]. For example, D might contain some sensitive values that cannot be disclosed to the server, or D represents a business asset to the data owner and/or the client, or the service providers wish to provide SNN service as an assurance to attract more customers.

Without loss of generality, we assume that D is represented by N tuples {p1, . . . , pN}. Each tuple can be viewed as a d-dimensional point: for any p ∈ D, p = 〈v1, v2, . . . , vd〉; p can also be considered as a vector in d-dimensional space.

Remarks. One may consider an alternative formulation of the SNN problem by regarding the data owner and the client as the same party, since they share the same key and are assumed to trust each other. We explicitly differentiate the data owner from the client, so as to be consistent with previous work [15], [21] and to simplify our discussion on the loopholes of the existing methods (see Section III).

Unless otherwise speciﬁed, all proofs in this paper can be found in Appendix ?? from our online technical report [22].

# III. INSECURITY OF EXISTING METHODS

# A. Solution by Wong et al. [21]

Basic idea. The data owner encrypts each tuple in the database before sending it to the server using a customized encryption scheme ET. The client sends an encrypted query using a related but slightly different customized encryption scheme EQ to the server. Wong et al. [21] showed that the customized encryption schemes ET and EQ preserve the dot product between the query vector q and any tuple vector p from the database D, i.e., q · p = EQ(q) · ET(p). Furthermore, for any two points p1 and p2 from D, p1 · p2 = ET(p1) · ET(p2), i.e, the dot product between two tuples in D cannot be obtained directly from their ciphertext.

Given an encrypted query point E(q), the server (i) inspects the dot product between E(q) and the ciphertext ET(p) of each tuple p ∈ D, and (ii) returns to the client the ciphertext that corresponds to the answer of the SNN query (see [21] for the detailed algorithm). After that, the client decrypts the ciphertext to get the query result. Note that, in order for the client to encrypt and decrypt, the data owner needs to share the secret key with the client.

# Customized encryption schemes.

The data owner and the client share the following secret information: (i) an integer d′ ≥ d, (ii) two d′ × d′ matrices M1 and M2 that are random but invertible, (iii) a random bit vector A with d′ bits b1, b2, . . ., bd′, and (iv) some additional information that is irrelevant to our discussion.

Let p = 〈v1, v2, . . . , vd〉 be any tuple in the database. The encryption scheme ET works as follows. The data owner ﬁrst converts p into a d-dimensional tuple p′ = [v′1, ..., v′d] T, such that (i) v′i = vi for any i ≤ d, (ii) v′d+1 = −2 ∑j=1d vj, and (iii) v′d+2, ..., v′d′ are random numbers generated by some speciﬁc rules (omitting such details does not affect our analysis here). Next, p′ is transformed into two tuples p′1 = [x1, . . . , xd′] T and p′2 = [y1, . . . , yd′] T based on A, such that for any i ∈ [1, d′],

1. if bi = 1 (the ith bit from A), then xi and yi are two random numbers satisfying xi + yi = vi;
2. otherwise, xi = yi = v′i.

At last, the data owner computes *p* = MT · p' and p* = MT · p', and sends p* and p* to the server as the encrypted version of p*.

Meanwhile, the scheme *EQ for encrypting query points is as follows. Given q = 〈v1, v2, . . . , vd〉 and a random number r > 0, the client first converts q into a d′-dimensional tuple q′ = [v′ , ..., v′ ]T that satisfies two conditions. First, v′ = r vi for any i ∈ [1, d′] where i <= d, and vd+1 = r. Second, vi for i ∈ [d + 1, d′] are random values generated according to some specific rules, such that the scalar product over the artificial attributes (between d + 1 and d′) from any q′ and p′* is always 0.

Then *q′ is transformed into two tuples q′a = [x1, . . . , xd′]T and q′b = [y1, . . . , yd′]T, such that ∀i ∈ [1, d′]*:

1. If *bi = 0 (the ith bit from A), then xi and yi are two random numbers such that xi + yi = v′;*
2. Otherwise, *xi = yi = v′.*

The encrypted version of *q is the pair: qa = M-1 · p′ and qb = M1 · qa and qb = M2 · qb.*

# Security guarantee.

Wong et al. show that the above encryption schemes preserve the dot product between any query point *q and any point p in the database, i.e., q · p = ET(q) · EQ(p) (this forms the basis for their SNN method [21]). Furthermore, Wong et al. claim that this protocol can guard against any attacks based on the knowledge of a number of (plaintext, ciphertext) pairs [21], and their argument is as follows: if the boolean vector A is known to the adversary, then he/she would be able to use the known (plaintext, ciphertext) pairs to construct linear equations about M1 and M2, and then solve the equations to obtain M1 and M2. However, since A is secret, it would be hard for the adversary to derive the correct linear equations to use, since the formulation of the equations depends on A. A brute-force approach would require the adversary to examine all possible bit vector A, which leads to 2|A| linear equation systems that cannot be solved in reasonable time when |A|* is large.

We observe that the above reasoning is not rigorous, since it assumes that the adversary only attempts his/her attacks by solving *M1 and M2. We will demonstrate an attack that does not require any knowledge about M1 and M2*.

# Our attack using chosen-plaintext attack.

Assume that the server obtains *d query points and their encryption (by asking the oracle in the chosen plaintext attack model). For each q of those query points, the server would have two encrypted points qa and qb generated by EQ. Wong et al.’s encryption schemes ensure that the dot product between q and any database point p* can be calculated based on the following equation:

*p · q = pa · qa + pb · qb* (1)

Notice that the above equation contains only *d variables unknown to the server, i.e., the d coordinates of the data point p. Since the server has the plaintext-ciphertext pair of d query points, he can construct d linear equations like (1) to derive the coordinates of p*.

# B. Solution by Hu et al. [15]

Hu et al. [15] consider the SNN problem under a setting that is different but similar to ours. They assume that each client (i) has the ciphertexts of all data points in *D and the encryption function *E* used to encrypt D, but (ii) does not have the decryption function E-1. On the other hand, the server has E-1* and some auxiliary information about each data point (which is irrelevant to our discussion), but does not have the plaintext or ciphertext of any data point. The objective of Hu et al.’s method is to enable the client to identify the encrypted answer for any SNN query (with the help from the server), after which the client can retrieve the auxiliary information associated with the answer from the server (the plaintext of the answer remains secret to the client). Hu et al. claimed that their solution not only prevents the server and client from learning the plaintext of any data point, but also prevents the data owner and the server from learning the queries posed by the clients. However, we will show that Hu et al.’s solution does not fulfill their security claims.

# The encryption scheme.

The construction in [15] relies on an encryption scheme that gives what they called the privacy homomorphism (PH). PH is an encryption transformation which maps some operations on cleartext to operations on ciphertext. Formally, they are encryptions *Ek : P → X that allow a set of operations F on encrypted data without knowledge of the decryption function (here, P is the domain of plaintext and X is the domain of ciphertext). In particular, they used the ASM-PH encryption scheme from [9], which supports modular addition, subtraction, and multiplication. In what follows, we use E to denote an ASM-PH encryption function, and E-1 to denote the corresponding decryption function (with the necessary secret keys). The PH encryption E in [9] is shown to be secure against known-plaintext attacks, and it can perform addition, subtraction, and multiplication directly on the ciphertexts, e.g., E(a + b) = E(a) + E(b). Note that in PH the operation on E(a) and E(b) is not necessarily the same as that in plaintexts to preserve an operation, but maybe some function f on E(a) and E(b) that is efficient to compute and gives the same output as the operation of interest over the corresponding plaintexts, i.e., E(a + b) = f(E(a), E(b)). But for simplicity, in the remainder of this paper, we just use the same operation over the ciphertexts to denote such an f*.

However, assuming a fully secure ASM-PH scheme E, we can still launch an efficient attack on Hu et al.’s solution.

# Basic idea of Hu et al.’s solution.

The data owner builds a multidimensional index *I over his database D. Each node b in I has a set of entries, where each entry e has a key value v and a pointer p (to a child node of b). Note that v can represent any object. For example, in the case of a d-dimensional R-tree, v is a minimum bounding rectangle (MBR) and can be represented as (→ ℓ, → u), where ℓ = {ℓ1, . . . , ℓd} and u = {u1, . . . , ud}, such that [ℓ, u] is the extent of the MBR in the ith dimension. After I is generated, the data owner constructs a shadow index E(I), which is identical to I except that the key values (and only the key values) in all entries from all nodes are encrypted by an ASM-PH encryption function E. E(I) is published to all clients, and only the decryption function E-1 of E* is sent to the server.

During query processing, Hu et al.’s solution requires the client to encrypt the query *q and traverse the shadow index E(I) locally with the help of the server. In particular, for each node b in E(I) visited by the client and for each entry e = (E(v), p) in b, the client computes E(mindist(q, v)) = mindist(E(q), E(v)) using the properties of the ASM-PH encryption E, where mindist(·) is the minimum distance between a query point q and an MBR v. Hu et al. showed that in the ith dimension (suppose that q = (q1, . . . , qd)*):

*E(2 · mindist(qi,[ℓi, ui])) = sign(ui − qi)(E(ui) − E(qi)) + sign(ℓi − qi)(E(ℓi) − E(qi)) − (E(ui) − E(ℓi)), (2) mindist(E(q), E(v)) = ∑ E2(2·mindist(qi,[ℓi, ui])), (3) where sign(a − b) returns −1 if a < b and 1* otherwise.

Note that in (2), only *sign(ui − qi) and sign(ℓi − qi) are not known/computable by the client locally. To figure out their values, the client computes E(ui) − E(qi) = E(ui − qi) and E(ℓi) − E(qi) = E(ℓi − qi) locally and sends them to the server. The server, with the decryption function E−1, can easily tell the values for sign(ui − qi) and sign(ℓi − qi) and send them back to the client, given E(ui − qi) and E(ℓi − qi)*.

Now, knowing the values of *sign(ui − qi) and sign(ℓi − qi), the client proceeds to compute E(2 · mindist(qi,[ℓi, ui])) by (2) and then derive mindist(E(q), E(v)) by (3). Finally, the client sends mindist(E(q), E(v)), which is equivalent to E(mindist(q, v)), to the server for decryption to figure out the actual distance between q and the MBR represented by v*.

The client repeats this process for each entry *e = (E(v), p) from an index node u*, and chooses the proper children nodes to browse in the next level, following the standard NN search algorithm in an R-tree.

To prevent the server from knowing the exact value of *ui − qi and ℓi − qi, before sending E(ui − qi) and E(ℓi − qi) to the server, the client subjects them to a scrambling process. Similarly, to prevent the client from knowing the exact value of mindist(q, v), the server subjects the decrypted value of mindist(E(q), E(v))* to a recoding process.

The details of the scrambling and recoding procedures are not important to our discussion here. The bottom line is, in Hu et al.’s scheme, *sign(ui − qi) and sign(ℓi − qi) must be computed by the server and sent to the client for each dimension i ∈ [1, d]*, so that the client can compute some distances locally to decide the next node(s) to visit. We construct our attack using this simple knowledge.

# Our attack using chosen-plaintext attack.

As said above, for any *d-dimensional query point q and any encrypted value E(v) where v = {ℓ, u}, the server returns the values of sign(ui − qi) and sign(ℓi − qi) (−1 or 1) to the client (for all i ∈ [1, d]). With this knowledge, however, the client can actually recover the value v using a chosen plaintext attack. This means that the client can recover any point p in D, since p’s ciphertext E(p) is stored in the leaf-level entries of the shadow index E(I) at the client side. As a result, Hu et al.’s approach cannot conceal the database D* from the client (which contradicts their security claims). Our attack works as follows.

# IV. HARDNESS OF THE SNN PROBLEM

Given the observations that none of the existing SNN methods guarantees security in a standard security model, one may wonder if the SNN problem is indeed hard. By being hard, we mean that it is at least as hard as some other well-understood cryptography problems that are known having no efficient secure schemes in well-established security models. To answer this question, we will show in this section that the SNN problem is at least as hard as the order-preserving encryption (OPE) problem [5], [6].

An order-preserving encryption *E : P → X is an encryption that takes a plaintext in a domain P and outputs a ciphertext in a domain X, such that for any p1, p2 ∈ P, one can determine if p1 > p2 or p1 < p2 given only c1 = E(p1) and c2 = E(p2). (Note that deciding whether p1 = p2 can be reduced to checking whether both p1 > p2 and p1 < p2 are false.) In other words, one can understand an OPE encryption scheme as a set of functions {E, E−1, op}*, such that:

*op(c1,c2) = 1 iff p1 < p2, op(c1,c2) = −1 iff p1 > p2, (4) where op(·) is a polynomial operation that does not involve (or have any knowledge of) the decryption function E−1*.

The concept of an OPE scheme was first proposed in the database community [1]. The solution, however, did not come with a rigorous analysis of its security guarantee. It was until the efforts from the cryptography community [5], [6] that we understand the hardness of constructing a truly secure OPE scheme. Specifically, Boldyreva et al. [6] have shown that it is impossible to construct a secure OPE in standard security.

models (such as indistinguishability against chosen-plaintext attack, a.k.a. IND-CPA). Interested readers are referred to [5], [6] for details. The critical message from [5], [6] is as follows:

# Theorem 1:

[from [5], [6]] A truly secure OPE does not exist in standard security models, such as IND-CPA. It also does not exist even in much relaxed security models, such as the indistinguishability under ordered chosen-plaintext attack security model (a.k.a. IND-OCPA).

We can establish the hardness of the SNN problem using this negative result. We will show that given E(q), designing an SNN method to find q’s (encrypted) exact nearest neighbor from an encrypted database E(D) is as hard as designing a secure OPE in standard security models. For convenience, let nn(q, D) denote the nearest neighbor of q in D.

# The reduction.

Suppose that we have a d-dimensional database D that contains N points p1, . . . , pN, and an encryption scheme E that is secure under a standard security model M. We use E-1 to denote the decryption function of E, and E(D) to denote the set {E(p1), . . . , E(pN)}. Assume that we can construct a truly secure SNN method that is able to find exactly E(nn(q, D)) efficiently given E(q) and the encrypted database E(D) alone. We denote this polynomial method as B and formally define it as:

B(E(q), E(D)) → E(nn(q, D)), B does not use E-1.

If such a method B(·) exists, we can construct an OPE E(·) in the same security model M. Our construction is as follows. Suppose that the message space for the OPE E(·) is the same as the encryption scheme E above, which is represented by N values {m1, . . . , mN}, and without loss of generality, m1 < m2 < · · · < mN-1 < mN. Our first step in constructing E(·) is to map these values to a set of one dimensional points D = {p1, . . . , pN, pN+1} using a special random hash function h, such that for any i ∈ [1, N + 1], pi is a random value subject to the following constraints:

1. pi ∈ Z+ for i ∈ [1, N + 1];
2. h(mi) = pi for i ∈ [1, N];
3. pi < pj for any i, j ∈ [1, N + 1] iff i < j;
4. pi+1 − pi < pi − pi−1 for any i ∈ [2, N].

# Lemma 1:

For any message space {m1, . . . , mN}, the above hash function h(·) guarantees that:

nn(h(mi), D) = h(mi+1) for any i ∈ [1, N − 1], and nn(h(mN), D) = pN+1, nn(pN+1, D) = pN = h(mN).

Lemma 1 indicates that, for any two consecutive values mi and mi+1 in the message space of E(·), the hash value of mi+1 is the NN of the hash value of mi. In addition, for the maximum element mN in the message space of E(·), the NN of its hash value is the maximum element in the output space of h(·). Figure 1 shows an example of the hash function h(·).

We are now ready to present our OPE. For any mi from a message space {m1, . . . , mN}, we define an encryption scheme E:

E(mi) = E(h(mi)) = E(pi), E-1(c) = h-1(E-1(c)),

# Algorithm 1:

op(c = E(mi), z = E(mj))

1. i = traverse(c);  /* see Algorithm 2 */
2. j = traverse(z);  /* see Algorithm 2 */
3. if i < j then return 1; else return −1;

# Algorithm 2:

traverse(c)

1. set γ = 0;
2. let t = B(c, E(D)); t′ = c
3. while B(t, E(D)) = t′ do
4. let t′ = t and  t = B(t, E(D));
5. γ = γ + 1;
6. return N − γ;  /* B(·), E(D) are global inputs */

Next, we will show that E(·) is an OPE, by proving that there exists an operator op(·) that satisfies the Equation 4. Algorithm 1 presents the details of our formulation of op(·). Note that the algorithm only uses E(D) and B without any knowledge about the secret of E (which includes both the secret of E and the random mapping h). Algorithm 1 also uses Algorithm 2 as its building block. Given a ciphertext c = E(mi), Algorithm 2 outputs the index value i for the plaintext mi. Hence, op(·) in Algorithm 1 simply compares the two index values of the two input ciphertexts.

Specifically, the idea in Algorithm 2 is as follows. By Lemma 2, B(c, E(D)) = B(E(mi), E(D)) outputs E(mi+1) (for i ∈ [1, N − 1]). Now, we can repeatedly apply B(·) γ times on its result until we hit E(mN) = E(pN); clearly, the only challenge left is: how can we check if we have reached E(mN) = E(pN)? To explain how we address this, observe that, by Lemma 2, we have B(E(mN), E(D) =

E(pN+1) and B⌈E(pN+1), E(D)⌉ = E(pN) = E(mN), i.e., once we hit E(mN) for the first time, subsequent calls to B(·) on its result will bounce between E(pN+1) and E(mN). Furthermore, among all possible ciphertexts E(m1) = E(p1), . . . , E(mN) = E(pN), E(pN+1), this mini-loop only happens between E(mN) and E(pN+1) (when we repeatedly apply B(·) to its own output).

Thus, if we record the current value of t as t′ before we set t = B(t, E(D)) in line 4 in Algorithm 2 (same idea in line 2), then when t becomes E(mN), line 4 would first set t′ = t = E(mN), and then set t = B(t, E(D)) = B(E(mN), E(D)) = E(pN′+1). After that, B(t = E(pN′+1), E(D)) outputs E(mN) =′t again, in which case t and t would satisfy B(t, E(D)) = t; this is precisely the condition that terminates the loop in line 3.

Finally, for c = E(mi), it is easy to verify that this termination condition is first met when we have iterated t through E(mi+1), . . ., and E(mN) exactly once (by the mini-loop observation above). Thus, the running time of Algorithm 2 is at most O(N Z) where Z is the running time of the SNN method B(·). This indicates that the cost of the Algorithm 1 for op is also O(N Z).

# Theorem 2:

Let {m1, . . . , mN} be any message space and mi < mj if i < j. Let E(mi) = E(h(mi)) and E −1 be as defined in (7), using the hash function h and the secure encryption scheme E from the SNN method B(·). Define op(·) as shown in Algorithm 1. Then (E,E−1,op) is an OPE scheme that is secure in any security model M in which E is secure.

Finally, by Theorems 1 and 2, our conclusion is:

# Theorem 3:

It is impossible to construct a secure SNN method B(·) satisfying (5) in standard security models, such as IND-CPA. It is not even possible to construct such an B(·) in much relaxed security models such as IND-OCPA.

# V. PARTITION BASED SNN METHOD

As shown in Theorem 3, given only an encrypted NN query E(q) and an encrypted database E(D), there is no SNN method that can pinpoint the NN of q in D. To circumvent this impossibility result, a natural idea is to devise an SNN method that does not exactly retrieve the NN of q. For example, the server may answer an SNN query by returning the encrypted database E(D) as a whole to the client, after which the client can decrypt E(D) and compute the answer to the query locally. This naive approach is clearly secure (as secure as E), but it is highly inefficient as it requires transferring E(D) to the client. To improve, we propose to partition D into small groups and store the encrypted version of each group on the server, such that any SNN query can be answered by returning one encrypted group instead of the whole encrypted database. Specifically, our partitioning of D is based on the Voronoi diagram of D, as explained in the following.

# A. Secure Voronoi Diagram

Given a multi-dimensional point database D with |D| = N, a Voronoi diagram of D is a decomposition of the space Ω in which the points in D are defined. The diagram consists of n disjoint Voronoi cells, each of which is associated with a point in D (referred to as the owner of the cell). If a point p is the owner of a cell c, then c equals the union of all points in Ω that are closer to p than to any other points in D. Thus, if a query point q falls in c, then its nearest neighbor in D is p. For example, Figure 2 illustrates the Voronoi diagram of a database with 16 two-dimensional points.

The Voronoi diagram of points in D can induce a partition of D for SNN. Specifically, we can impose a square grid on the Voronoi diagram, and then construct an overlapping partition of D, such that each element of the partition (i) corresponds to a grid cell B and (ii) consists of the owners of all Voronoi cells that overlap with B. For example, in Figure 2, the partition element (i) G1 corresponds to the grid cell B1, and (ii) G1 consists of ten points (i.e., p1, p2, p3, p4, p5, p6, p7, p8, and p10), since B1 overlaps with the Voronoi cells owned by those ten points. Observe that, if a query point falls in a grid cell Bi, then its nearest neighbor must be a point in the partition element Gi associated with Bi.

Given the aforementioned partition of D, the data owner pads each partition element to the same size, and then encrypts them separately (with the same key) and gives each element a random identifier. (The padding procedure ensures that the encrypted partition elements cannot be distinguished by their sizes). After that, the data owner sends all encrypted partition elements and their associated identifiers to the server, and informs the client about the description of the square grid and the identifier of each partition element. Whenever the client has an SNN query q, she first identifies the grid cell B that contains q, and then retrieves the identifier i of the partition element that corresponds to B. Then, the client asks the server to return the encrypted partition element whose identifier equals i (notice that this partition element must contain the nearest neighbor of q). Upon receiving the partition element, the client decrypts it and computes the answer to q locally. Intuitively, this SNN method is secure, as it allows the server to learn nothing but the identifier of the returned encrypted partition, which is randomly generated. We provide the formal security proof in Section V-C.

The above partition scheme, albeit simple and secure, incurs significant space overhead (for the server) and communication cost (for the client). To understand this, recall that each partition element needs to be padded to the same size before encryption. Let smax be the number of points in the largest partition element. Then, after padding, the size of each partition element is smax. Assume that the size of the encryption of a message is (roughly) linearly dependent (or in a stair-case fashion) on the size of the message, which is the case for most encryption functions, the server requires O(k · smax) space to store all encrypted partition elements (where k denotes the total number of partition elements), and the client pays O(smax) communication cost for each SNN query. Ideally, we would prefer a partition scheme that ensures smax = N/k, in which case both the server’s space overhead and the client’s communication cost are minimized. This, however, would

# Improved Partition Schemes

Gi = {p|p ⊂ Bi}

|B1|p₂|p₈|p₁₃|B2|B2|B4|B2|B4| |
|---|---|---|---|---|---|---|---|---|---|
|p|p₅|p₉|p|p¹⁵|B1|B3|B1|B3| |
|G|3|p₇|p₁₄| |G2| |(a) Square Grid: SG.|(b) MinSG.|(c) MinMax.|

Fig. 2: The SVD method.

Fig. 3: Different partitioning schemes, k = 4.

k = 2, G₁ = {p₁, p₂}, G₂ = {p₃, p₄}, B₁ = {−∞, σ}, B₂ = {σ, +∞}

# Two Dimensional Data:

The case for two-dimensional data is much more complicated than the one-dimensional case, which renders it difficult to compute an optimal solution efficiently. This motivates us to derive two partition schemes based on heuristics, as will be explained in the following.

# The MinSG scheme.

This partition scheme adopts a greedy approach to generate a grid where the sizes of cells vary in a manner that adapts to the distribution of points in D. We start with a grid that contains only one cell Ω that covers the entire data space. Then, we iteratively cut the grid cells into smaller ones using either horizontal (or vertical) lines through [−∞,+∞] along the x-axis (or the y-axis). The process is conducted until the desired number of grid cells is met. After that, we generate the partition by identifying the owners of the Voronoi cells that intersect with each grid cell (as with the case of a square grid in the SG method).

Remark: The partition scheme of imposing a square grid over the Voronoi diagram was also used by Ghinita et al. [10] in the context of private information retrieval (PIR). We will discuss the difference between SNN and PIR in Section VII. We dub this scheme the SG (Square Grid) partition.

The effectiveness of the above algorithm relies on how we choose the horizontal (or vertical) line to cut the grid cells. As we aim to minimize smax, we propose to choose a line cutting through the grid cell Bmax that determines smax, i.e., the grid cell that intersects the largest number of Voronoi cells. The intuition is that, when Bmax is split into two smaller cells Bα and Bβ, each of the two cells may intersect a smaller number of Voronoi cells, which leads to a decrease of smax. To maximize the decrease of smax, we should minimize max{|sα|,|sβ|}, where |sα| (|sβ|) denotes the number of Voronoi cells that intersects Bα (Bβ). Choosing a line that minimizes max{|sα|,|sβ|}, however, is challenging given that there exists an infinite number of lines that cut through Bmax.

# 1) One Dimension:

In one dimension, there is an optimal partition scheme that generates disjoint and equal-size partition elements. To explain this, observe that the Voronoi cells of any one-dimensional dataset are one-dimensional intervals, such that (i) any two intervals are disjoint, and (ii) the union of all intervals equals the data space. For example, Figure 4 shows the Voronoi cells (vc1, . . . , vc4) of a one-dimensional dataset that contains four points p1, p2, p3, p4.

Assume that we aim to generate a partition of D with k elements. Then, it suffices to divide the data space into disjoint intervals, such that each interval contains N/k Voronoi cells of D (where N is the number points in D). The owners of the Voronoi cells in each interval can be taken as partition elements, which leads to an optimal partition scheme where smax = N/k. For instance, if we are to generate a partition with two elements on the dataset in Figure 4, then we can put p1, p2 into a partition element, and p3, p4 into the other.

As mentioned, the above splitting procedure is applied.

iteratively based on the grid cell that intersects the largest number of Voronoi cells, until the number of grid cells reaches a pre-deﬁned threshold k. Since each cutting line that we use would span the whole x- or y-axis, it may split more than one grid cells, and hence, when the algorithm terminates, the total number of grid cells may be more than k. Whenever this happens, we would iteratively merge some neighboring cells without affecting the size of the largest partition, until only k cells are left. We omit such technical details for brevity.

MWe refer to the aforementioned partition scheme as the INSG (Minimum Space Grid) method. For example, Figure 3(b) shows the results of applying MINSG over the same dataset in Figure 3(a).

It can be veriﬁed that the number of iterations performed by MINSG is no more than k −1 (since each iteration increases the total number of grid cells by at least one). Furthermore, the number of cutting lines that MINSG needs to inspect in each iteration is O(N), since (i) the total number of vertices in a Voronoi diagram is 2N − 5 (for N ≥ 3), i.e., |V1| = 2N − 5, (see Theorem 7.3, [8]); and (ii) each Voronoi cell, being a convex polygon, can intersect the boundary of a grid cell at no more than 8 points, i.e., |V2| ≤ 8N. For each candidate cutting line ℓ, we need to identify the Voronoi cells intersecting ℓ and to incrementally update the number of Voronoi cells that overlap with each grid cell, which incurs O(N) cost in the worst case. Therefore, the time complexity of MINSG is O(kN2). In practice, however, the running time of MINSG is often not quadratic to N, since the sizes of V1 and V2 are often much smaller than N.

# The MinMax scheme

The MINSG method tries to minimize the maximum element size in the partition, by iteratively splitting the largest partition element. Nevertheless, the split is induced by a horizontal or vertical line that spans the whole x- or y-axis, which often incurs unnecessary split of other partition elements. For example, consider the grid partition in Figure 3(b), where the grid cell B1 intersects the largest number of Voronoi cells. If we are to split B1 with a vertical line ℓ, then the cell B2 would be split into two smaller cells by ℓ as well, even though the split of B2 does not decrease the maximum element size in the induced partition.

To address this problem, we propose to improve MINSG by splitting, in each iteration, nothing but the grid cell that induces that largest partition element. Speciﬁcally, in an iteration where the large partition element is induced by grid cell Bmax, we would split Bmax using a horizontal (vertical) line segment ℓ′ whose projection on the x-axis (y-axis) equals Bmax’s projection on the same axis. Furthermore, the line segment is selected among those that pass through (i) a vertex of a Voronoi cell or (ii) the intersection point between a face of a Voronoi cell and the boundary of Bmax – the correctness of this approach can be shown by a result similar to Lemma 3. The rest of the algorithm is the same as in MINSG. We refer to this improved method as the MINMAX (Minimum Max partition) method. Figure 3(c) shows the results of applying MINMAX on the same dataset in Figure 3(a).

Observe that each iteration of MINMAX increases the number of grid cells by one. Thus, the total number of iterations performed by MINMAX is (k − 1). Each iteration inspects O(N) cutting line segments, and examines O(N) Voronoi cells for each line segment. Therefore, the time complexity of MINMAX is O(kN2), as with the case of MINSG. But, for similar reasons, its running time in practice is much better.

# Remark

No matter which partition scheme is used, the data owner does not send the k partition elements to the client, which have a total size of N points. Instead, he only needs to send the description of the grid constructed, and the associated (randomly generated) identiﬁer for each grid cell, which only has a size of O(k) for all three methods, SG, MINSG, and MINMAX.

# C. Security Analysis

No matter which partition scheme is used, the SVD method only releases the encryptions of all partition elements to the server, using an encryption scheme E that is proven secure in a standard security model M, and their associated (randomly generated) identiﬁers. Furthermore, during query processing, the client sends only the identiﬁer for the partition element whose corresponding grid cell contains the query point q, to the server. Thus, the server learns nothing but an id number (randomly generated by the data owner for each partition element) in answering a query. Formally:

# Theorem 4:

If E is a secure encryption scheme in a standard security model M, e.g., indistinguishability under chosen plaintext attack (IND-CPA), then the SVD method is as secure as E in the same model M with respect to a single query.

Further improvement of security. The above analysis considers a powerful adversary that is able to obtain a large number of plaintext-ciphertext pairs (in either chosen plaintext attack model or chosen ciphertext attack model), but implicitly assumes that the adversary has no knowledge of how the user’s queries are distributed. When this assumption does not hold, the adversary may infer information by exploiting the correlation between different encrypted queries from the user. For example, assume that the adversary knows in advance that most of the queries from the user would have a query point in a region R. Then, the adversary can keep track of the encrypted partition element retrieved by each user query over a long period, after which the adversary can link R to the partition element that is retrieved most frequently.

To guard against such attacks, we can extend our solution by adopting private information retrieval (PIR) techniques [10]. In particular, for any SNN query q, the user can ﬁrst identify the encrypted partition element that contains the answer to q; and then, the user can invoke a PIR protocol to retrieve the encrypted partition element from the server, without allowing the server to learn which partition element is returned. But notice that existing PIR techniques either incur considerable overhead in query processing [10] or require specialized secure hardware that is expensive [17], i.e., the improved security guarantee would come at a cost.

# VI. EXPERIMENT

Our implementations were achieved in C++. We used the Qhull library to find the Voronoi diagram for a dataset D, and the latest Crypto++ library for any standard encryption schemes. All experiments were performed on a Linux machine with an Intel Xeon 3.07GHz CPU and 12GB memory.

# Datasets

When investigating our attacks to existing schemes in different dimensions, we generate random points following either a random cluster or a uniform distribution. Based on the construction of our attacks, the distribution of the points does not affect the efficiency of our attacks.

For SVD methods, we focus on 2-dimensions with two real datasets, which are points of interest in California (CA) and Texas (TX) from the OpenStreetMap project. In each dataset, we randomly select 2 million points to create the largest dataset Dmax and form smaller datasets based on Dmax. We also make sure that smaller datasets are always subsets of larger datasets, in order to isolate the impact of |D|.

# Setup

In the investigation of our attacks, since the distribution of the data does not introduce a noticeable difference, our default distribution is uniform. In the scheme from Wong et al. [21], we set the default values of d and d′ as d = 30 and d′ = 60. In the scheme from Hu et al. [15], we only report the results from d = 2 for brevity.

# Preprocessing cost

For the data owner, there are two major steps: partition and encryption. Both are mainly affected by the number of grid cells k (which is also the number of partition elements) and the size of the database. Figure 7(a) shows that the partition costs in both MINSG and MINMAX increase linearly with k, however, the cost of MINSG increases much faster than that in MINMAX, which increases very slowly (almost unnoticeable). This is due to the optimization in MINMAX (compared to the cutting lines in MINSG) to limit any cutting line to be strictly within the cell to split.

# A. Attacks to existing methods

We first studied the efficiency of our attack on the SNN method by Wong et al. [21], and the results are given by Figure 5. As shown in Section III-A, our attack only needs d query points and their encryption to form a linear system of d linear equations with d unknowns to solve one data point p ∈ D. Thus, the cost of our attack should be linear to both |D| and d, which is reflected in Figures 5(a) and 5(b). Our attack is extremely efficient. For example, Figure 5(a) shows that it takes less than 23 minutes to recover a database with 2 million points in 30 dimensions and also with 30 artificial dimensions.

Lastly, the artificial dimensions d′ introduced in the solution of Wong et al. [21] is not significant to our attack, as seen in Figure 5(c). When d′ goes from 30 up to 80, the overhead introduced to the overall time to attack is less than 40 seconds when the total time to attack is 600 some seconds.

# Return a partition element vs. return nn(q, D)

One may wonder if the SVN method “leaks” too much information to the client about the database D, by returning a partition element (i.e., a number of points) for each query. We argue that this should not be a concern at all: if one allows the client to learn the nearest neighbor of a query point of her choice (by any SNN methods), the client can efficiently reconstruct the entire database D anyway, i.e., there is no way of hiding the database D from the client if one wants to support client’s nearest neighbor queries. We show why this is the case in Appendix ?? in our online technical report [22].

# B. Evaluation of the SVD method

We next evaluate the efficiency of the new SVD method, when we instantiate it with three different partitioning schemes introduced in Section V. To differentiate them, we simply refer to the resulting SVD methods by the names of the partitioning methods used.

# Running time of the partition phase

|60|SG|MinSG|MinMax|100|SG|MinSG|MinMax|
|---|---|---|---|---|---|---|---|
|45| | | |80| | | |
|30| | | |40| | | |
|15| | | |20| | | |
|partition time (secs)|0| | |0|0.4|0.8|1.2|
|0|300|600|900|1200|0|0.4|0.8|
| |k| | ||D|=Ν: x10| | | |

# Partition size in different methods

|10⁸|SG|MinSG|MinMax|10⁸|SG|MinSG|MinMax|
|---|---|---|---|---|---|---|---|
|10⁶| | | |10⁶| | | |
|10⁴| | | |10⁴| | | |
|10²| | | |10²| | | |
|avg partition size (bytes)|10⁰|0|300|600|900|1200|0|
| |0.4|0.8|1.2|1.6|2||D|=Ν: x10⁶| |

The partition cost of SG is constant regardless of k, since it calculates the unit length of each cell constantly once k is given. MINMAX is extremely efficient; its partition cost is almost as good as the partition cost of SG. It produces 1,225 partitions for 1 million points in just 20 seconds.

Next, Figure 7(b) shows the partition cost when we vary the size of the database from 0.2 million to 2 million. The partition cost in SG clearly should be linear to N = |D| once it has figured out the unit length of each cell, which is observed in Figure 7(b). Interestingly enough, even though our analysis in Section V-B indicates that the worst case complexity for both MINSG and MINMAX is O(kN²). In practice, both their costs are in fact only linear to N. This is because that the bad case in our analysis, where a cutting line intersects with all O(N) Voronoi cells, is almost impossible in practice. Instead, for both MINSG and MINMAX, in any step a cutting line typically only intersects with a constant number of Voronoi cells. This means that both their costs should be only O(kN) (for a maximum of k possible steps). Also, clearly a cutting line in MINSG expects to intersect with more Voronoi cells than that in MINMAX in any step. Hence, we also see a higher cost in MINSG than the cost of MINMAX, and a faster pace of increase in cost when |D| increases. Figure 7(b) indicates that MINMAX is almost as efficient and scalable as SG. When |D| changes from 0.2 to 2 million points, the partition cost of MINMAX only increases from 5 seconds to 40 seconds.

We then examine the sizes of the partition elements from different methods before applying the random padding operation. Due to the random padding operation to “inflate” every partition element with random bytes to the size smax of the maximum partition element, two values are critical: smax, which decides the storage cost at the server and the communication cost of every query, and the variance of the sizes of partition elements, which decides the overhead of the total “inflation”. Figure 8 plots the average size of partition elements along with smax and smin (the size of the minimum partition element), as the error bar, w.r.t. k and |D|.

All methods produce partitions that have a similar average size. However, SG always has the largest values in both smax and the variance, due to its complete ignorance of the data distribution. MINSG does significantly reduce the value of smax, which is expected since its design is to greedily split the partition element with the maximum size. However, following our analysis in Section V-B, due to the long extent of its cutting lines (always from [−∞, +∞]), its splitting method will potentially lead to partitions of very small size, as observed in Figure 8. The design of MINMAX makes further improvement to MINSG, so it further reduces smax considerably. It also eliminates very small partition elements by limiting a cutting line to be only within the extent for the cell to split (the cell for the current maximum partition element). Hence, MINMAX always produces a balanced partition. As a result, its smax is very close to the average size of all partition elements and the variance is also small, as seen in Figure 8.

Finally, not surprisingly, for all partition methods, the values for both the average size and the smax reduce when more grid cells are used (Figure 8(a)), and increase when D grows (Figure 8(b)). Nevertheless, MINMAX always produces highly balanced partitions with the smallest (much smaller than that from the other two methods) smax values.

# Total running time of the preprocessing step

|total running time (secs)|10³|Send−D|10²| |10¹| | |
|---|---|---|---|---|---|---|---|
|1000|300|600|900|1200|0|0.4|0.8|
| |1.2|1.6|2| ||D|=Ν: x10⁶| | |
| |(a) vary k.|(b) vary |D|.| | | | | |

Figure 9 reports the total running time for the preprocessing step, which includes the costs of both the partition and the encryption (as well as the Voronoi diagram construction and the random padding operation, whose costs are small compared to partition and encryption costs). For reference, we also include the preprocessing cost from the naive method Send-D (see the first paragraph in Section V), whose preprocessing cost is to encrypt D in its entirety as one message.

What is interesting to observe is that, even though SG is fastest in producing its partitions, it becomes the slowest method overall. This is explained by the fact that partitions produced by SG suffer from the largest variance and the largest smax value. After the random padding operation, all partitions share the same size as the maximum partition element. Hence, the value of smax decides the total encryption cost when there are equal number of partitions; and the variance in partition size decides the overhead introduced to the encryption step by the “inflation” of random bytes. Given the results in Figure 8, it is not surprising to see that SG becomes the slowest method, and MINMAX becomes the fastest method (especially when MINMAX also enjoys a partition cost that is almost as good as the partition cost in SG, see Figure 7).

# VII. RELATED WORK

Our study falls into the general category of secure query processing as discussed in Section I. Existing work have

# Figures and Tables

|10¹² SG MinSG MinMax|10¹² SG MinSG MinMax|SG MinSG MinMax| | | | | | | | | | | |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| | |10¹⁰|Send−D||D||10|10|Send−D||D||108|Send−D| | | |
| | | | |10⁷| | | | | | | | | |
|10⁸| | | | | | | | | | | | | |
| | | | |10⁶| | | | | | | | | |
| | | | |10⁵| | | | | | | | | |
|6| | |10⁶| |10⁴|1040| | | | | | | |
| | | | |query communication (bytes)| | | | | | | | | |
| | | |size of all encryptions (bytes)| | | | | | | | | | |
| | |0| |300|600|900|1200|0|0.4|0.8|1.2|1.6|2|
| | | ||D|=Ν: x106| | | | | | | | | | |
|(a) vary k. (b) vary |D|.| | | | | | | | | | | | | |

Fig. 10: Total size of all encrypted partition elements.

Fig. 11: Query communication cost.

| | | |SG|MinSG|MinMax| | | | | | | | |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| | |10¹|Send−D| | | | | | | | | | |
| | | | |10⁰| | | | | | | | | |
| | | | |10−1| | | | | | | | | |
| | | | | |10−2| | | | | | | | |
| | | | |query time (secs)| | | | | | | | | |
| | | | |10−3| | | | | | | | | |
| | |0| |300|600|900|1200|0|0.4|0.8|1.2|1.6|2|
| | | |k| | | | | | | | | | |
|(a) vary k. (b) vary |D|.| | | | | | | | | | | | | |

Fig. 12: Query time for different methods.

Thus, it is natural to see a linear increase w.r.t. k and |D| in the total running time in producing all encrypted partition elements for all SVD methods. However, as shown in Figure 9, MINMAX is at least one order of magnitude faster than SG, and about 3-6 times faster than MINSG. In fact, MINMAX only takes less than 90 seconds to produce all encrypted partition elements with k = 625 over a database with 2 million points as shown in Figure 9(b). Of course, Send-D is fastest, but MINMAX’s overhead compared to Send-D is small.

We also examined the total size of all encrypted partition elements. It affects both the communication cost from the data owner to the server and the storage cost at the server. After the random padding operation, each partition element has a size of smax; hence, this value is simply kemax, assuming emax is the size of the ciphertext for a message of size smax encrypted under the secure encryption scheme E used. Figure 10 shows the total size of all encrypted partition elements for all methods. We can view Send-D as a method with only one partition element to encrypt, which is D itself. For reference, we also include the size of D. Clearly, the total size only increases linearly with |D| in all methods; it also increases linearly with k in all SVD methods. Among the three SVD methods, MINMAX is the clear winner, which again is due to the smallest smax value it achieves (see Figure 8). All methods introduce a owner-server communication and server storage overheads compared to using the database D itself. However, MINMAX’s overhead is almost as small as that from the naive method Send-D which has the smallest such overheads one can hope for.

Finally, the client’s storage cost is dependent only on the size of the description for all grid cells as shown in Section V-C, which is O(k) for all three SVD methods, regardless of the size of the database and the sizes of partition elements! Since typical k values are very small compared to the database size (having few hundred grid cells is good enough for a few million points), this cost is almost negligible.

Lastly, we do not observe any significant difference from the TX datasets. Hence, we omit all results from TX for brevity.

Query processing cost. Recall that for a query q, the client locally figures out the identifier for the grid cell that contains q, using the description of all grid cells she has; then she simply requests the server to return the corresponding, encrypted partition element. But due to the random padding operation, each encrypted partition element has the same size, emax, which is the size of the encryption for a message of size smax (the size of the maximum partition element) under the secure encryption scheme. For each experiment, we generate 100 random queries and report the average in Figure 12. Figure 12(a) shows that the query costs of all SVD methods reduce when k increases, due to smaller number of points in the partition element returned. However, MINMAX enjoys the best improvement when k increases. This is because we report the average query cost and it produces the most balanced partition elements. All SVD methods outperform the naive method Send-D in all k values. In fact, MINMAX is faster by 2-3 orders of magnitude than Send-D, and by 1-2 orders of magnitude than SG. When |D| increases, the query time of all methods increases linearly with |D| as shown in Figure 12(b). Nevertheless, MINMAX still has the best performance, which is 3 orders of magnitude faster than Send-D, and 2 orders of magnitude faster than SG. When D has 2 million points, with 625 partitions MINMAX’s query time at client is as little as 10−2 second.

examined the problems of answering basic SQL queries [11], nearest neighbors, nearest neighbors in non-euclidean space executing aggregate queries [13], [16], and performing range queries [14], [19], over an encrypted database. As shown by existing studies [14], [15], [19], [21], special treatments are often required for more complex query types, to meet the security requirements and/or achieve better efficiency. In particular, research effort [15], [21] has been made to address the SNN problem; the solutions thus proposed, however, are insecure and can be attacked efficiently, as we have demonstrated. Secure query processing (including the SNN problem) is related to but different from another well known problem called private information retrieval (PIR) [3], [10], [20]. In PIR, the objective is to prevent the server from knowing anything about which records have been retrieved/accessed by a user query, while the server is allowed to know all of the tuples in the database. In particular, using PIR for answering NN queries has been studied in [10], [17], but the solutions thus proposed only protect the privacy of user queries, without preventing the server from knowing the content of the database. For similar reasons, our problem is also different from privacy issues in location-based services [2], [4], [7].

Our reduction from OPE to SNN (which shows the hardness of the SNN problem) leverages on the concept of order-preserving-encryption, which was first proposed in [1]. However, the OPE schemes proposed in [1] did not come with any formal analysis on their security guarantees. It was until recently that the formal security analysis on the general concept of OPE schemes has surfaced from the cryptography community [5], [6]. In particular, it is proven that it is impossible to construct secure OPE schemes in standard security models (see Section IV and [5], [6] for details).

Our partitioning schemes share some similar motivation from the design of indexing methods based on Voronoi diagram, e.g., [18]. However, our methods must adhere to the specific partitioning policy derived based on the particular security and efficiency constraints to the SNN problem, which makes our study here different from existing work. Lastly, as discussed in Section V-A, the basic method SG was used in a different context for answering spatial queries using PIR techniques. However, as shown by our study, we have proposed new partitioning schemes, MINSG and MINMAX that significantly outperform SG in terms of both the size of the maximum partition element and how balance the sizes of different partition elements are.

# VIII. CONCLUSION

This work revisits the secure nearest neighbor problem. We show the insecurity of existing solutions, and the hardness of the SNN problem. We then design a new partition-based secure Voronoi diagram (SVD) method. The SVD method is as secure as the encryption function it uses, and any standard secure encryption schemes can be employed by the SVD method. Extensive experiments clearly demonstrate the efficiency and the scalability of the SVD method. Future work include extending our investigation to higher dimensions, k

# ACKNOWLEDGMENT

Bin Yao was supported by the NSFC (No. 61202025) and the 863 Program of China (No. 2011AA01A202). Feifei Li was supported by NSF Grant CNS-0831278. Xiaokui Xiao was supported by the Nanyang Technological University’s SUG Grant M58020016, and by Agency for Science, Technology, and Research (Singapore) under SERC Grant 102-158-0074.

# REFERENCES

[1] R. Agrawal, J. Kiernan, R. Srikant, and Y. Xu. Order preserving encryption for numeric data. In SIGMOD, 2004.

[2] C. A. Ardagna, M. Cremonini, E. Damiani, S. D. C. di Vimercati, and P. Samarati. Location privacy protection through obfuscation-based techniques. In DBSec, 2007.

[3] D. Asonov and J. C. Freytag. Almost optimal private information retrieval. In Privacy Enhancing Technologies, 2002.

[4] C. Bettini, S. Jajodia, P. Samarati, and X. S. Wang, editors. Privacy in Location-Based Applications, Research Issues and Emerging Trends, Lecture Notes in Computer Science. Springer, 2009.

[5] A. Boldyreva, N. Chenette, Y. Lee, and A. O’Neill. Order-preserving symmetric encryption. In EUROCRYPT, 2009.

[6] A. Boldyreva, N. Chenette, and A. O’Neill. Order-preserving encryption revisited: Improved security analysis and alternative solutions. In CRYPTO, 2011.

[7] C.-Y. Chow, M. F. Mokbel, and W. G. Aref. Casper*: Query processing for location services without compromising privacy. ACM TODS, 34(4), 2009.

[8] M. de Berg, O. Cheong, M. van Kreveld, and M. Overmars. Computational Geometry: Algorithms and Applications. Springer, 3rd edition, 2008.

[9] J. Domingo-Ferrer. A provably secure additive and multiplicative privacy homomorphism. In ISC, 2002.

[10] G. Ghinita, P. Kalnis, A. Khoshgozaran, C. Shahabi, and K.-L. Tan. Private queries in location based services: anonymizers are not necessary. In SIGMOD, 2008.

[11] H. Hacigümüs, B. R. Iyer, C. Li, and S. Mehrotra. Executing SQL over encrypted data in the database service provider model. In SIGMOD, 2002.

[12] H. Hacigümüs, B. R. Iyer, and S. Mehrotra. Providing database as a service. In ICDE, 2002.

[13] H. Hacigümüs, B. R. Iyer, and S. Mehrotra. Efficient execution of aggregation queries over encrypted relational databases. In DASFAA, 2004.

[14] B. Hore, S. Mehrotra, M. Canim, and M. Kantarcioglu. Secure multidimensional range queries over outsourced data. VLDBJ. To Appear.

[15] H. Hu, J. Xu, C. Ren, and B. Choi. Processing private queries over untrusted data cloud through privacy homomorphism. In ICDE, 2011.

[16] E. Mykletun and G. Tsudik. Aggregation queries in the database-as-a-service model. In DBSec, 2006.

[17] S. Papadopoulos, S. Bakiras, and D. Papadias. Nearest neighbor search with strong location privacy. PVLDB, 3(1):619–629, 2010.

[18] M. Sharifzadeh and C. Shahabi. VoR-Tree: R-trees with voronoi diagrams for efficient processing of spatial nearest neighbor queries. PVLDB, 2010.

[19] E. Shi, J. Bethencourt, H. T.-H. Chan, D. X. Song, and A. Perrig. Multi-dimensional range query over encrypted data. In IEEE Symposium on Security and Privacy, 2007.

[20] P. Williams and R. Sion. Usable pir. In NDSS, 2008.

[21] W. K. Wong, D. W.-L. Cheung, B. Kao, and N. Mamoulis. Secure knn computation on encrypted databases. In SIGMOD, 2009.

[22] B. Yao, F. Li, and X. Xiao. Secure nearest neighbor revisited. Technical report, http://www.cs.utah.edu/∼lifeifei/papers/snn.pdf.

