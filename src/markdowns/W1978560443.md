# Modeling the Psychology of Consumer and Firm Behavior with Behavioral Economics

TECK H. HO, NOAH LIM, and COLIN F. CAMERER*

Marketing is an applied science that tries to explain and influence how firms and consumers behave in markets. Marketing models are usually applications of standard economic theories, which rely on strong assumptions of rationality of consumers and firms. Behavioral economics explores the implications of the limits of rationality, with the goal of making economic theories more plausible by explaining and predicting behavior more accurately while maintaining formal power. This article reviews six behavioral economics models that are useful to marketing. Three models generalize standard preference structures to allow for sensitivity to reference points and loss aversion, social preferences toward outcomes of others, and preference for instant gratification. The other three models generalize the concept of game-theoretic equilibrium, allowing decision makers to make mistakes, encounter limits on the depth of strategic thinking, and equilibrate by learning from feedback. The authors also discuss a specific marketing application for each of these six models. The goal of this article is to encourage marketing researchers to apply these models. Doing so will raise technical challenges for modelers and will require thoughtful input from psychologists who study consumer behavior. Consequently, such models could create a common language both for modelers who prize formality and for psychologists who prize realism.

# Introduction

Economics and psychology are the two most influential disciplines that underlie marketing. Both disciplines are used to develop models and establish facts to understand how firms and customers actually behave in markets and to give advice to managers. Although both disciplines have the common goal of understanding human behavior, relatively few marketing studies have integrated ideas from the two disciplines. This article reviews some of the recent research developments in “behavioral economics,” an approach that integrates psychological insights into formal economic models. Behavioral economics has been applied fruitfully in business disciplines such as finance (Barberis and Thaler 2003) and organizational behavior (Camerer and Malmendier, in press). This review shows how ideas from behavioral economics can be used in marketing applications to link the psychological approach of consumer behavior to the economic models of consumer choice and market activity. Because behavioral economics is growing too rapidly to survey thoroughly in an article of this sort, we concentrate on six topics. Three of the topics are extensions of the classical utility function, and three of the topics are new methods.

# Author Information

*Teck H. Ho is William Halford Jr. Family Professor of Marketing, Haas School of Business, University of California, Berkeley (e-mail: hoteck@haas.berkeley.edu). Noah Lim is Assistant Professor of Marketing, CT Bauer College of Business, University of Houston (e-mail: noahlim@uh.edu). Colin F. Camerer is Axline Professor of Business Economics, California Institute of Technology (e-mail: camerer@hss.caltech.edu). This research is partially supported by a National Science Foundation grant (No. SBR 9730187). The authors thank Wilfred Amaldoss, Juin-Kuan Chong, Drew Fudenberg, Botond Koszegi, George Loewenstein, John Lynch, Robert Meyer, Drazen Prelec, and Matt Rabin for their encouragement and helpful comments. They are especially grateful to the late journal editor, Dick Wittink, for inviting and encouraging them to undertake this review. Dick was a great supporter of interdisciplinary research. The authors hope that this review can honor his influence and enthusiasm by spurring research that spans both marketing and behavioral economics.

# Footnotes

1. Marketing is inherently an applied field that is always interested in both the descriptive question of how actual behavior occurs and the prescriptive question of how behavior can be influenced to meet a certain business objective.

© 2006, American Marketing Association

Journal of Marketing Research

ISSN: 0022-2437 (print), 1547-7193 (electronic)

Vol. XLIII (August 2006), 307–331

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

ods of game-theoretic analysis that are alternatives to the standard Nash equilibrium (hereinafter NE) analysis. We describe a specific marketing application for each idea. It is important to emphasize that the behavioral economics approach extends rational choice and equilibrium models; it does not advocate abandoning these models entirely. All the new preference structures and utility functions we describe here generalize the standard approach by adding one or two parameters, and the behavioral game theories generalize standard equilibrium concepts in many cases as well. Adding parameters allows us to detect when the standard models work well and when they fail and to measure empirically the importance of extending the standard models. When the standard methods fail, these new tools can be used as default alternatives to describe and influence markets. Furthermore, there are usually many delicate and challenging theoretical questions about model specifications and implications that will engage modelers and lead to progress in this growing research area.

# DESIRABLE PROPERTIES OF MODELS

Our view is that models should be judged according to whether they have four desirable properties: generality, precision, empirical accuracy, and psychological plausibility. The first two properties, generality and precision, are prized in formal economic models. For example, the game-theoretical concept of NE applies to any game with finitely many strategies (it is general) and gives exact numerical predictions about behavior with zero free parameters (it is precise). Because the theory is sharply defined mathematically, little scientific energy is spent debating what its terms mean. A theory of this sort can be taught around the world and used in different disciplines (ranging from biology to political science), so that scientific understanding and cross-fertilization accumulates rapidly.

In general, the third and fourth desirable properties that models should have, empirical accuracy and psychological plausibility, have been given more weight in psychology than in economics, that is, until behavioral economics came along. For example, in building a theory of price dispersion in markets from an assumption about consumer search, whether the consumer search assumption accurately describes experimental data (for example) is often considered irrelevant in judging whether the theory of market prices built on that assumption might be accurate (as Milton Friedman [1953] influentially argues, a theory’s conclusions might be reasonably accurate, even if its assumptions are not). Similarly, until recently, whether an assumption is psychologically plausible—that is, consistent with how brains work and with data from psychology experiments—has not been considered a good reason to accept or reject an economic theory.

The goal in behavioral economics modeling is to have all four properties, insisting that models have both the generality, precision, empirical accuracy, and psychological plausibility simultaneously with behavioral economics models.

# SIX BEHAVIORAL ECONOMICS MODELS AND THEIR APPLICATIONS TO MARKETING

Table 1 shows the three generalized utility functions and the three alternative methods of game-theoretic analysis that are the focus of this article. Under the generalized preference structures, decision makers care about both the final outcomes and the changes in outcomes with respect to a reference point and are loss averse. They are not purely self-interested and care about others’ payoffs. They exhibit a taste for instant gratification and are not exponential discounters, as is commonly assumed. The new methods of game-theoretic analysis allow decision makers to make mistakes, encounter surprises, and learn in response to feedback over time. We also suggest how these new tools can increase the validity of marketing models with specific marketing applications.

This article makes three contributions:

1. It describes some important generalizations of the standard utility function and robust alternative methods of game-theoretic analysis. These examples show that it is possible to achieve generality, precision, empirical accuracy, and psychological plausibility simultaneously with behavioral economics models.

There are several reviews of the behavioral economics area aimed at the economics audience (Camerer 1999; McFadden 1999; Rabin 1998, 2002). Camerer, Loewenstein, and Rabin (2003) compile a list of key readings in behavioral economics and Camerer and colleagues (2003) discuss the policy implications of bounded rationality. Our review reads more like a tutorial and is different in that we show how these new tools can be used and applied to typical problem domains in marketing.

# Modeling the Psychology of Consumer and Firm Behavior

# Table 1

# SIX BEHAVIORAL ECONOMICS MODELS

|Behavioral Regularities|Standard Assumptions|New Specification (Reference Example)|New Parameters (Behavioral Interpretation)|Marketing Application|
|---|---|---|---|---|
|Generalized Utility Functions|Expected utility hypothesis|Reference-dependent preferences (Kahneman and Tversky 1979)|ω (weight on transaction utility) μ (loss-aversion coefficient)|Business-to-business pricing contracts|
| |Pure self-interest|Inequality aversion (Fehr and Schmidt 1999)|γ (envy when others earn more) η (guilt when others earn less)|Sales force compensation|
|Impatience and taste for instant gratification|Exponential discounting|Hyperbolic discounting (Laibson 1997)|β (preference for immediacy, “present bias”)|Price plans for gym memberships|
|New Methods of Game-Theoretic Analysis|Best-response property|Quantal response equilibrium (McKelvey and Palfrey 1995)|λ (better-response sensitivity)|Price competition with differentiated products|
|Rational expectations hypothesis|Cognitive hierarchy (Camerer, Ho, and Chong 2004)|τ (average number of thinking steps)| |Market entry|
| |Instant equilibration|Self-tuning EWA (Ho, Camerer, and Chong, in press)|λ (better-response sensitivity)|Lowest-price guarantees|
|aThere are two additional behavioral parameters φ (change detection, history decay) and ξ (attention to forgone payoffs, regret) in the self-tuning EWA model. These parameters do not need to be estimated; they are calculated on the basis of feedback.| | | | |

Notes: EWA = experience-weighted attraction.

It demonstrates how each generalization and new method of game-theoretic analysis works with a concrete marketing application example. In addition, we show how these new tools can influence how a firm makes its price, product, promotion, and distribution decisions with examples of further potential applications.

It discusses potential research implications for behavioral and modeling researchers in marketing. We believe that this new approach is a sensible way to integrate research between consumer behavior and economic modeling.

We organize the rest of the article as follows: First, we discuss each of the six models listed in Table 1 and describe an application example in marketing. Second, we extend the discussion on how these models have been and can be applied in marketing. Third, we discuss research implications for behavioral researchers and (both empirical and analytical) modelers. We designed the article to be appreciated by two audiences. We hope that psychologists, who are uncomfortable with broad mathematical models and suspicious of how much rationality is ordinarily assumed in such models, will appreciate how relatively simple models can capture psychological insight. We also hope that mathematical modelers will appreciate the technical challenges in testing these models and, in extending them, will use the power of deeper mathematics to generate surprising insights into marketing.

A classic example that demonstrates reference dependence and loss aversion is the “endowment effect” experiment (Thaler 1980). In this experiment, one group of participants is endowed with a simple consumer good, such as a coffee mug or an expensive pen. Those who are endowed with the good are asked the least amount of money they...

310 JOURNAL OF MARKETING RESEARCH, AUGUST 2006

would accept to sell the good, and those who are not compromise effect (Kivetz, Netzer, and Srinivasan 2004; Simonson 1989; Simonson and Tversky 1992; Tversky and Simonson 1993), and can account for the large premium in returns to equities relative to bonds and the surprisingly few number of announcements of negative corporate earnings and negative year-to-year earnings changes. Cab drivers appear to be averse to “losing” by falling short of a daily income target (reference point), so they supply labor until they hit that target. Disposition effects refer to the tendency to hold on to money-losing assets (housing and stocks) too long rather than sell and recognize accounting losses. Loss aversion also appears at industry levels, creating “antitrade bias” and in micro decisions of monkeys trading tokens for food rewards.

# The Generalized Model

The aforementioned evidence suggests that a realistic model of preferences should capture the following two empirical regularities:4

4See also Tversky and Kahneman (1991). There is a third feature of reference dependence, called the “reflection effect,” which we do not discuss. The reflection effect posits that decision makers are risk averse in gain domains and risk seeking in loss domains.

# Table 2

SOME EVIDENCE OF REFERENCE DEPENDENCE AND LOSS AVERSION

|Economic Domain|Study|Type of Data|Estimated Loss-Aversion Coefficienta|
|---|---|---|---|
|Instant endowment effects for goods|Kahneman, Knetsch, and Thaler (1990)|Field survey, goods experiments|2.29|
|Choices over money gambles|Kahneman and Tversky (1992)|Choice experiments|2.25|
|Loss aversion for goods relative to money|Bateman et al. (2005)|Choice experiments|1.30|
|Asymmetric price elasticities|Putler (1992)|Supermarket scanner data|2.40|
| |Hardie, Johnson, and Fader (1993)| |1.63|
|Loss aversion relative to initial seller “offer”|Chen, Lakshminarayanan, and Santos (2005)|Capuchin monkeys trading tokens for stochastic food rewards|2.70|
|Aversion to losses from international trade|Tovar (2004)|Nontariff trade barriers, U.S. industries in 1983|1.95–2.39|
|Reference dependence in distribution channel pricing|Ho and Zhang (2004)|Bargaining experiments|2.71|
|Equity premium puzzle|Benartzi and Thaler (1995)|U.S. stock returns|n.r.|
|Surprisingly few announcements of negative EPS and negative year-to-year EPS changes|Degeorge, Patel, and Zeckhauser (1999)|EPS changes from year to year for U.S. firms|n.r.|
|Disposition effects in housing and stocks|Genesove and Mayer (2001)|Boston condo prices 1990–1997|n.r.|
| |Odean (1998)|Individual investor stock trades| |
| |Weber and Camerer (1998)|Stock trading experiments| |
|Daily income targeting by New York City cab drivers|Camerer et al. (1997)|Observations of daily hours and wages|n.r.|
|Consumption: aversion to period utility loss|Chua and Camerer (2004)|Savings–consumption experiments|n.r.|

aWe discuss the loss-aversion coefficient in detail in the subsection “The Generalized Model.”

Notes: n.r. indicates that the studies did not estimate the loss-aversion coefficient directly. EPS = earnings per share.

# Modeling the Psychology of Consumer and Firm Behavior

1. Outcomes are evaluated as changes with respect to a reference point. Positive changes are framed as gains, and negative changes are framed as losses.

2. Decision makers are loss averse. That is, losses generate proportionally more disutility than equal-sized gains.

Prospect theory (Kahneman and Tversky 1979) is the first formal model of choice to capture these empirical regularities. Extending this insight, Koszegi and Rabin (2004) model individual utility u(x|r) so that it depends on both the final outcome (x) and a reference point (r). Specifically, u(x|r) is defined as

(1) u(x|r) ≡ v(x) + t(x|r),

where v(x) represents the intrinsic utility associated with the final outcome (independent of the reference point) and t(x|r) is the transaction or change utility associated with gains and losses relative to the reference point r. This model generalizes the neoclassical utility function by incorporating a transaction component into the utility function. If t(x|r) = 0, the general function reduces to the standard one used in rational choice theory. An important question is how the reference point is determined. In general, we use the typical assumption that the reference point reflects the status quo before a transaction, but richer and more technically interesting approaches are worth studying.

We assume that v(x) is concave in x. For example, the intrinsic utility can be a power function given by v(x) = x0.5. In Koszegi and Rabin’s (2004) formulation, t(x|r) is assumed to have several simple properties. We assume that t(x|r) = t(x – r) and define t(y) = t(x|r) to economize on notation. The crucial property of t(y) is

t'(0) ≡ μ > 1, where t'(0) ≡ limy→0 t'(|y|) and t'(0) ≡ limy→0 t'(-|y|).

The parameter μ is the loss-aversion coefficient; it measures the marginal utility of going from a small loss to zero, relative to the marginal utility of going from zero to a small gain. In a conventional (differentiable) utility function μ = 1. If μ > 1, there is a “kink” at the reference point.

A simple t(y) function that satisfies the Koszegi-Rabin properties is

t(y) = ω × v(y) if y ≥ 0,

t(y) = −μ × ω × v(|y|) if y < 0,

where ω > 0 is the weight on the transaction utility relative to the intrinsic utility v(x) and μ is the loss-aversion coefficient.

This reference-dependent utility function can be used to explain the endowment effect. Suppose that a decision maker has preferences for amounts of pens and dollars, denoted x = (xp, xd). Because there are two goods, the reference point will also have two dimensions, r = (rp, rd). Because the choice involves two dimensions, a simple model is to assume that the intrinsic utilities for pens and dollars can be evaluated separately and added up so that v(x) = v(xp) + v(xd). For simplicity, let k = 1, so that v(xp) = bxp and v(xd) = xd, where b > 0 represents the relative preference for pens over dollars. Make the same assumption for the transactional components of utility, t(x|r) = t(y) = t(yp) + t(yd), where yp = xp – rp and yd = xd – rd. The decision results in the three treatments, when ω > 0 and μ > 1, the prices are ranked PC > PS > PB because (b[1 + μω])/(1 + ω) > b > (b[1 + ω])/(1 + μω). That is, selling prices are higher than choosing prices, which are higher than buying prices. However, note that if either ω = 0 (transaction utility does not matter) or μ = 1 (there is no loss aversion), all three prices are equal to the value of the pen b, so there is no endowment effect.

5 In the power form, v(x) = –xk if x is negative.

# Marketing Application: Business-to-Business Pricing

A classic problem in channel management is the “channel coordination” or “double marginalization” (DM) problem. Suppose that an upstream firm (a manufacturer) offers a downstream firm (a retailer) a simple linear price contract, charging a fixed price per unit sold. This simple contract creates a subtle inefficiency: When the manufacturer and the retailer maximize their profits independently, the manufacturer does not account for the externality of its pricing decision on the retailer’s profits. If the two firms become vertically integrated so that the manufacturing division in the merged firm sells to the retailing division using an internal transfer price, the profits of the merged firm would be higher than the total profits of the two separate firms because the externality becomes internalized.

Moorthy (1987) had the important insight that even when the manufacturer and the retailer operate separately, the total channel profits can be equal to that attained by a vertically integrated firm if the manufacturer offers the retailer a two-part tariff (TPT) that consists of a lump-sum fixed fee F and a marginal wholesale per-unit price w. In this simplest of nonlinear pricing contracts, the manufacturer should set w at its marginal cost. Marginal-cost pricing eliminates the externality and induces the retailer to buy the optimal quantity. However, marginal-cost pricing does not enable the manufacturer to make any profits, but setting a fixed fee F does. The retailer then earns (p – w) × q – F, which is the markup on each of q units sold less the fee F.

Ho and Zhang (2004) conducted the first experiments on the use of TPTs in a channel and studied their behavioral consequences. The results show that contrary to the theoretical prediction, channel efficiency (the total profits of the two separate firms compared with the theoretical 100% benchmark for the vertically integrated firm) is only 66.7%. The standard theoretical predictions and some experimental statistics appear in Table 3. These data show that the fixed fees F are too low compared with the theoretical prediction (actual fees are approximately 5, whereas theory predicts 16). Because F is too low, to maintain profitability, the manufacturers must charge a wholesale price w, which is too high (charging approximately 4 rather than the marginal cost of 2). As a result, retailers often reject the contract offers.

The reference-dependence model we described previously can explain the deviations of the experimental data from the theoretical benchmark. The main intuition is that retailers suffer an immediate loss from the fixed fee F but perceive later gains from selling above the wholesale price w that they are charged. Specifically, the retailer’s transaction utility occurs in two stages with a TPT. In the first stage, the retailer begins with a reference profit of zero but is loss averse with respect to paying the fixed fee F. Its transaction utility, if it accepts the contract, is simply – ω × μ × F, where ω and μ are as we defined them previously. In the second stage, the retailer realizes a final profit of (p – w) × q – F, which represents a gain of (p – w) × q relative to a reference point of –F (its new reference point after the first stage). Thus, its transaction utility in the second stage is ω × ((p – w) × q). The retailer’s overall utility is the intrinsic utility from its net profit (p – w) × q – F in the entire game plus the two components of transaction utility, –ω × μ × F and ω × ((p – w) × q). Adding all three terms gives the retailer a utility of:

uR = (1 + ω) (p – w) × q – F

Note that when ω = 0, the reference-dependent model reduces to the standard economic model, and utility is just the profit of (p – w) × q – F. When μ = 1 (no loss aversion), the model simply scales up retailer profit by a multiplier (1 + ω), which reflects the hedonic value of an above-reference-point transaction. When there is loss aversion (μ > 1), however, the retailer’s perceived loss after paying the fee F has a disproportionate influence on overall utility. Using the experimental data, Ho and Zhang (2004) estimated the fixed-fee multiplier (1 + ω × μ)/(1 + ω) to be 1.57, which is much larger than the 1.0 that standard theory predicts, with ω = 0 or μ = 1. Given this estimate, Table 3 shows the predictions of crucial empirical statistics, which, in general, match the wholesale and retail prices (w and p), the fees F, and the contract rejection rate reasonably well. A value of ω = .5 implies a loss aversion coefficient of 2.71.

# SOCIAL PREFERENCES

# Behavioral Regularities

Standard economic models usually assume that people are purely self-interested; that is, they care only about earning the most money for themselves. Self-interest is a useful simplification, but it is a poor assumption in many cases. Self-interest cannot explain why decision makers seem to care about fairness and equality, are willing to give up money to achieve more equal outcomes, or punish others for actions perceived as selfish or unfair. This type of behavior points to the existence of social preferences, which defines a person’s utility as a function of his or her own payoff and others’ payoffs.

The existence of social preferences can be demonstrated in an “ultimatum” price-posting game. In this game, a monopolist retailer sells a product to a customer by posting a price p. The retailer’s marginal cost for the product is $0.

**PREDICTIONS AND EXPERIMENTAL RESULTS FOR MODEL WITH TPT**
|Decisions|Standard Theoretical Predictiona|Experimental Data (M)|Reference-Dependence Prediction|
|---|---|---|---|
|Wholesale price w|2|4.05|4.13|
|Fixed fee F|16|4.61|4.65|
|Reject contract? (%)|0|28.80|34.85|
|Retail price p|6|6.82|7.06|

aMarginal cost of the manufacturer is 2, and demand is q = 10 – p in the experiment.

# Modeling the Psychology of Consumer and Firm Behavior

and the customer’s willingness to pay for the product is $1. The game proceeds as follows: The retailer posts a price p ∈ [0, 1], and the customer chooses whether to buy the product. If the customer buys, consumer surplus is given by 1 – p, and the retailer’s profit is p; if the customer chooses not to buy, each party receives a payoff of zero. If both parties are purely self-interested and care only about their own payoffs, the unique subgame perfect equilibrium to this game would be for the retailer to charge p = $.99 (assuming that the smallest unit of money is a penny), anticipating that the customer accepts the price and earns a penny of surplus. Many experiments have been conducted to test the validity of this prediction in such ultimatum games (Camerer 2003, Ch. 2). The results are markedly different from the prediction of the pure self-interested model and are characterized by three empirical regularities: (1) The average prices are in the region of $.60 to $.70, with the median and modal prices in the interval [$.50, $.60]; (2) there are hardly any prices greater than $.90, and very high prices often result in no purchases (rejections) (e.g., prices of $.80 and higher yield no purchases about half the time); and (3) there are almost no prices in the range of p < $.50; that is, the retailer rarely gives more surplus to the consumer than to itself.

These results can be explained easily as follows: Customers have social preferences, which lead them to sacrifice part of their own payoffs to punish what they consider an unfair price, particularly when the retailer’s resulting monetary loss is greater than that of the customer. The retailer’s behavior can be attributed to both social preferences and strategic behavior; that is, either retailers dislike creating unequal allocations or they are selfish but rationally anticipate the customers’ concerns for fairness and lower their prices to maximize profits.

# The Generalized Model

A way to capture concerns about fairness mathematically is to apply models of inequality aversion. These models assume that decision makers are willing to sacrifice to achieve more equitable outcomes if they can. Fehr and Schmidt (1999) formalize a simple model of inequity aversion in terms of differences in players’ payoffs. Their model puts different weights on the payoff difference, depending on whether the other player earns more or less. For the two-player model (denoted as Players 1 and 2), the utility of Player 1 is given by

u1(x1, x2) = ⎧x1 − η × (x1 − x2),  x1 > x2

⎨ x1 − γ × (x2 − x1) x2 > x1

⎩

where γ ≥ η and 0 ≤ η < 1. In this utility function, γ captures the loss from disadvantageous inequality (envy), and η represents the loss from advantageous inequality (guilt). For example, when γ = .5 and Player 1 is behind, he or she is willing to give up a dollar only if it reduces Player 2’s payoffs by $3 or more (because the loss of $1 is less than the reduction in envy of 2γ). Correspondingly, if η = .5 and Player 1 is ahead, he or she is just barely willing to give away enough to Player 2 to make them even (because giving away $x reduces the disparity by $2x and thus changes utility by –x + η × 2 × x). The assumption that γ ≥ η captures the fact that envy is stronger than guilt. If γ = η = 0, the preceding model reduces to the standard pure self-interest model.

To assess how this model can explain the empirical regularities of the ultimatum price-posting game, suppose that both the retailer and the customer have inequity-averse preferences that are characterized by the specific parameters (γ, η). Recall that if both of them are purely self-interested (i.e., γ = η = 0), the retailer will charge the customer $.99, which the customer will accept. However, suppose that we observe the customer reject a price of $.90. In this case, we know that γ must be greater than .125 if customers are rational (because rejecting earns 0, which is greater than .1 – γ(.9 – .1) if and only if γ > .125). What is the equilibrium outcome predicted by this model? Customers with envy parameter γ are indifferent to rejecting a price offer of p* = (1 + γ)/(1 + 2γ). (Rejecting gives 0 – γ(0 – 0), and accepting gives 1 – p – γ[p – (1 – p)]; setting these two expressions to be equal gives p*.) If we assume that retailers do not feel too much guilt (i.e., η < .5), retailers will want to offer a price that customers will just accept. Therefore, their optimal price is p* = (1 + γ)/(1 + 2γ). If γ = .5, for example, the retailer’s maximum price is $.75. This ceiling price is consistent with the empirical observations that p typically ranges from $.50 to $.70 and that very low offers are rejected. The model can also explain why almost no retailer charges less than $.50, namely, because doing so results in less profit and more envy.

Inequality aversion models are easy to use because a modeler can simply substitute inequality-adjusted utilities for terminal payoffs in a game tree and use standard equilibrium concepts. Many other models of social preferences have been proposed. For example, Charness and Rabin (2002) suggest a model in which players care about their own payoffs, the minimum payoff, and the total payoff. In a two-player game, this model reduces to Fehr and Schmidt’s (1999) form, but in multiplayer games, it can explain why one “do-gooder” player may sacrifice a small amount to create social efficiency.

# Marketing Application: Sales Force Compensation

The literature on sales force management has focused mainly on how a manager should structure compensation plans for a salesperson. If the effort level of the salesperson cannot be contracted on or is not fully observable, a self-interested salesperson will always want to shirk (provide the minimum level of effort) if effort is costly. Thus, the key

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

objective for the manager (principal) revolves around designing incentive contracts (ICs) that prevent moral hazard by the salesperson (agent) (Basu et al. 1985). Inequality aversion and reciprocity complicate this simple view. If agents feel guilt or repay kindness with reciprocal kindness, they will not shirk as often as models that assume self-interest predict. Fehr, Klein, and Schmidt (2004) suggest that incentive contracts that are designed to prevent moral hazard do not work as well as implicit bonus contracts (BCs) if there is a proportion of managers and salespeople who care about fairness.

In Fehr, Klein, and Schmidt’s (2004) model, the manager can choose to offer the salesperson either of two contracts: a BC or an IC. The salesperson’s effort e is observable, but any contract on effort must be verified by a monitoring technology, which is costly. The costs of effort c(e) are assumed to be convex (for experimental parameters, see Table 4).

Under the BC, the manager offers a contract (w, e*, b*), where w is a prepaid wage, e* is a requested effort level, and b* is a promised bonus for the salesperson. However, both requested effort and the promised bonus are not binding, and there is no legal or reputational recourse. If the salesperson accepts the contract, he or she earns the wage w immediately and chooses an effort e in the next stage. In the last stage, the manager observes effort e accurately and decides whether to pay an actual bonus b ≥ 0 (which can be less than or even greater than the promised bonus b*). The payoffs for the manager and the salesperson under the BC are πM = 10 × e – w – b and πS = w – c(e) + b, respectively.

Under the IC, the manager can choose whether to invest K = 10 in the monitoring technology. If the manager does, he or she offers the salesperson a contract (w, e*, f) that consists of a wage w, a demanded effort e*, and a penalty f. The penalty f (which is capped at a maximum of 13 in this model) is automatically imposed if the manager verifies that the salesperson has shirked (e < e*). Although the monitoring technology is perfect when it works, it works only one-third of the time. With the IC, the expected payoffs for the manager and the salesperson if the manager invests in the monitoring technology are:

πM = 10 × e − w − K, πS = w − c(e) if e ≥ e*, and πM = 10 × e − w − K − 0.33f, πS = w − c(e) − 0.33f if e < e*.

There is a large gain from exchange in this game if salespeople can be trusted to choose high effort. A marginal increase in one unit of effort earns the manager an incremental profit of 10 but costs the agent only 1 to 4 units. Therefore, the first-best outcome in this game is for the manager to forgo investing in the monitoring technology and for the salesperson to choose e = 10, giving a combined surplus of 10 × e – c(e) = 80. Under the IC, the optimal contract would be (w = 4, e* = 4, f = 13), resulting in πM = 26 and πS = 0. Under the BC, a self-interested manager will never pay any bonus in the last stage. Because the salesperson knows this, he or she will choose e = 1. Therefore, the optimal contract will be (w = 0, e* = 1, b* = 0), yielding πM = 10 and πS = 0. Thus, if the manager has a choice between the two contracts, standard economic theory predicts that the manager will always choose the IC over the BC. Intuitively, if managers do not expect the salespeople to believe their bonus promises and think that salespeople will shirk, they are better off asking for a modest enough effort (e = 4), enforced by a probabilistic fine in the IC, so that the salespeople will put forth some effort.

Fehr, Klein, and Schmidt (2004) asked a group of participants (acting as managers) first to choose a contract form (either IC or BC) and then to make offers using that contract form to another group of participants (acting as salespeople). On accepting a contract offer from a manager, a salesperson chose his or her effort level.

**Table 4: EFFORT COSTS FOR SALESPERSON**
|e|1|2|3|4|5|6|7|8|9|10|
|---|---|---|---|---|---|---|---|---|---|---|
|c(e)|0|1|2|4|6|8|10|13|16|20|

| |IC| |BC| |
|---|---|---|---|---|
|Prediction|Actual (M)|Prediction|Actual (M)| |
|Managers’ Decisions| | | | |
|Choice (%)|100|11.6|0|88.4|
|Wage|4|24.0|0|15.2|
|Effort requested|4|5.7|1|6.7|
|Fine|13|10.6|n.a.|n.a.|
|Bonus offered|n.a.|n.a.|0|25.1|
|Bonus paid|n.a.|n.a.|0|10.4|
|Salespeople’s Decisions| | | | |
|Effort|4|2.0|1|5.0|
|Outcomes| | | | |
|πM|26|–9.0|10|27.0|
|πS|0|14.4|0|17.8|

Notes: n.a. = not applicable.

# Modeling the Psychology of Consumer and Firm Behavior

theoretical predictions and the actual results of the data collected using standard experimental economics methodology.

Contrary to the predictions of standard economic theory, managers chose to offer the BC 88% of the time. Salespeople reciprocated by exerting a greater effort than necessary (an average of 5 out of 10), which is profitable for firms. Fehr, Klein, and Schmidt (2004) also report that actual ex post bonus payments increased with actual effort, which implies that managers reward salespeople’s efforts (similar to voluntary “tipping” in service professions). As a result of the higher effort levels, the payoffs for both the manager and the salesperson (combined surplus) are higher under the BC than under the IC. Overall, these observed regularities cannot be reconciled in a model with purely self-interested preferences.

Fehr, Klein, and Schmidt (2004) show that the results of the experiment are consistent with Fehr and Schmidt’s (1999) inequality aversion model of when the proportion of fair-minded managers and salespeople (with γ, η, >.5) in the market is assumed to be 40%. For the BC, there is a pooling equilibrium in which both the self-interested and the fair-minded managers offer w = 15, with the fair-minded manager paying b = 25 and the self-interested manager paying b = 0 (giving an expected bonus of 10). The self-interested salesperson will choose e = 7, and the fair-minded salesperson will choose e = 2, giving an expected effort level of 5. The low effort exerted by the fair-minded salesperson is attributed to him or her disliking the inequality in payoffs whenever he or she encounters the self-interested manager, with a probability of .6. For the IC, Fehr, Klein, and Schmidt show that it is optimal for the self-interested manager to offer the contract (w = 4, e* = 4, f = 13). However, the fair-minded manager will choose (w = 17, e* = 4, f = 13), which results in an equal division of surplus when e = 4. A purely self-interested salesperson will accept and obey the contracts offered by both the self-interested and the fair-minded managers. However, the fair-minded salesperson will accept and obey only the contracts offered by the fair-minded manager.

Comparing the BC and IC, the average level of effort is higher in the former (effort level of 5 versus 4), resulting in a higher expected combined surplus. Consequently, both the self-interested and the fair-minded managers prefer the BC over the IC. This example illustrates how fairness and reciprocity can generate efficient outcomes in principal–agent relations when standard theory predicts rampant shirking.

# HYPERBOLIC DISCOUNTING

# Behavioral Regularities

The discounted-utility (DU) framework is widely used in economics and other fields (including behavioral ecology in biology) to model intertemporal choice. The DU model assumes that decision makers make current choices that maximize the discounted sum of instantaneous utilities in future periods. The most common assumption is that decision makers discount the future utility at time t by an exponentially declining discount factor, d(t) = δt (where 0 < δ < 1).

The discount factor δ is also commonly written as 1/(1 + r), where r is the discount rate.

Despite its simplicity and normative appeal, many studies have shown that the DU model is problematic empirically. In economics, Thaler (1981) was the first to show that the per-period discount factor δ appears to decline over time (following Ainslie [1975] and others in psychology). Thaler asked participants to state the amount of money they would require in three months, one year, and three years later in exchange for receiving a sum of $15 immediately. The respective median responses were $30, $60, and $100, which implies average annual discount rates of 277% over three months, 139% over one year, and 63% over three years. The finding that discount rates decline over time has been corroborated by many other studies (e.g., Benzion, Rapoport, and Yagil 1989; Holcomb and Nelson 1992; Pender 1996).

Moreover, it has been shown that a hyperbolic discount function of the form d(t) = 1/(1 + m × t) fits data on time preferences better than the exponential form does. Hyperbolic discounting implies that agents are relatively farsighted when making trade-offs between rewards at different times in the future but pursue immediate gratification when it is available. Recent research in neuroeconomics (McClure et al. 2004) suggests that hyperbolic discounting can be attributed to competition of neural activities between the affective and the cognitive systems of the brain. A major consequence of hyperbolic discounting is that the behavior of decision makers will be time inconsistent; that is, decision makers might not make the same decision they expected they would (when they evaluated the decision in prior periods) when the actual time arrives. Descriptively, this property is useful because it provides a way to model self-control problems and procrastination.

# The Generalized Model

A useful model that approximates hyperbolic discounting introduces one additional parameter into the standard DU framework. This generalized model is known as the β–δ “quasi-hyperbolic” or the “present-biased” model.

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

and Pollak (1968) first introduced it to study transfers from parents to children, and it was then borrowed and popularized by Laibson (1997). With quasi-hyperbolic discounting, the decision maker’s weight on current (time t) utility is 1, and the weight on period τ’s utility (τ > t) is βδτ – t. Thus, the decision maker’s intertemporal utility in period t, Ut, can be represented by

(11) U(ut, ut+1, ..., uT) ≡ ut + β ∑τ=t+1T δτ-t uτ.

In the β–δ model, the parameter δ captures the decision maker’s long-term preferences, and β (which is between 0 and 1) measures the strength of the taste for immediate gratification or, in other words, the degree of present bias. Lower values of β imply a stronger taste for immediacy. Note that the discount factor placed on the next period after the present is βδ, but the incremental discount factor between any two periods in the future is (βδt+1)/(βδt) = δ. Decision makers act today as if they will be more patient in the future (using the ratio δ), but when the future arrives, the discount factor placed on the next period is βδ. In the special case of β = 1, the model reduces to the standard DU framework. This special case is also important in that it is sometimes used as the benchmark by which the welfare effects of hyperbolic discounting are made. The β–δ model has been applied to study self-control problems, such as procrastination and deadline setting (O’Donoghue and Rabin 1999b, c; 2001) and addiction (Gruber and Koszegi 2001; O’Donoghue and Rabin 1999a, 2002).

A question that arises is whether decision makers are aware that they are discounting hyperbolically. A way to capture agents’ self-awareness about their self-control is to introduce beliefs about their own future behavior (O’Donoghue and Rabin 2001; 2003). Let β^ denote the agent’s belief about β. Agents can be classified into two types. The first type is the “naïf,” who is totally unaware that he or she is a hyperbolic discounter and believes that he or she discounts exponentially (β < β^ = 1). The second type is the “sophisticate” (β = β^ < 1), who is fully aware of his or her time inconsistency and makes decisions that rationally anticipate these problems. The sophisticate seeks external self-control devices to commit him- or herself to acting patiently in the future (Ariely and Wertenbroch 2002), but the naïf does not.

We illustrate how hyperbolic discounting and decision makers’ beliefs about their preferences affect behavior with an example. For simplicity, we assume that δ = 1. A consumer faces two sequential decisions:

1. Purchase decision (Period 0): The consumer must decide between buying a small (containing one serving) or large (containing two servings) pack of chips. The large pack of chips comes with a quantity discount, so it has a lower price per serving.
2. Consumption decision (Period 1): The consumer must decide on the number of servings to consume. If he or she bought the small pack, only one serving can be consumed. However, if he or she bought the large pack, a decision must be made.

To keep the example simple, we do not include the benefits and costs of eating the leftover serving in future periods; the results remain unchanged, even if we include them.

|Purchase and Consumption Decision|Instantaneous Utility|Instantaneous Utility| | |
|---|---|---|---|
| | |in Period 1|in Period 2|
|Small: 1 serving|2.5|–2| |
|Large: 1 serving|3.0|–2| |
|Large: 2 servings|6.0|–7| |

# Modeling the Psychology of Consumer and Firm Behavior

# Table 7

# UTILITIES OF THE CONSUMER GIVEN PURCHASE AND CONSUMPTION DECISIONS

| |Rational|Naïf|Sophisticate|
|---|---|---|---|
|Purchase Decision (Period 0)|Small|2.5 – 2|β(2.5 – 2)|
| |Large|Max{U1L, U2L) = Max{3–2, 6–7}|β × Max{U1L, U2L) = β × Uj*L, where j* = argmax{Large–j serving in Period 1}|
|Consumption Decision (Period 1)|Small: 1 serving|2.5 – 2|2.5 – β × 2|
| |Large: 1 serving|0.3 – 2|0.3 – β × 2|
| |Large: 2 servings|0.6 – 7|0.6 – β × 7|

# Table 8

# DECISIONS AND UTILITIES OF THE CONSUMER (β = .5 FOR NAÏF AND SOPHISTICATE)

| |Rational|Naïf|Sophisticate| |
|---|---|---|---|---|
|Purchase Decision (Period 0)|Large|Large|Small| |
| |Small|0.5|0.25| |
| |Large|1.0|–.50| |
|Consumption Decision (Period 1)|1 Serving|2 Servings|1 Serving| |
| |Small: 1 serving|n.a.|n.a.|1.5|
| |Large: 1 serving|0.1|2.0|n.a.|
| |Large: 2 servings|–1|2.5|n.a.|

Notes: n.a. = not applicable.

Behavior: In period 0, the naïf chooses as if he or she will be comparing between utilities of 3 – 2 and 6 – 7 in Period 1, neglecting the β weight that will actually appear and discount the high future cost in Period 1, making the naïf eager to eat both servings in one period. Note that as a result, actual utility, evaluated at Period 0, is not .5 but rather .5(6 – 7) = –.5.

The sophisticate forecasts accurately what will happen if he or she buys the large pack. That is, the Table 7 entries for utilities of consuming from the large pack when Period 1 arrives are exactly the same for the naïf and the sophisticate. The difference is that the sophisticate anticipates this actual choice when planning which pack to buy in Period 0. As a result, the sophisticate deliberately buys the small pack, eats only one serving, and has both a forecasted and an actual DU of .25. The crucial point here is that the naïf does not plan to eat both servings, so he or she buys the large pack. The sophisticated knows that he or she cannot resist and thus buys the small pack.

Marketing Application: Price Plans for Gym Memberships

Hyperbolic discounting is most likely to be found for products that involve either immediate costs with delayed benefits (visits to the gym, health screenings) or immediate benefits with delayed costs (smoking, using credit cards, eating) and temptation. Della Vigna and Malmendier (2004) examine the firm’s optimal pricing contracts in the presence of consumers with hyperbolic preferences for gym memberships. Their three-stage model is set up as follows.

At time t = 0, the monopolist firm offers the consumer a TPT with a membership fee F and a per-use fee p. The consumer either accepts or rejects the contract. If the consumer rejects the contract, he or she earns a payoff of u at t = 1, the firm earns nothing, and the game ends. If the consumer accepts the contract, he or she pays F at t = 1 and then decides between exercise (E) or nonexercise (N). If the consumer chooses E, he or she incurs a cost c and pays the firm the usage fee p at t = 1. The consumer earns delayed health benefits b > 0 at t = 2. If he or she chooses N, the cost is 0, and the payoffs at t = 2 are also 0. It is assumed that the consumer learns cost c at the end of t = 0, after he or she has made the decision to accept or reject the contract. However, before the consumer makes that decision, he or she knows the cumulative distribution G(c) from which c is drawn. The firm incurs a setup cost of K ≥ 0 whenever the consumer accepts the contract and a unit cost a if the customer chooses E. The consumer is a hyperbolic discounter with parameters (β, δ). For simplicity, it is also assumed that the firm is time consistent with a discount factor δ.

For the naive hyperbolic consumer choosing to exercise, the decision process can be described as follows: At t = 0, the utility from choosing E is βδ × (δb – p – c), and the payoff from N is 0. Thus, the consumer chooses E if c ≤ δb – p. However, when t = 1 actually arrives, choosing E yields only βδb – p – c, and thus the consumer actually chooses E only if c ≤ βδb – p. The naive hyperbolic consumer mispredicts his or her own future discounting process and thus overestimates the net utility of E when buying the membership. The actual probability that the consumer chooses to exercise is the percentage chance that his or her cost is.

# NEW METHODS OF GAME-THEORETIC ANALYSES

Thus, the consumer chooses to exercise less often than he or she plans to when buying the membership. The difference between the expected and the actual probability of exercise is reflected by G( δb – p) – G( βδb – p). In addition, if an intermediate case in which the consumer can be partially naive (β < ^ β < 1) is allowed, the degree by which the consumer overestimates his or her probability of choosing E is G( ^ – G( βδb – p). Unlike the naive or partially naive consumers, the fully sophisticated consumer (β = ^ β < 1) displays no overconfidence about how often he or she will choose E. Overall, the consumer’s expected net benefit at t = 0 when he or she accepts the contract is βδ[–F + (βδb – p c)dG(c)].

The rational firm anticipates this, and its profit-maximization problem is given by:

(12) max δ {F − K + G(βδb − p)(p − a)}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F p

such that βδ − F + ∫βδb − p(δb − p − c) dG(c) = βδu.

The “such that” constraint reflects the notion that as a monopolist, the firm can fix contract terms that make the consumer indifferent between going and earning the expected benefit or rejecting and earning the discounted rejection payoff βδu. The firm maximizes its own discounted profits, which is the fixed fee F less its fixed costs K times the percentage of time it collects user fees because the consumer chooses E (the term G(βδb – p)) times the net profit from the user fees p – a.

Della Vigna and Malmendier (2004) begin with the case in which consumers are time consistent (β = 1). Then, the firm simply sets p* equal to marginal cost a and chooses F* to satisfy the consumer’s participation constraint (the aforementioned “such that” constraint). More interestingly, when β < 1, the firm’s optimal contract involves setting the per-use fee below marginal cost (p* < a) and the membership fee F above the optimal level F* for time-inconsistent consumers. This result can be attributed to two reasons: First, the below-cost usage fee serves as a commitment device for the sophisticate to increase his or her probability of exercise. The sophisticate likes paying a higher membership fee coupled with a lower per-use fee because the sophisticate knows that he or she will be tempted to skip the gym unless the per-use fee is low. Second, the firm can exploit the naïf’s overconfidence about future exercise; the naïf will accept the contract and pay F* but will exercise (and pays p* < a) less often than he or she believes.

To support these theoretical results, Della Vigna and Malmendier presented empirical evidence that shows that the industry for health club memberships typically charges high membership fees and low (and often zero) per-use fees. Furthermore, in their study the average membership fee is approximately $300 per year. For most gyms, consumers also have the option of paying no membership fee but a higher per-use fee (approximately $15 per visit). The average consumer who paid a typical $300 fee goes to the gym so rarely that his or her effective per-use cost is $19 per visit; this consumer would have been better off not buying the membership and just paying on a per-use basis. This type of forecasting mistake is precisely what the naive hyperbolic consumer does.

21 For example, the predictions of NE in games with a unique mixed-strategy equilibrium are often close to the empirical results in aggregate.

# Modeling the Psychology of Consumer and Firm Behavior

# Table 9

# ASYMMETRIC HIDE-AND-SEEK GAME

| |B1 (q)|B2 (1 – q)|(N = 128)|NE|QRE|
|---|---|---|---|---|---|
|A1 (p)|9, 0|0, 1|.54|.50|.65|
|A2 (1 – p)|0, 1|1, 0|.46|.50|.35|
|Empirical frequency|.33|.67| | | |
|NE|.10|.90| | | |
|QRE|.35|.65| | | |

Behavioral Regularities

Table 9 shows a game between two players. The row player’s strategy space consists of Actions A1 and A2, and the column player’s strategy space consists of Actions B1 and B2. The game is a simple model of “hide-and-seek,” in which one player wants to match another player’s choice (e.g., A1 responding to B1), and another player wants to mismatch it (e.g., B1 responding to A2). The row player earns either nine or one from matching on (A1, B1) or (A2, B2), respectively. The column player earns one from mismatching on (A1, B2) or (A2, B1).

Table 9 also shows the empirical frequencies of each possible action, averaged across many periods of an experiment conducted on this game. 22 What is the NE prediction for this game? We begin by observing that there is no pure-strategy NE for this game, so we look for a mixed-strategy NE. Suppose that the row player chooses A1 with probability p and A2 with probability 1 – p, and suppose that the column player chooses B1 with probability q and B2 with probability 1 – q. In a mixed-strategy equilibrium, the players actually play a probabilistic mixture of the two strategies. If their valuation of outcomes is consistent with expected utility theory, they prefer playing a mixture only if they are indifferent between each of their pure strategies. This property gives a way to compute the equilibrium mixture probabilities p and q. The mixed-strategy NE for this game turns out to be ([.5 A1, .5 A2], [.1 B1, .9 B2]). 23 Comparing this with the empirical frequencies, we find that NE prediction is close to actual behavior by the row players, whereas it underpredicts the choice of B1 for the column players.

If one player plays a strategy that deviates from the prescribed equilibrium strategy, according to the optimization assumption in NE, the other player must choose the best response and deviate from NE as well. In this case, although the predicted NE and actual empirical frequencies almost coincide for the row player, the players are not playing an NE jointly, because the row player should have played differently given that the column player deviated far.

22The data are taken from the first row of Table IX in McKelvey and Palfrey (1995).

23Assuming that the row player is mixing between A1 and A2 with probabilities p and 1 – p, the expected payoff for the column player from choosing B1 is p × 0 + (1 – p) × 1, and the expected payoff from choosing B2 is p × 1 + (1 – p) × 0. Equating the two expressions gives a solution p = .5. Similarly, the row player’s expected payoffs from A1 and A2 are q × 9 + (1 – q) × 0 and q × 0 + (1 – q) × 1. Equating the two expressions gives a solution q = .1.

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

highest expected payoff is played almost all the time. As λ increases, higher and higher probability is put on strategies with better payoffs.

We now illustrate how to derive the QRE for a given value of λ for the hide-and-seek game. Again, suppose that the row player chooses A1 with probability p and A2 with probability 1 – p, and suppose that the column player chooses B1 with probability q and B2 with probability 1 – q. Then, the expected payoffs from playing A1 and A2 are q × 9 + (1 – q) × 0 = 9q and q × 0 + (1 – q) × 1 = 1 – q, respectively. Therefore, we have:

πRowA1 = p = (eλ × 9q) / (eλ × 9q + eλ × (1 – q)).

Similarly, the expected payoffs to B1 and B2 for the column player are 1 – p and p, respectively, so we have πColumnB1 = q = (eλ × (1 – p)) / (eλ × (1 – p) + eλ × p).

Furthermore, note that q is on the right-hand side of the first equation, which determines p, and p is on the right-hand side of the second equation, which determines q. To a psychologist, the logic might appear “circular” because p depends on q and q depends on p, but that mutual dependence is what delivers mathematical precision. For any value of λ, there is only one pair of (p, q) values that solves the simultaneous equations and yields a QRE. For example, if λ = 2, the QRE predictions are p* = .646 and q* = .343, which are closer to the empirical frequencies than the NE predictions.

Using the actual data, a precise value of λ can be estimated using maximum-likelihood methods. The estimated λ for the QRE model for the asymmetric hide-and-seek game is 1.95. The negative of the log-likelihood of QRE (an overall measure of goodness of fit) is 1721, a substantial improvement over a random model benchmark (p = q = .5), which has a fit of 1774. The NE prediction has a fit of 1938, which is worse than random because of the extreme prediction of q = .1.

Marketing Application: Price Competition with Differentiated Products

We now apply QRE to study price competition between firms and contrast its predictions with NE. We adapt this application from the work of Friedman, Palfrey, and Thisse (1995), who derive the QRE for a differentiated goods Bertrand duopoly. In this model, there are two firms that choose prices p1 and p2. After the firms choose prices simultaneously, the quantity of products they sell is given by two demand functions:

q1(p1, p2) = a – bp1 + cp2, and q2(p1, p2) = a – bp2 + cp1, where a, b, and c > 0. For simplicity, we assume that the marginal cost of production for each firm is zero and that c < 2b. That c > 0 implies that the two firms’ products are imperfect substitutes, so that if p2 is higher, consumers will demand more of Product 1. We consider only the case in which the payoffs are nonnegative, so the firms’ strategy space is the interval [0, (a/b)]. We can easily show that the symmetric pure-strategy NE in which both firms choose the same price is pNE = a/(2b – c).

To begin deriving the QRE, let p denote the firm’s expected price in the symmetric QRE in which both firms choose the same distribution of prices. Friedman, Palfrey, and Thisse assume a quantal response function as follows:

The data show that the NE prediction of 0 explains first-period choices very poorly in this game. Furthermore, telling someone to play the equilibrium choice is bad advice. However, choices are heterogeneous across participant groups.

# Modeling the Psychology of Consumer and Firm Behavior

# Table 10

# AVERAGE CHOICE IN P-BEAUTY CONTESTS

|Participant Pool|Group Size|Sample Size|M|
|---|---|---|---|
|Caltech board|73|73|49.4|
|80-year-olds|33|33|37.0|
|High school students|20–32|52|32.5|
|Economics PhDs|16|16|27.4|
|Portfolio managers|26|26|24.3|
|Caltech students|3|24|21.5|
|Game theorists|27–54|136|19.1|

Source: Table 2 in Camerer, Ho, and Chong (2004).

The data raise an important question: Is there an alternative to NE that generates more accurate predictions and captures the heterogeneity across different participants? The CH model (Camerer, Ho, and Chong 2004) is one such model.

# The Generalized Model

The CH model relaxes the assumption of mutual consistency by allowing players’ beliefs of others’ actions to be different from actual choices that others make. Unlike NE, the CH model assumes that there are some players who have not carefully thought through what other players are likely to do and thus will be surprised. It uses an iterative process, which formalizes Selten’s (1998, p. 421) intuition that “the natural way of looking at game situations is not based on circular concepts, but rather on a step-by-step reasoning procedure.” It captures heterogeneity in players’ reasoning abilities and explicitly models the decision rule each type of player uses.

To begin, the CH model captures the possibility that some players use zero steps of thinking; that is, they do not reason strategically at all. 24 It is assumed that these zero-step players randomize equally among all available strategies. Players who are one-step thinkers choose actions that maximize their payoffs, believing that all others use zero steps (i.e., players are “overconfident” in that they believe that all others use fewer steps of thinking). Proceeding inductively, the model assumes that K-step players believe that all others use zero to K – 1 steps. The model assumes that the frequencies of K-step thinkers, f(K), is given by:

(19) f(K) = e-τ × K / K!

The Poisson characterization is appealing because it has only one free parameter τ (which is both its mean and its variance). A large value of τ implies that players are sophisticated and undertake many steps of iterative reasoning.

Step-K players’ beliefs of the proportions of the lower steps are obtained by dividing the actual proportions of lower-step types by the sum of their frequencies so that they add up to one as follows:

(20) g(h) = f(h) / ∑ f(h) for h ≤ K – 1, and g(K) = 0 for h ≥ K.

As K gets larger, these normalized beliefs converge to the actual frequencies f(h). That is, K is a measure of how well calibrated a player’s beliefs are; this is similar to “strategic intelligence.” It is assumed that step-K thinkers (K > 0) compute expected payoffs given their beliefs and choose the strategy that yields the highest expected payoff.

We illustrate how to derive the CH prediction for a specific value of τ for the p-beauty contest. The value of τ that we assume in this case is 1.55, and the frequencies of the step-zero through step-six players are .212, .329, .255, .132, .051, .016, and .004, respectively. In the CH model, the step-zero players do not think strategically; in this example, their choices are distributed uniformly from 0 to 100. The step-one players believe that all the other players are step-zero thinkers and best-respond; because their perceived average is 50, step-one players will choose (2/3) × 50 = 33. The step-two players believe that the proportions of the step-zero and step-one players are .39 (from .212/[.212 + .329]) and .61, respectively. They perceive the average as (.39 × 50) + (.61 × 33) = 39.6 (39 including their own choice) and thus choose 26 as a best response. Following the same reasoning, we can compute the choices for players of higher steps. Finally, we compute the predicted choice of the CH model by weighting the K-step players’ choices by the proportions of players doing each of K steps. For τ = 1.55, the CH model predicts that the average would be 32.67. The estimated τs and the respective CH predictions for the participant pools in Table 10 appear in Table 11. In general, Camerer, Ho, and Chong (2004) find that the value of τ that best explains a wide variety of games is approximately 1.5.

# Marketing Application: Market Entry

A central concept in marketing strategy is what markets a firm should enter. Entry should depend on whether a market leverages a firm’s brand equity (“umbrella branding”) and has cost or economies-of-scope advantages relative to its competitors. However, entry also depends on a sensible forecast of how large the market will be and how many other firms will enter. Even if a firm has competitive advantages in a particular market, if too many firms enter—perhaps because they underestimate the amount of competition or are optimistic about their relative advantage—the firm should stay out until the “shake-out” period when overly optimistic firms fail (e.g., Camerer and Lovallo 1999). The simplest way to study the effect of forecasts of competitors is with a simple model that strips away cost advantages. Suppose that each of N firms simultaneously

# Table 11

# ESTIMATED τ AND CH PREDICTION FOR DIFFERENT PARTICIPANT POOLS

|Participant Pool|M|CH Prediction|Estimated τ|
|---|---|---|---|
|Caltech board|49.4|43.1|.50|
|80-year-olds|37.0|36.9|1.10|
|High school students|32.5|32.7|1.60|
|Economics PhDs|27.4|27.5|2.30|
|Portfolio managers|24.3|24.4|2.80|
|Caltech students|21.5|23.0|3.00|
|Game theorists|19.1|19.1|3.70|

322 JOURNAL OF MARKETING RESEARCH, AUGUST 2006

decides whether to enter a market or stay out (denoted as 1 and 0, respectively). We denote the total market demand as d &lt; N, where d is expressed as a fraction of the number of firms (i.e., 0 &lt; d &lt; 1). If d or fewer firms enter (i.e., supply is equal to or less than demand), the entrants each earn a profit of 1. If more than d firms enter (i.e., supply is greater than demand), all the entrants earn 0. If a firm does not enter, it earns a profit of 0.5.

To keep the mathematics simple, we assume that firms are risk neutral and that there are infinitely many “atomistic” entrants. In this case, firms care only about whether the fraction of others entering is above d or not: If the fraction of others entering is below d, the firm should enter, but if the fraction of others entering is above d, the firm is better off staying out and earning 0.5. The NE in this case is a mixed-strategy equilibrium in which firms randomize and enter with probability d. When the number of firms is large (N → ∞), the law of large numbers implies that the fraction of entry is d.

In actual experiments conducted on market entry games such as this one, there are three empirical regularities (see Camerer 2003, Ch. 7; Rapoport and Seale, in press):

1. Entry tends to be monotonically increasing in demand d, even in one-shot games and early periods of repeated games;
2. There is too much entry for low values of d (relative to NE); and
3. Too little entry for high values of d;

Individual profiles of entry rates for different d values in within-subject designs (in which players choose whether to enter for different d values) tend to show some simple step functions and more jagged out-in-out-in step functions (e.g., Rapoport, Seale, and Winter 2002).

The CH model can explain all these regularities. To begin, we denote the entry function of step-K firms for a given demand d as e(K, d). This function maps the demand d and thinking step K into a decision either to enter (1) or to stay out (0). We denote the interim total entry function for all steps up to and including K as E(K, d). In the CH model, a step-K firm believes that it is competing against a normalized Poisson distribution of players that do 0, 1, 2, …, K – 1 steps of thinking. Thus, the step-K firm believes that it is facing an interim total entry rate of E(K – 1, d) = Σh = 0K − 1 gK(h) × e(h, d). If E(K – 1, d) &lt; d, the step-K firm should enter (e(K, d) = 1); if E(K – 1, d) &gt; d, the firm should stay out (e(K, d) = 0). The CH model’s prediction of how many firms will enter for each value of d is the limiting case E(∞, d), which depends on the value of τ.

We now work through the first couple of steps of entry predicted by the CH model. Step-zero firms will randomize, so their entry function is e(0, d) = 0.5 for all values of d (think of these firms as ignoring competitors or market size). Step-one firms believe that if d is below 0.5, there will be too much entry (because e(0, d) = 0.5 &gt; d), so they stay out. However, if d is above 0.5, they anticipate e(0, d) = 0.5 &lt; d, so there will not be enough entry, and they can profit by entering. Step-two firms believe that they are facing a mixture of step-zero and step-one firms. In the Poisson CH model, the relative proportions of these two types of firms are g2(0) = 1/(1 + τ) and g2(1) = τ/(1 + τ). For d &lt; 0.5, the expected interim entry function E(1, d) is g2(0) × 0.5 + g2(1) × 0 = 0.5/(1 + τ). Thus, when d &lt; 0.5/(1 + τ), there is too much entry due to the entry by the step-zero firms, and so the step-two firms stay out. However, when 0.5/(1 + τ) &lt; d &lt; ...

# Modeling the Psychology of Consumer and Firm Behavior

# LEARNING

# Behavioral Regularities

Equilibrium concepts such as NE study behavior after equilibration, at the point when players have come to guess accurately what other players do. One force that produces equilibration is learning from feedback. That is, players’ actions at a point in time reflect their prior experiences with those actions, which are used to anticipate others’ future actions. An example that illustrates learning is the “median-action” coordination game (see Van Huyck, Battalio, and Beil 1991). This game involves a group of n players, where n is an odd number. The choice of each player i consists of choosing an integer action xi from 1 to 7. Let M denote the median of all the players’ actions. The payoff function for each player is given by πi(xi, M) = .1M – .05(M – xi)² + .6. This game captures the key features of economic situations in which there is a motive for conformity because players are penalized for choosing an xi that is different from the median M (through the penalty of .05[M – xi]²). At the same time, players have a common incentive to coordinate on a higher median choice because of the premium .1M added to profits. Thus, all the players want the median number to be high, which creates a motive to choose a large number, but nobody wants to choose a number larger than what they expect the median will be.

In this game, there are many NE. For each of the values from 1 to 7, if players believe that the median will equal that value, the best response is xi = M, so the median M will result. So all the integers from 1 to 7 are pure-strategy NE (there are many mixed equilibriums as well). In this example, the NE is not precise at all. This imprecision leaves room for an empirical theory to pin down what happens when players play for the first time (as the CH theory described previously) and to specify a path of play over time as players learn. Before theories of limited strategizing and learning came along in behavioral game theory, however, theorists were inclined to ask which general deductive principles players might use to select among the many equilibriums (these are called “selection principles”).

Three deductive principles of equilibrium selection may be useful in predicting what players will choose in the median-action game. The first selection principle is “payoff dominance”; that is, players will choose the equilibrium that is best for everyone. The payoff-dominant equilibrium is for everyone to choose 7, earning $1.30 each. The second selection principle is based on the concept that people will maximize their “security” and choose the action whose smallest payoffs are the largest (maximizing the minimum payoff). Choosing 3 guarantees that a player will make a minimum of at least $.50, and because this is the highest guaranteed payoff for any strategy, the “maximin” rule selects the strategy of 3. The third selection principle is the one-step rule we introduced previously in the CH model, in which people will choose the strategy with the highest expected value, assuming all medians are equally likely. This rule selects the strategy of 4.

Van Huyck, Battalio, and Beil (1991) conducted six experimental sessions in which a group of nine players made decisions for ten periods for the game we just described. The results exhibit four regularities: First, the principles of payoff dominance and secure (maximin) actions are not supported; the medians were never 7 or 3 in any period; in fact, the medians for every period are either 4 or 5. Second, the median choices in each session are strongly influenced by the initial median (in all cases, the tenth-period median is exactly the initial first-period median). Third, not only does pure-strategy NE fail to provide a determinate prediction, but it also performs rather poorly because all the nine players chose the same action in only 19 of the 60 total periods. Fourth, and most important for our purpose, equilibration seems to result from learning over time because the NE (in which all participants play the same strategy in those 19 periods) is played in the later periods. Next, we present a model that is able to capture some of these dynamics.

# The Generalized Model

Before we begin, some notation is necessary. For player i, there are mi strategies, denoted as sij (the jth strategy for player i). Strategies that i actually chooses in period t and that all other players (denoted as –i) choose are si(t) and s–i(t), respectively. Player i’s ex post payoff of choosing strategy sij in time t is πi(sij, s–i(t)), and the actual payoff received is πi(si(t), s–i(t)) ≡ πi(t). For player i, strategy j has a numerical attraction Aij(t) at the end of period t after updating from the period’s experience, and Aij(0) is the initial attraction before the game starts. Attractions of period t determine choice probabilities in period t + 1 through the following logistic stochastic response function:

Pij(t + 1) = ∑k=1mi eij(t) / ∑k=1mi eλ × Aik(t)

where λ measures the degree of payoff sensitivity. Note that as in the QRE model we discussed previously, λ = 0 represents random response, and λ = ∞ represents best response. In the self-tuning EWA model, attractions are updated by:

Aij(t) = (φi(t) × Ni(t - 1) × Aij(t - 1) + {ξij(t) × I[sij, si(t)] × πij(sij, s-i(t))}) / (φi(t) × Ni(t - 1) + 1)

where I[x, y] is an indicator function (equal to 1 if x = y and 0 if otherwise; see Camerer and Ho 1998, 1999; Camerer, Ho, and Chong 2002; Ho, Camerer, and Chong, in press). That is, previous attractions are multiplied by an experience weight N(t – 1), decayed by a weight φi(t), incremented either by the actual payoff received (when I[sij, si(t)] = 1) or by ξij(t) times the payoff that could have been received (when I[sij, si(t)] = 0), and normalized by dividing by φi(t) × N(t – 1) + 1. Note that an equilibrium model is a special case of nonlearning in which the initial attractions Aij(0) are derived from equilibrium calculations, and the initial experience weight N(0) is very large.

The EWA is a hybrid of reinforcement and fictitious play (belief-learning) models. Standard reinforcement models assume that only actual choices are reinforced (i.e., when ξij(t) = 0; Erev and Roth 1998). The weighted fictitious play belief-learning model corresponds to a case in which all choices are reinforced with equal weights (i.e., all forgone payoffs are reinforced by a weight of ξij(t) = 1). We initialize N(0) by setting it equal to one, and we update it according.

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

to N(t) = φi(t) × N(t – 1) + 1. The initial attractions Aij(0) are computed numerically using the CH model with τ = 1.5.

# Figure 2

# EMPIRICAL FREQUENCIES FOR THE MEDIAN ACTION GAME

| | | | | | | |
|---|---|---|---|---|---|---|
| | | | | | | |
| | | | | | | |
| | | | | | | |
| | | | | | | |
| | | | | | | |

The change-detector function φi(t). The decay rate φi(t), which weights lagged attractions, is often called “forgetting.” Although forgetting does occur, the more interesting variation in φi(t) is a player’s perception of how quickly the learning environment is changing. Therefore, the function φi(t) should be capable of “detecting change.” When a player senses that other players are changing, a self-tuning φi(t) should dip down, putting less weight on old experience. The core of the φi(t) change-detector function is a “surprise index,” which is the difference between other players’ recent strategies and their strategies in previous periods. We define a history vector across the other players’ strategies k that records the historical frequencies (including the most recent period t) of the choices made by the other players. A vector element is hik(t) = ( Σt I[si, si(τ)]/t. The recent “history” rik(t) is a vector of zeros and ones, which has a one for strategy si = si(t) and zeros for all other strategies s (i.e., rik(t) = I[sik, si(t)]). The surprise index Si(t) = Σk (hik(t) - rik(t))2 sums up the squared deviations between the cumulative history vector hik(t) and the immediate recent history vector rik(t) across all the strategies. This surprise index varies from zero to two. To map it into a sensible change detection value, φi(t) = 1 – 0.5 × Si(t) is used. Because Si(t) is between zero and two, φi(t) is always (weakly) between one and zero.

The attention function ξij(t). The parameter ξij(t) is the weight on forgone payoffs. Presumably, this is tied to the ex post attention participants pay to alternative payoffs. Those who have limited attention are likely to focus on strategies that would have given higher payoffs than what they actually received because these strategies represent missed opportunities. To capture this property, define ξij(t) = 1 if π(si, si(t)) ≥ π(t) and 0 if otherwise. That is, participants reinforce chosen strategies (in which the payoff inequality is always an equality) and all unchosen strategies that have better payoffs (in which the inequality is strict) with a weight of one. They reinforce unchosen strategies with equal or worse payoffs by zero. Note that this ξij(t) can transform the self-tuning rule into special cases over time. If participants are strictly best responding (ex post), no other strategies have a higher ex post payoff, so ξij(t) = 0 for all strategies j that were not chosen, which reduces the model to choice reinforcement. However, if participants always choose the worst strategy, then ξij(t) = 1, which corresponds to weighted fictitious play. If participants choose neither the best nor the worst strategy, the updating scheme will push them (probabilistically) toward strategies that yield better payoffs, which is both characteristic of human learning and normatively sensible.

The self-tuning EWA model captures the dynamics of the median-action game we described. Figure 2 shows the empirical frequency for each of the seven strategies across time for all the six sessions. These aggregate data show that the initial choices were relatively more diffuse and converge toward NE behavior (around 4 and 5) in the subsequent rounds. Figure 3 shows how the self-tuning EWA model tracks these changes over time. Ho, Camerer, and Chong (in press) also show how the same model captures learning dynamics in other games ranging from coordination, dominance-solvable games to games with a unique mixed.

# Figure 3

# PREDICTED FREQUENCIES OF THE SELF-TUNING EWA MODEL

| | | | | | | |
|---|---|---|---|---|---|---|
| | | | | | | |
| | | | | | | |
| | | | | | | |
| | | | | | | |
| | | | | | | |

Marketing Application: Price Matching with Loyalty. Capra and colleagues (1999) experimentally studied a type of price-matching competition (first introduced by Basu [1994]). In this game, two firms must choose an integer price between marginal cost and a reservation price that is common to all customers. If the prices are equal, each

# Modeling the Psychology of Consumer and Firm Behavior

firm receives the common price as its payoffs (i.e., the sales volume is normalized to one). If the prices are unequal, each firm receives the lower of the two prices. In addition, the firm that charges the lower price receives a bonus R, and the firm that charges the higher price pays a penalty of R. Thus, this type of competition is akin to a duopoly, in which the two sellers promise customers that their posted prices are the lowest and offer lowest-price guarantees in the form of price matching to underpin their claims. Because customers believe that firms that offer such guarantees have the lowest price (Jain and Srivastava 2000), the firm that charges the lowest price earns a goodwill reward, whereas the high-price firm suffers a reputation loss when customers compare their posted prices (for a generalization of this game, see Ho and Lim 2004). As long as R > 1, the unique NE for this game is that equilibrium prices will be at marginal costs. The proof is simple: If another firm is expected to choose a price P, by undercutting P by one unit, the lower price firm earns P – 1 + R, which is more than it can earn by matching P (and therefore earning P) or overpricing (earning P – R). Because both firms always want to undercut by one unit, in theory, there is a “race to the bottom.” Strikingly, this prediction is also invariant to the size of the penalty/reward factor R.

# Figure 5

PREDICTED FREQUENCIES OF THE SELF-TUNING EWA MODEL

| |0|1|2|3|4|5|6|7|8|9|10|
|---|---|---|---|---|---|---|---|---|---|---|---|
| |Probability|.0|.1|.2|.3|.4|.5|.6|.7|.8|.9|

Capra and colleagues (1999) tested the NE prediction of this game, varying R at six different levels (5, 10, 20, 25, 50, and 80). Participants grouped randomly in pairs were told to name a price from 80 to 200 simultaneously. Each participant played the game for ten rounds for each level of R. Figure 4 shows empirical frequencies for R = 50. A wide range of prices are posted in the early rounds. Prices gradually fall to between 91 and 100 in rounds three through five, 81 and 90 in rounds five through six, and toward the NE prediction of 80 in subsequent rounds. As Figure 5 shows, the self-tuning EWA model captures the data well. Given the initial dispersion of prices, it is able to capture the dynamics of equilibration and the high proportion of NE outcomes in the subsequent rounds (approximately 80% choose the NE in the final round).

# MARKETING APPLICATIONS

In this article, we described a marketing-related application of each of the new models we presented. Our goal was to show exactly how each new model is used and how its application can lead to new insights. This section extends our discussion and speculates on how these new tools can be applied more broadly to determine and influence the four marketing-mix decisions (i.e., decisions on price, product, promotion, and place).

The concepts of reference price and asymmetric price effects, which have been ascribed to reference dependence and loss aversion, are well-known empirical regularities in marketing (Hardie, Johnson, and Fader 1993; Kalyanaram and Winer 1995; Mayhew and Winer 1992; Winer 1986). Yet with the exception of the work of Greenleaf (1995), there has been virtually no analytical research on how past prices or the magnitude of loss aversion affects firms’ pricing strategies, particularly in the contexts of competition and intertemporal pricing. For example, does reference dependence predict that prices should move in cycles and decline within each cycle, as in the case of a monopoly? More important, can marketing researchers formulate pricing strategies for reference-dependent customers for new products or products for which customers do not have price histories? Koszegi and Rabin (2004) developed a model of reference-dependent preferences that assumes that the customer’s reference point is not based on past prices but on whether he or she expects to purchase a certain product on a...

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

particular shopping trip. Their framework provides a natural way to view advertising and other practices as a means to influence customer expectations of purchase and willingness to pay (see also Heidhues and Koszegi 2005). Marketing practices such as free 30-day trials and test drives of cars can be viewed as attempts to shift the reference point so that not buying the product is perceived as a loss.

Another area of research is to study how firms should price products in the presence of customers who are hyperbolic discounters. Recently, Oster and Morton (2004) studied the prices of approximately 300 magazines in the United States. They found that the ratio of subscription to newsstand prices is higher for “investment” magazines, such as Forbes, than for “leisure” magazines, such as Entertainment Weekly. An explanation for this is that the sophisticated time-inconsistent customers require only relatively small subscription discounts to induce them to subscribe to the investment magazines.

Finally, all the existing models of price competition in marketing that we are aware of use NE as a tool to generate descriptive and prescriptive predictions. Applying alternative solution concepts, such as QRE or the CH model, represents a potentially fruitful area of research because they more accurately represent the presence of latent payoffs or decision makers’ cognitive limitations, respectively. A key issue in promotions is the frequency and depth of price promotions. Narasimhan (1988) and Raju, Srinivasan, and Lal (1990) show that when two stores have their own loyal customers and compete for “switchers” by setting prices, the NE solution is characterized by a mixed-strategy profile that has been interpreted as price promotion (Rao, Arunji, and Murthi 1995).

# Product

Many customers are offered the option of buying extended product or service warranties when they purchase consumer durables. These extended warranties are marketed as ways to augment the basic warranty (usually provided free of charge by the manufacturer for a limited period) to “insure” the value of the new purchase. They are offered either by the manufacturer of the product or by third-party companies, and they increase either the scope or the length of the basic warranty (or both). An open research question is why customers buy these warranties in the first place. Although many articles in the practitioner literature have suggested that the additional coverage is not worth the price of the premiums, this has not been studied formally.

Are customers driven by extreme risk aversion, or is it more likely loss aversion (as we believe) that drives the demand for such warranties? Specifically, are customers loss averse with respect to losing their newly owned products (with the value of the product inflated through the endowment effect) such that they are willing to buy or even pay extra for the extended warranties, or do they overweight the small probabilities of breakdown (as in the prospect theory π(p) weighting function)?

The Bass diffusion model is one of the most widely used marketing tools to predict and explain the rate of product adoption at an aggregate level. Chatterjee and Eliashberg (1990) provide a theoretical underpinning to the Bass diffusion model by using a rational framework to model the adoption process of individual potential customers.

25 The data are available from the authors on request.

26 The experiments in Choi and Messinger’s (2005) work involve pairs of participants that set prices in a repeated setting.

# Modeling the Psychology of Consumer and Firm Behavior

An interesting issue is how rebate redemption behavior will change if firms vary the length of time they allow customers to redeem the rebate and the monetary size of these rebates if the customers consist of naive and sophisticated hyperbolic discounters. For example, should the profit-maximizing firm extend the redemption period and increase the size of the rebate to attract the naïfs, knowing that they are more likely to delay or forget (if it is a function of delay) to redeem the rebate and end up paying the full price? Furthermore, how should this be reconciled with the desires of the sophisticates for tighter redemption deadlines or even “instant” rebates as forms of commitment devices? These questions have yet to be formally analyzed.

# Place

The study of marketing distribution channels has been heavily dominated by theoretical modeling. Compared with areas such as consumer behavior, there is relatively little empirical research on channels. The study of channels presents marketing researchers with unique opportunities to combine empirical and especially experimental work (Anderson and Coughlan 2002) with the modeling tools in behavioral economics. Existing models of channel relationships can be generalized following careful empirical studies that challenge the predictions of orthodox economic theory.

For example, firms in an independent channel cannot capture all the possible profits in the channel by using a linear price contract (this is the DM problem we mentioned previously). Pioneering work by Jeuland and Shugan (1983) and Moorthy (1987) shows theoretically that more complex nonlinear contracts, such as quantity discounts and TPTs, can eliminate the DM problem. A fundamental question that arises from this stream of research is, Given that there are many forms of quantity discount contracts that are used in practice, should some contracts be preferred over others? Using experimental economics methodology, Lim and Ho (2006) compare two popular quantity discount contracts, the two-block and the three-block declining tariffs, which are theoretically equally effective at solving the DM problem. They find that the three-block tariff yields higher channel profits than the two-block tariff. They show that the results are consistent with a QRE in which the downstream firm in the channel also cares about the additional profits it would have earned if the lower marginal price in a given block were to be applied to other blocks with higher marginal prices.

In a different behavioral approach to DM, Cui, Raju, and Zhang (2004) note that the DM problem may not create inefficiency in practice, even with a linear price contract, if channel members are not purely self-interested. They show that if firms are sufficiently inequity averse (as in Fehr and Schmidt 1999), the efficient outcome that is reached by a vertically integrated monopoly can be achieved with separate firms, so that complex nonlinear contracts are superfluous.

# RESEARCH IMPLICATIONS

In this article, we show how the standard utility function of decision makers such as customers or managers can be generalized to capture three well-established empirical regularities about people: They care about both absolute outcomes and changes in outcomes relative to some reference point, they care about both their own and others’ payoffs, and they exhibit a taste for immediate gratification. These utility modifications have been increasingly popular in economics because they have one or two additional parameters over the standard models, which make them amenable to empirical testing and estimation. We also provide three alternatives to the standard NE solution concepts in competitive situations. The QRE generalizes the standard equilibrium concepts by allowing decision makers to better-respond instead of best-respond. The CH model relaxes the mutual consistency assumption of NE to allow decision makers to encounter surprises (because their beliefs of what others will do may not be the same as what others actually do). The self-tuning EWA model captures how decision makers might respond to experience over time when they compete in repeated interactions. All these models come with only one (in most cases) or two additional parameters that can be empirically estimated.

We emphasize that the proposed models are by no means the final or complete models that capture all documented behavioral regularities. Research in psychology and economics is still actively delineating the boundaries of these behavioral regularities (see, e.g., Novemsky and Kahneman [2005] on loss aversion). It is also important to continue to test the predictions of standard models. More tests lead to more facts about when and how the standard models fail (and when they succeed), which are useful because behavioral alternatives are still being proposed and refined. Tests that include rational models as special cases also give estimates of the values of the additional parameters introduced in the behavioral models and can serve as a check of whether these behavioral models are well specified (e.g., showing whether the parameter values obtained from the data are psychologically plausible). The recent trend toward testing well-specified theories in the laboratory (e.g., Amaldoss et al. 2000; Ghosh and John 2000; Ho and Zhang 2004; Lim and Ho 2006; Srivastava, Chakravarti, and Rapoport 2000) is a promising avenue for further research and often makes it easier to separate rational and behavioral predictions clearly.

# Implications for Behavioral Researchers

We believe that it is crucial for behavioral researchers to continue to document robust violations of standard models. However, showing the existence of an important behavioral regularity is only the necessary first step toward its wide applicability in marketing. To receive wide applicability, it is necessary that the regularity be precisely specified in a formal model. This formal specification process requires an active collaboration between behavioral and quantitative researchers. Such collaboration, whether in the form of coauthorship or mutual influence from a common understanding of facts and modeling language, is a promising area for further research. This article also implies that it is important for behavioral researchers to demonstrate important behavioral regularities in the field. The field experimentation approach allows researchers to test the idea that bounded rationality may not survive in the marketplace because it rewards rationality more.

328 JOURNAL OF MARKETING RESEARCH, AUGUST 2006

# Implications for Empirical Researchers

Empirical researchers in marketing have been successful in testing standard economic models using field data sets. We believe that our proposed revised utility functions should be used in future empirical testing because they nest the standard models. The empirical tests will provide useful information as to when and how the standard models fail. We believe that this is an extremely fertile area of research. The QRE and the CH model can be used to study off-equilibrium path behavior in the framework of new empirical industrial organization, which is an active area of research in marketing. These revised models allow researchers to check a foundational assumption of the field empirically; that is, firms always play pure equilibrium strategies and never encounter surprises and make mistakes. We speculate that this standard assumption is likely to be true in mature industries but less so in developing industries. There is also room for applying the EWA learning models to capture how managers and customers learn over time. For example, Ho and Chong (2003) apply the EWA model to predict consumers’ product choices and show that it outperforms several existing models, including that of Guadagni and Little (1983), using an extensive data set involving more than 130,000 purchases across 16 product categories.

# Implications for Analytical Researchers

We believe that there is an opportunity for analytical modelers to incorporate the revised utility functions in their modeling work. For example, it would be fruitful to investigate how a firm’s marketing-mix actions change when it faces a group of customers who have reference-dependent preferences, care about fairness, and are impatient. How would the market structure and degree of competition vary as a result of these changes? We believe that incorporating these changes might provide explanations for what seem like market paradoxes that cannot be explained using standard economic models. For example, Rotemberg (2005) shows that if customers care about fairness, it is optimal for firms to engage in temporary sales events, and they should announce their intention of increasing prices before actually doing so. Similarly, we believe that analytical modelers can apply both QRE and the CH model to analyze how firms might compete in a specific market setting. These models will allow researchers to capture behavior that would otherwise be suppressed by the stringent requirements of no surprises and zero mistakes. Both methods seem particularly promising in modeling rapidly changing product markets and in markets in which firms may not have a sufficient knowledge of actual demand and supply conditions.

# REFERENCES

Ainslie, George (1975), “Specious Reward: A Behavioral Theory of Impulsiveness and Impulse Control,” Psychological Bulletin, 82 (4), 463–96.

Akerlof, George and Janet Yellen (1990), “The Fair Wage-Effort Hypothesis and Unemployment,” Quarterly Journal of Economics, 105 (2), 255–83.

Amaldoss, Wilfred, Robert Meyer, Jagmohan Raju, and Amnon Rapoport (2000), “Collaborating to Compete a Game-Theoretic Model and Experimental Investigation of the Effect of Profit-Sharing Arrangement and Type of Alliance,” Marketing Science, 19 (2), 105–126.

Anderson, Erin and Anne Coughlan (2002), “Channel Management: Structure, Governance and Relationship Management,” in Handbook of Marketing, Barton Weitz and Robin Wensley, eds. London: Sage Publications, 223–47.

Ariely, Dan and Klaus Wertenbroch (2002), “Procrastination, Deadlines, and Performance: Self-Control by Precommitment,” Psychological Science, 13 (3), 219–24.

Barberis, Nicholas and Richard Thaler (2003), “A Survey of Behavioral Finance,” in Handbook of the Economics of Finance, George Constantinides, Milton Harris, and Rene Stultz, eds. Amsterdam: Elsevier Science, North Holland, 1053–1128.

Basu, Amiya, Rajiv Lal, V. Srinivasan, and Richard Staelin (1985), “Salesforce Compensation Plans: An Agency Theoretic Perspective,” Marketing Science, 4 (4), 267–91.

Basu, Kaushik (1994), “The Traveler’s Dilemma: Paradoxes of Rationality in Game Theory,” American Economic Review, 84 (2), 391–95.

Bateman, Ian, Daniel Kahneman, Alistair Munro, Chris Starmer, and Robert Sugden (2005), “Testing Competing Models of Loss Aversion: An Adversarial Collaboration,” Journal of Public Economics, 89 (8), 1561–80.

Baye, Michael and John Morgan (2004), “Price-Dispersion in the Lab and on the Internet: Theory and Evidence,” RAND Journal of Economics, 35 (3), 449–66.

Benartzi, Shlomo and Richard Thaler (1995), “Myopic Loss Aversion and the Equity Premium Puzzle,” Quarterly Journal of Economics, 110 (1), 73–92.

Benzion, Uri, Amnon Rapoport, and Joseph Yagil (1989), “Discount Rates Inferred from Decisions: An Experimental Study,” Management Science, 35 (3), 270–84.

Bolton, Gary and Axel Ockenfels (2000), “ERC: A Theory of Equity, Reciprocity and Competition,” American Economic Review, 90 (1), 166–93.

Bradlow, Eric T., Ye Hu, and Teck-Hua Ho (2004a), “A Learning-Based Model for Imputing Missing Levels in Partial Conjoint Profiles,” Journal of Marketing Research, 41 (November), 369–81.

———, ———, and ——— (2004b), “Modeling Behavioral Regularities of Consumer Learning in Conjoint Analysis,” Journal of Marketing Research, 41 (November), 392–96.

Camerer, Colin (1999), “Behavioral Economics: Reunifying Psychology and Economics,” Proceedings of the National Academy of Sciences, 96 (19), 10575–77.

——— (2001), “Prospect Theory in the Wild: Evidence from the Field,” in Choices, Values and Frames, Daniel Kahneman and Amos Tversky, eds. Cambridge, UK: Cambridge University Press, 288–300.

——— (2003), Behavioral Game Theory: Experiments in Strategic Interaction. Princeton, NJ: Princeton University Press.

——— (2005), “Three Cheers—Psychological, Theoretical, Empirical—for Loss Aversion,” Journal of Marketing Research, 42 (May), 129–33.

# Modeling the Psychology of Consumer and Firm Behavior

———, Linda Babcock, George Loewenstein, and Richard Thaler (1997), “Labor Supply of New York City Cab Drivers: One Day at a Time,” *Quarterly Journal of Economics*, 112 (2), 407–442.

——— and Teck Ho (1998), “EWA Learning in Coordination Games: Probability Rules, Heterogeneity, and Time Variation,” *Journal of Mathematical Psychology*, 42 (2), 305–326.

——— and ——— (1999), “Experience-Weighted Attraction Learning in Normal Form Games,” *Econometrica*, 67 (4), 837–74.

———, ———, and Juin-Kuan Chong (2002), “Sophisticated EWA Learning and Strategic Teaching in Repeated Games,” *Journal of Economic Theory*, 104 (1), 137–88.

———, ———, and ——— (2004), “A Cognitive Hierarchy Model of Games,” *Quarterly Journal of Economics*, 119 (3), 861–98.

———, Samuel Issacharoff, George Loewenstein, and Ted O’Donoghue (2003), “Regulation for Conservatives: Behavioral Economics and the Case for Asymmetric Paternalism,” *University of Pennsylvania Law Review*, 151 (3), 1211–54.

———, George Loewenstein, and Matthew Rabin (2003), *Advances in Behavioral Economics*. Princeton, NJ: Russell Sage Foundation/Princeton University Press.

——— and Dan Lovallo (1999), “Overconfidence and Excess Entry: An Experimental Approach,” *American Economic Review*, 89 (1), 306–318.

——— and Ulrike Malmendier (in press), “Behavioral Economics of Organizations,” in *Economic Institutions and Behavioral Economics*, Peter Diamond and Hannu Vartiainen, eds. Princeton, NJ: Princeton University Press.

Capra, Monica, Jacob Goeree, Rosario Gomez, and Charles Holt (1999), “Anomalous Behavior in a Traveler’s Dilemma?” *American Economic Review*, 89 (3), 678–90.

Charness, Gary and Matthew Rabin (2002), “Understanding Social Preferences with Simple Tests,” *Quarterly Journal of Economics*, 117 (3), 817–69.

Chatterjee, Rabikar and Jehoshua Eliashberg (1990), “The Innovation Diffusion Process in a Heterogeneous Population: A Micro-modeling Approach,” *Management Science*, 36 (9), 1057–1079.

Chen, Keith, Venkat Lakshminarayanan, and Laurie Santos (2005), “The Evolution of Our Preferences: Evidence from Capuchin-Monkey Trading Behavior,” working paper, Yale School of Management.

Chen, Yuxin, Ganesh Iyer, and Amit Pazgal (2005), “Limited Memory and Market Competition,” working paper, Haas School of Business, University of California, Berkeley.

Choi, Sungchul and Paul Messinger (2005), “Edgeworth Promotional Cycles in the Loyal-Switcher Game,” working paper, Marketing Department, University of Alberta.

Chua, Zikang and Colin Camerer (2004), “Experiments on Intertemporal Consumption with Habit Formation and Social Learning,” working paper, Division of Humanities and Social Sciences, California Institute of Technology.

Cui, Haitao, Jagmohan Raju, and John Zhang (2004), “Fairness and Channel Coordination,” working paper, Marketing Department, Wharton School, University of Pennsylvania.

Degeorge, Francois, Jayendu Patel, and Richard Zeckhauser (1999), “Earnings Management to Exceed Thresholds,” *Journal of Business*, 72 (1), 1–33.

Della Vigna, Stefano and Ulrike Malmendier (2004), “Contract Design and Self-Control: Theory and Evidence,” *Quarterly Journal of Economics*, 119 (2), 353–402.

Dufwenberg, Martin and Georg Kirchsteiger (2004), “A Theory of Sequential Reciprocity,” *Games and Economics Behavior*, 47 (2), 268–98.

Ellison, Glenn (2005), “Bounded Rationality in Industrial Organization,” paper presented at the 2005 Econometric Society World Congress, University College London (August 19–24), (accessed April 12, 2006), [available at www.econ.ucl.ac.uk/eswc2005].

Erev, Ido and Alvin Roth (1998), “Predicting How People Play Games: Reinforcement Learning in Experimental Games with Unique Mixed-Strategy Equilibria,” *American Economic Review*, 88 (4), 848–81.

Fehr, Ernst, Alexander Klein, and Klaus Schmidt (2004), “Contracts, Fairness and Incentives,” Discussion Paper No. 2004-07, Department of Economics, University of Munich.

——— and Klaus Schmidt (1999), “A Theory of Fairness, Competition and Cooperation,” *Quarterly Journal of Economics*, 114 (3), 817–68.

Frederick, Shane, George Loewenstein, and Ted O’Donoghue (2002), “Time Discounting and Time Preference: A Critical Review,” *Journal of Economic Literature*, 40 (2), 351–401.

Friedman, James, Thomas Palfrey, and Jacques-Francois Thisse (1995), “Random Choice Behavior in Continuum Models,” research note, Department of Economics, University of North Carolina.

Friedman, Milton (1953), “The Methodology of Positive Economics,” in *Essays in Positive Economics*, Milton Friedman, ed. Chicago: University of Chicago Press, 3–43.

Fudenberg, Drew and David Kreps (1993), “Learning Mixed Equilibria,” *Games and Economic Behavior*, 5 (3), 320–67.

Genesove, David and Christopher Mayer (2001), “Loss Aversion and Seller Behavior: Evidence from the Housing Market,” *Quarterly Journal of Economics*, 116 (4), 1233–60.

Ghosh, Mrinal and George John (2000), “Experimental Evidence for Agency Models of Salesforce Compensation,” *Marketing Science*, 19 (4), 348–65.

Greenleaf, Eric (1995), “The Impact of Reference Price Effects on the Profitability of Price Promotions,” *Marketing Science*, 14 (1), 82–104.

Gruber, Jonathan and Botond Koszegi (2001), “Is Addiction Rational? Theory and Evidence,” *Quarterly Journal of Economics*, 116 (4), 1261–1305.

Guadagni, Peter and John Little (1983), “A Logit Model of Brand Choice Calibrated on Scanner Data,” *Marketing Science*, 2 (3), 203–238.

Hardie, Bruce, Eric Johnson, and Peter Fader (1993), “Modeling Loss Aversion and Reference Dependence Effects on Brand Choice,” *Marketing Science*, 12 (4), 378–94.

Heidhues, Paul and Botond Koszegi (2005), “The Impact of Consumer Loss Aversion on Pricing,” working paper, Department of Economics, University of California, Berkeley.

Ho, Teck, Colin Camerer, and Juin-Kuan Chong (in press), “Self-Tuning Experience Weighted Attraction Learning in Games,” *Journal of Economic Theory*.

———, ———, and Keith Weigelt (1998), “Iterated Dominance and Iterated Best-Response in p-Beauty Contests,” *American Economic Review*, 88 (4), 947–69.

——— and Juin-Kuan Chong (2003), “A Parsimonious Model of SKU Choice,” *Journal of Marketing Research*, 40 (August), 351–65.

——— and Noah Lim (2004), “A Theory of Lowest-Price Guarantees,” working paper, Marketing Department, Haas School of Business, University of California, Berkeley.

——— and Juan-Juan Zhang (2004), “Does the Format of Pricing Contracts Matter?” working paper, Marketing Department, Haas School of Business, University of California, Berkeley.

Hoch, Stephen and George Loewenstein (1991), “Time-Inconsistent Preferences and Consumer Self-Control,” *Journal of Consumer Research*, 17 (4), 492–507.

Holcomb, James and Paul Nelson (1992), “Another Experimental Look at Individual Time Preference,” *Rationality and Society*, 4 (2), 199–220.

Jain, Sanjay and Joydeep Srivastava (2000), “An Experimental and Theoretical Investigation of Price-Matching Refund Policies,” *Journal of Marketing Research*, 37 (August), 351–62.

Jeuland, Abel and Steven Shugan (1983), “Managing Channel Profits,” *Marketing Science*, 2 (3), 239–72.

# JOURNAL OF MARKETING RESEARCH, AUGUST 2006

Kahneman, Daniel, Jack Knetsch, and Richard Thaler (1990), “Experimental Tests of the Endowment Effect and the Coase Theorem,” Journal of Political Economy, 98 (6), 1325–48.

——— and Amos Tversky (1979), “Prospect Theory: An Analysis of Decision Under Risk,” Econometrica, 47 (2), 263–91.

——— and ——— (1992), “Advances in Prospect Theory: Cumulative Representation of Uncertainty,” Journal of Risk and Uncertainty, 5 (4), 297–324.

Kalyanaram, Gurumurthy and Russell Winer (1995), “Empirical Generalizations from Reference Price and Asymmetric Price Response Research,” Marketing Science, 14 (3), G161–69.

Kivetz, Ran, Oded Netzer, and V. Srinivasan (2004), “Alternative Models for Capturing the Compromise Effect,” Journal of Marketing Research, 41 (August), 237–57.

Koszegi, Botond and Matthew Rabin (2004), “A Model of Reference-Dependent Preferences,” working paper, Department of Economics, University of California, Berkeley.

Laibson, David (1997), “Golden Eggs and Hyperbolic Discounting,” Quarterly Journal of Economics, 112 (2), 443–77.

Leeflang, Peter, Dick Wittink, Michel Wedel, and Philippe Naert, eds. (2000), Building Models for Marketing Decisions. New York: Kluwer Academic Publishers.

Lim, Noah and Teck Ho (2006), “Designing Price Contracts for Boundedly Rational Customers: Does the Number of Blocks Matter?” working paper, Marketing Department, Haas School of Business, University of California, Berkeley.

Little, John (1970), “Models and Managers: The Concept of a Decision Calculus,” Management Science, 16 (8), B466–85.

Loewenstein, George (1987), “Anticipation and the Valuation of Delayed Consumption,” Economic Journal, 97 (387), 666–84.

——— and Drazen Prelec (1992), “Anomalies in Intertemporal Choice: Evidence and an Interpretation,” Quarterly Journal of Economics, 107 (2), 573–97.

——— and ——— (1993), “Preferences for Sequences of Outcomes,” Psychological Review, 100 (1), 91–108.

——— and Richard Thaler (1989), “Anomalies: Intertemporal Choice,” Journal of Economic Perspectives, 3 (4), 181–93.

Mayhew, Glenn and Russell Winer (1992), “An Empirical Analysis of Internal and External Reference Price Effects Using Scanner Data,” Journal of Consumer Research, 19 (1), 62–70.

McClure, Samuel, David Laibson, George Loewenstein, and Jonathan Cohen (2004), “Separate Neural Systems Value Immediate and Delayed Monetary Rewards,” Science, 306 (5695), 503–507.

McFadden, Daniel (1999), “Rationality for Economists,” Journal of Risk and Uncertainty, 19 (1–3), 73–105.

McKelvey, Richard and Thomas Palfrey (1995), “Quantal Response Equilibria for Normal Form Games,” Games and Economic Behavior, 10 (1), 6–38.

Moorthy, Sridhar (1985), “Using Game Theory to Model Competition,” Journal of Marketing Research, 22 (August), 262–82.

——— (1987), “Managing Channel Profits: Comment,” Marketing Science, 6 (4), 375–79.

Nagel, Rosemarie (1995), “Unraveling in Guessing Games: An Experimental Study,” American Economic Review, 85 (5), 1313–26.

Narasimhan, Chakravarti (1988), “Competitive Promotional Strategies,” Journal of Business, 61 (4), 427–49.

Novemsky, Nathan and Daniel Kahneman (2005), “The Boundaries of Loss Aversion,” Journal of Marketing Research, 42 (May), 119–28.

Odean, Terence (1998), “Are Investors Reluctant to Realize Their Losses?” Journal of Finance, 53 (5), 1775–98.

O’Donoghue, Ted and Matthew Rabin (1999a), “Addiction and Self-Control,” in Addiction: Entries and Exits, Jon Elster, ed. New York: Russell Sage Foundation, 169–206.

——— and ——— (1999b), “Doing It Now or Later,” American Economic Review, 89 (1), 103–124.

# Modeling the Psychology of Consumer and Firm Behavior

Thaler, Richard (1980), “Toward a Positive Theory of Consumer Choice,” Journal of Economic Behavior and Organization, 1 (1), 39–60.

——— (1981), “Some Empirical Evidence on Dynamic Inconsistency,” Economic Letters, 8 (3), 201–207.

Tovar, Patricia (2004), “The Effects of Loss Aversion on Trade Policy and the Anti-Trade Bias Puzzle,” working paper, Economics Department, University of Maryland.

Tversky, Amos and Daniel Kahneman (1991), “Loss Aversion in Riskless Choice: A Reference-Dependent Model,” Quarterly Journal of Economics, 106 (4), 1039–1061.

——— and Itamar Simonson (1993), “Context-Dependent Preferences: The Relative Advantage Model,” Management Science, 39 (10), 1179–89.

Van Huyck, John, Raymond Battalio, and Richard Beil (1991), “Strategic Uncertainty, Equilibrium Selection and Coordination Failure in Average Opinion Games,” Quarterly Journal of Economics, 106 (3), 885–911.

Von Neumann, John and Oskar Morgenstern (1944), The Theory of Games and Economic Behavior. Princeton, NJ: Princeton University Press.

Weber, Martin and Colin Camerer (1998), “The Disposition Effect in Securities Trading: An Experimental Analysis,” Journal of Economic Behavior and Organization, 33 (2), 167–84.

Wertenbroch, Klaus (1998), “Consumption Self-Control by Rationing Purchase Quantities of Virtue and Vice,” Marketing Science, 17 (4), 317–37.

Winer, Russell (1986), “A Reference Price Model of Demand for Frequently Purchased Products,” Journal of Consumer Research, 13 (2), 250–56.

Zauberman, Gal and John Lynch (2005), “Resource Slack and Discounting of Future Time Versus Money,” Journal of Experimental Psychology, 134 (1), 23–37.

Copyright of Journal of Marketing Research (JMR) is the property of American Marketing
Association and its content may not be copied or emailed to multiple sites or posted to listserv
           copyright holder" express written permission.                   print,
without the                                             However_ Users may       download,
email articles for individual Use_

