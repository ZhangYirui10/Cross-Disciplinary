# Effective Keyword-based Selection of Relational Databases

# Bei Yu

# Guoliang Li

# Karen Sollins

# National University of Singapore

# Tsinghua University

# MIT

# Anthony K. H. Tung

# National University of Singapore

# ABSTRACT

The wide popularity of free-and-easy keyword based searches over World Wide Web has fueled the demand for incorporating keyword-based search over structured databases. However, most of the current research work focuses on keyword-based searching over a single structured data source. With the growing interest in distributed databases and service oriented architecture over the Internet, it is important to extend such a capability over multiple structured data sources. One of the most important problems for enabling such a query facility is to be able to select the most useful data sources relevant to the keyword query. Traditional database summary techniques used for selecting unstructured data sources developed in IR literature are inadequate for our problem, as they do not capture the structure of the data sources. In this paper, we study the database selection problem for relational data sources, and propose a method that effectively summarizes the relationships between keywords in a relational database based on its structure. We develop effective ranking methods based on the keyword relationship summaries in order to select the most useful databases for a given keyword query. We have implemented our system on PlanetLab. In that environment we use extensive experiments with real datasets to demonstrate the effectiveness of our proposed summarization method.

Categories and Subject Descriptors: H.2 [Database Management]: Miscellaneous

General Terms: Design

Keywords: keyword query, summarization, database selection

# 1. INTRODUCTION

Keyword search over structured data such as relational databases is an increasingly important capability, taking advantage of a combination of DB and IR techniques. While these projects focus on keyword-based query processing in a centralized database, the increasing deployment of P2P networks and service oriented architectures has made it equally important to extend such keyword-based search capabilities to distributed databases. Analogous to distributed IR systems, keyword-based database selection is a critical step towards locating useful databases for answering a keyword query, and on which existing centralized keyword search methods can be directly applied.

For effective selection of useful data sources in distributed IR systems, a common approach is to summarize document collections with a list of keywords associated with some intra-collection (e.g., frequency) or inter-collection (e.g., inverse collection frequency (ICF)) weightings. Data sources are then ranked by comparing the keyword queries with their summaries, which can be stored either at the data sources or the querying clients (allowing for different tradeoffs in terms of communication cost and workload size).

Summarizing a relational database with the simple keyword-list method as in IR systems is, however, inadequate for two reasons. First, relational tables in a database are typically normalized. Therefore, the keyword frequency statistics, which are used in most IR-based summaries for textual documents, cannot really measure the importance of keywords in a relational database. Consider the case where a keyword appears only once, and it is in a tuple that is referenced by many other tuples. Such a keyword is likely to be important since it is related to many other keywords in the connected tuples. Second, the results from a relational database with respect to a keyword query must take into account the number of join operations that must be done in order for all the keywords to appear in the result (often represented as an evaluation tree). This can only be obtained if the relationship between keywords in the relational database is somehow captured in the summary.

For illustration, let us look at the two example databases DB1 and DB2 shown in Figure 1, in which the arrowed lines drawn between tuples indicate their connections based on foreign key references. Suppose we are given a keyword query Q = {multimedia, database, V LDB}. We can observe that DB1 has a good result to Q, which is the result of joining tuple t₁ with t₃. On the contrary, DB2 cannot provide relevant results to Q — there are no trees of connected tuples containing all the query keywords. But, if we evaluate the two databases for Q based on the keyword frequency...

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

SIGMOD’07, June 12–14, 2007, Beijing, China. Copyright 2007 ACM 978-1-59593-686-8/07/0006 ...$5.00.

style summaries (denoted as KF-summary in this paper, where Ti is the i-th top result of DB given Q, and score(Ti, Q) measures the relevance of Ti to Q. KF-summary(DB1) = { · · · multimedia:1, database:2, VLDB:1, · · · }, and KF-summary(DB2) = { · · · multimedia:3, database:3, VLDB:1, · · · }), DB2 will be selected over DB1. Therefore, we can observe that the usefulness of a relational database in answering a keyword query is not only decided by whether it has all the query keywords, but more importantly, it depends on whether the query keywords can be connected meaningfully in the database.

In this paper, we define keyword relationship for representing such connections between keywords in a relational database and look at how summarizing keyword relationships can help us to effectively select relevant structured sources in a distributed setting. This work is part of our BestPeer project [25] for supporting P2P-based data sharing services. BestPeer is a P2P platform that can be configured to support either structured [18] and unstructured overlays, and it provides a set of tools for building data sharing applications.

# Contributions

We make the following contributions in this paper.

- We propose to look at the problem of structured data resources selection for keyword based queries. To the best of our knowledge, this is the first attempt to address this problem.
- We propose a method for summarizing the relationship between keywords in a relational database. The technique for generating the database summary can be done by issuing SQL statements and thus can be performed directly on the DBMS without modification to the database engine.
- We define metrics for effectively ranking source databases given a keyword query according to the keyword relationship summary.
- We implemented the system in real distributed settings on PlanetLab [7] and evaluate the effectiveness of the proposed summarization method with real datasets.

The rest of the paper is organized as follows. In Section 2, we present the way to discover the relationships between keywords in a relational database in order to effectively evaluate its usefulness in answering a given keyword query. We also show how to create the keyword relationship summary using SQL. In Section 3, we describe the metrics to rank databases based on the keyword relationship summaries. We present our experimental study in Section 4. Then, we discuss related work in Section 5 and conclude the paper and discuss our future work in Section 6.

# 2. SUMMARIZING A RELATIONAL DATABASE

We consider a set of relational databases {DB₁, DB₂, · · ·, DBN}. Given a keyword query Q = (k₁, k₂, · · ·, kq), we would like to rank the databases based on their usefulness to answer query Q. Basically, a database is useful given Q if it has high quality results to the keyword query. Therefore, we measure the usefulness of a database DB to Q as the total score of the top-K results it can return, i.e.,

score(DB, Q) = ∑i=1K score(Ti, Q), (2-1)

Based on the observation above, we measure the strength of keyword relationships between each pair of different keywords according to the combination of two factors — the proximity factor and the frequency factor. The proximity factor is defined as a parameter that is inverse to the distance of the joining sequence that connects the two keywords. The frequency factor, with respect to a particular distance d, is the number of combinations of exactly d + 1.

# Inproceedings

# Conferences

|id|inprocID|title|procID|year|month|annote|id|procID|Conference|
|---|---|---|---|---|---|---|---|---|---|
|t1|Adibal986|Historical Multimedia Databases|23|1988|Aug|temporal|tz|23|the Conference on VeryLarge Databases (VLDB)|
|Abarbanel|Connections Perspective|18|1987|May|Intellicorp|t4|18|ACM SIGMOD Conf. on the Management of Data| |

# (a) DB1

# citKeywd

|titles|id|citKey|keyWdId|
|---|---|---|---|
|t1|A Multimedia Component Kit|Mey93a|2|
| |Managing Distributed Databases|Burl94a|302|
| |Activity Model: A Declarative Approach for Capturing Communication Behaviour in Object-Oriented Database|Liu92b|t4|
| |Direct Manipulation of Temporal Structures in a Multimedia Application Framework|Acke94a| |

# (b) DB2

Figure 1: Example databases

number of distinct tuples that can be joined in a sequence between tuples. The entry T[i, j] of 1 denotes that tuple ti references (or is referenced by) tuple tj (1 ≤ i, j ≤ n).

In this manner, each database is summarized by a list of keyword pairs that have significant relationship scores. We will present how to discover and create such relationships between keywords in the following two subsections.

# 2.1 KRM: The Keyword Relationship Matrix

We model each relational database DB as two matrices D(m × n) and T(n × n), where m is the number of distinct keywords contained in all the tuples t ∈ DB, and n is the total number of tuples.

The D matrix, illustrated as:

D = (dij) =

|k1|1|0|0|0|
|---|---|---|---|---|
|k2|0|1|1|0|
|km|1|0|0|0|

represents the presence or absence of each keyword in each tuple in DB. This is closely related to the term-document matrix of the vector space model (VSM) in IR literature, with the change that documents are replaced by tuples in a relational database, in our work. Although there are also various weighting schemes developed by IR and DB community for measuring the importance of the keywords in either documents or tuples [13, 21, 27], in our case we have simplified this to being only 0 or 1 for absence or presence.

The T matrix, shown below:

T = (tij) =

|t1|0|1|1|0|
|---|---|---|---|---|
|t2|1|0|0|0|
|tn|1|0|0|0|

represents the relationships between tuples in a relational database, the most obvious kind being foreign key reference.

It is obvious that when two keywords are further apart based on the number of join operations, the relationship between them is weaker. Accordingly, ϕd should be a monotonically decreasing function with respect to increasing d. We propose to set ϕd as:

ϕd = 1 / (d + 1).

Note that ϕd could also be set differently based on specific requirements.

In this way, the KRM measures the total scores of up to top-K results within δ distance for each pair of keywords as query in a relational database, where each result, a joining sequence, has the score ϕd. A database with a higher relationship score for a given pair of keywords will generate better results. The reason we set an upperbound of the number of results, K, is to enable a user to control the quality of the results. For example, if for a pair of keywords k1 and k2, one database A has 5 joining sequences to connect k1 and k2 at 1 distance, and the other database B has 40 joining sequences to connect k1 and k2 at 4 distance. If K = 40, the score of the pair in A is 5 × 1 = 2.5, while the score of B is 40 × 1 = 8, as a result, we will choose B over A. However, one may very possibly prefer A to B because it has results with higher quality. If we decrease K to 10, the score of A is the same, but the score of B now becomes 10 × 1 = 2, such that A can be ranked higher than B. In general, K defines the number of top results users expected from a database.

# 2.2 Computation of KRM

We next look at how the KRM can be computed, i.e., ωd(ki, kj) between every pair of keywords ki and kj in DB. As said, we can derive such information based on D and T. We first define the d-distance tuple relationship matrix as follows.

Definition 2. The d-distance tuple relationship matrix, denoted as Td(n × n), is a symmetric matrix with binary entries, such that for any 1 ≤ i, j ≤ n and i ≠ j, Td[i, j] = Td[j, i] = 1 if and only if the shortest joining sequence to connect the two tuples ti and tj is of distance d, and Td[i, j] = 0, otherwise. According to the definition, Td actually records whether there is a shortest path with d hops between any pair of two tuples in a database, if we view the database as a graph in which the nodes are the tuples and the edges between nodes denote the reference relationships between tuples. Obviously, T1 = T, and T1 ∪ T2 ∪ · · · ∪ T∆ is the transitive closure of T1, where ∆ is the longest distance of the path between two tuples in the database graph. Taking database DB2 in Figure 1 as an example, its tuple relationship matrices T1, T2, and T3 are shown in Figure 2.

# Proposition 1.

Let Td₁ and Td₂(d1 = d2) be two tuple relationship matrices in a database. For any i and j, i ≠ j, if Td₁[i, j] = 1, then Td₂[i, j] = 0. From Proposition 1, we derive matrices T2, T3, · · ·, inductively, based on T1 = T.

# Proposition 2.

Given T1 = Td, and supposing Td = Td T1, we have for all 1 ≤ i, j ≤ n and i ≠ j, Td+1[i, j] = 0 if T1[i, j] = 1, if T1[i, j] = 0 and ∃r(1 ≤ r ≤ n), Td[i, r] ∗ T1[r, j] = 1.

Proof. Suppose we already have Td (d ≥ 1), and we can get T1 = ∨d Tk. When Td[i, j] = 1, it implies ∃k(1 ≤ k ≤ d), Tk[i, j] = 1. According to Proposition 1, for any 1 ≤ k ≤ d, when Tk[i, j] = 1, Td+1[i, j] = 0. Therefore, T1[i, j] = 1 implies Td+1[i, j] = 0. When T1[i, j] = 0, it means tuples ti and tj must be connected with more than d number of connections. If there is a maximum distance parameter δ and the upperbound of the number of desired results, K, the relationship score between each pair of keywords ki and kj, rel(ki, kj), in a database DB can be computed according.

# 2.3.2 Creation of T₁, T₂, · · ·, Tδ

|keyword pair|d = 0|d = 1|d = 2|d = 3|d = 4|
|---|---|---|---|---|---|
|database:multimedia|1|1|-|-|-|
|multimedia:VLDB|0|1|-|-|-|
|database:VLDB|1|1|-|-|-|

(a) Frequencies of keyword pairs in DB1

|keyword pair|d = 0|d = 1|d = 2|d = 3|d = 4|
|---|---|---|---|---|---|
|database:multimedia|0|0|0|0|2|
|multimedia:VLDB|0|0|0|0|0|
|database:VLDB|0|0|1|0|0|

(b) Frequencies of keyword pairs in DB2

# Figure 3: Compare the frequencies of keyword pairs of DB1 and DB2 in Figure 1 at distances d = 0, 1, 2, 3, 4

|keyword pair|DB1|DB2|
|---|---|---|
|database:multimedia|1.5|0.4|
|multimedia:VLDB|0.5|0|
|database:VLDB|1.5|0.33|

# Figure 4: Compare the relationship scores of keyword pairs of DB1 and DB2 in Figure 1

to Definition 1, i.e., rel(ki, kj) = R[i, j]. The higher the score, the stronger the relationship between them. For the two databases DB1 and DB2 in Figure 1, the relationship scores of the query keyword pairs are shown in Figure 4, where we set δ = 4 and K = 10.

# 2.3 Implementation with SQL

The generation of the matrices D, T₁, T₂, · · ·, Tδ and W₀, · · ·, Wδ, for each DB, can be performed conveniently inside the local RDBMS using SQL.

# 2.3.1 Creation of D

We use relation RD(kId, tId) to represent the non-zero entries of the D matrix. Each record (kId, tId) corresponds to the occurrence of a keyword (kId) in a tuple (tId). A separate table RK(kId, keyword) stores all the keywords and their associated ids in the database. These two relations can be populated by scanning all the native tables of the local database, parsing each tuple to extract the keywords, removing stop words, stemming each keyword, and inserting the keyword id (kId) and tuple id (tId) pair into RD(kId, tId) and the pair of kId and keyword into RK(kId, keyword). (Each native table is inserted with a field tId as the identity of the tuples in the database.)

The main cost includes a sequential read of all the tuples, and two sequential writes of the tables RK and RD.

# 2.3.3 Creation of W₀, W₁, · · ·, Wδ

W₀ is represented with a relation RW₀(kId1, kId2, freq), where tuple (kId1, kId2, freq) records the pair of keywords (kId1,kId2)(kId1 < kId2) and its frequency (freq).

# Figure 5: SQL for creating RT₃

INSERT INTO RT3 (tId1, tId2)
SELECT s1.tId1, s2.tId2
FROM RT2 s1, RT1 s2
WHERE s1.tId2 = s2.tId1;

INSERT INTO RT3 (tId1, tId2)
SELECT s1.tId1, s2.tId1
FROM RT2 s1, RT1 s2
WHERE s1.tId2 = s2.tId2 AND s1.tId1 < s2.tId1;

INSERT INTO RT3 (tId1, tId2)
SELECT s2.tId1, s1.tId2
FROM RT2 s1, RT1 s2
WHERE s1.tId1 = s2.tId2;

INSERT INTO RT3 (tId1, tId2)
SELECT s1.tId2, s2.tId2
FROM RT2 s1, RT1 s2
WHERE s1.tId1 = s2.tId1 AND s1.tId2 < s2.tId2;

DELETE a FROM RT3 a, RT2 b, RT1 c
WHERE (a.tId1 = b.tId1 AND a.tId2 = b.tId2) OR
(a.tId1 = c.tId1 AND a.tId2 = c.tId2);

INSERT INTO RW0 (kId1, kId2, freq)

SELECT s1.kId AS kId1, s2.kId AS kId2, count(*)

FROM RD s1, RD s2

WHERE s1.tId = s2.tId AND s1.kId &lt; s2.kId

GROUP BY kId1, kId2

Figure 6: SQL for creating RW0

INSERT INTO RWd(kId1, kId2, freq)

SELECT s1.kId AS kId1, s2.kId AS kId2, count(*)

FROM RD s1, RD s2, RTd r

WHERE ((s1.tId = r.tId1 AND s2.tId = r.tId2) OR (s1.tId = r.tId2 AND s2.tId = r.tId1)) AND s1.kId &lt; s2.kId

GROUP BY kId1, kId2

Figure 7: SQL for creating RWd

at 0 distance, where freq is greater than 0. RW0 is the result of self-joining RD(kId, tId). The SQL statement for

Similarly, W0 is shown in Figure 6.

RWd (1 ≤ d ≤ δ) is represented as a relation Wd(kId1, kId2, freq). Its records are populated by joining RD and RTd. Figure 7 shows the SQL statement.

The dominating cost for creating RWd (0 ≤ d ≤ δ) is the cost used for grouping the tuples resulted from the WHERE clause according to (kId1, kId2), as sorting is needed in order to group the same keyword pairs together. The total space overhead for storing RW0, RW1, · · ·, RWδ is at most 3m2, where m is the total number of distinct keywords, with kId using 3-byte unsigned integer. The actual storage will be much less, since only a small portion of keyword pairs will have relationships within δ distance.

The final resulting KRM, R, is stored in a relation RR(kId1, kId2, score), consisting of pairs of keywords and their relationship score, where the score is greater than 0. It is the union of RW0, RW1, · · ·, and RWδ with the score of each distinct keyword pair calculated according to Deﬁnition 1 and Equation 2-2. The keyword pairs and their associated scores stored in RR are the keyword relationship summary of the local database, which we named as KR-summary. A threshold τ can also be specified such that only the keyword pairs with relationship scores greater than τ will be exported.

# 2.3.4 Update issues

The tables for storing the matrices D, T1, T2, · · ·, Tδ and W0, W1, · · ·, Wδ, can be maintained dynamically when new tuples are added to the database or old tuples are deleted.

When a new tuple t is inserted into a table in DB, we can find out its relationships with other related tuples at various distances step by step. First, we identify the set of tuples that directly reference (or are referenced by) t, denoted as S1, and insert all the pairs — t with each tuple in S1 — into the table RT1. Then, we can further get the set of tuples, S2, that are directly connected to any one of the tuples in S1, and they have 2-distance relationships with t. So we insert the corresponding pairs into RT2. In addition, since the tuples in S1 are all connected to t, they themselves are connected to each other at 2 distance. Therefore, we also insert the pairs of tuples from S1 into RT2. We can repeat the process until RTδ is updated. Update of RW0, RW1, · · ·, and RWδ can be done together with the update of corresponding RTd, with the keywords pairs appearing in the affected tuples.

When a tuple t is deleted from a table in DB, we similarly first identify the set of tuples, S1, that directly refer to t.

relsum(Q, DB) =         ∑    rel(ki, kj),                   (3-5)
                         {ki,kj}⊆Q,i<j
                               ∏
       relprod(Q, DB) =             rel(ki, kj).                   (3-6)
                         {ki,kj}⊆Q,i<j
These estimations assume diﬀerent degrees of intersections
of the joining sequences for connecting pairs of query key-
words in the database, where intersections between joining
sequences of keyword pairs lead to steiner trees that contain
all the keywords.   The  relmin(Q) is most conservative as
it assumes few intersections, while               relprod(Q) assumes the
highest degree of intersection. Note that since these estima-
tions are only used for ranking, their accuracy compared to
the actual value is not so important as long as the ranking
is correct and we will show that this is the case in the exper-
iment section.              Interested readers are referred to [8] which
in the same spirit demonstrates why simple Bayesian clas-
siﬁer works well even on datasets where the assumption of
attribute independency is invalid.
3.2    Databases ranking and indexing
                    With the KR-summary, we can eﬀectively rank a set of
databases D = {DB₁, DB₂,· · · , DBN} for a given keyword
query.                   Speciﬁcally, the ranking is a mapping from D to
{1, 2,· · · , N}, such that rank(DBi) < rank(DBj) ⇔                  rel
(Q, DB ) ≥   rel (Q, DB  ), where                rel(Q, DB ) denotes the
       i                j                    i
relationship score of Q in DBi. With a user provided num-
ber  l, we can select the top l                 number of databases with
highest ranks.
                   In order to support eﬃcient ranking, we have diﬀerent
choices of indexing mechanism depending on the network
structure. We generalize them into two types.
Global Index
For eﬃcient selection of the top                l number of databases, a
global index can be built on the summaries of local source
databases.                 The index contains a list of distinct keyword
pairs that appear in the local database summaries.                  In a
manner similar to the “inverted ﬁle” used in IR, for each
keyword pair, there is an inverted list of pairs containing
the source database identiﬁer in which the pair of keywords
appears and the relationship score between them in that
database. A keyword query Q    of multiple keywords is eval-
uated by fetching the inverted lists for each pair of diﬀerent
keywords in Q, and then intersecting the lists of database
identiﬁers and calculating the relationships scores for each
database. As the page accesses for answering a query through
the index is typically O(logn), a global index for keyword
pairs is expected to have at most 2 times more page accesses
comparing to a simple keyword index when answering key-
word based query.
            A global index is typically stored in a central server which
querying clients will submit their queries to.            As it is, this
paradigm is well studied and our interest in this paradigm
will be limited to the discussion here.
Decentralized Index
Another possible paradigm is a decentralized index where
query clients are communicating with each other and are
able to share the indexing workload.                A typical example of
this paradigm is a peer-to-peer (P2P) network. In this case,
the global index can be distributed among the peers and
each of them can store a certain portion of the keyword
pairs and the associated inverted lists.
               To do so, each local database is attached to the P2P net-
                                                             145
work or to a server node in the network, and publishes its
summary, i.e., the keyword pairs and the associated scores,
which are disseminated to other nodes.       When a query is
received at some node, a set of search messages is sent out
for each pair of keywords in the query. The corresponding
inverted lists are returned from diﬀerent nodes in order that
the most useful databases can be selected. For experimental
purpose, in the next section, we evaluate our implementa-
tion of this paradigm over Chord [28], a DHT-based P2P
overlay system in order to see the usefulness and feasibility
of KR-summary being applied in such a context.
4. EXPERIMENTS

    In order to evaluate the performance of our proposed ap-
proach for the selection of relational databases, we have im-
plemented the system over PlanetLab [7], which is a testbed
for large-scale distributed systems. All codes are written in
Java. We built the distributed index for KR-summaries over
a Chord-based [28] P2P network as described in Section 3.2.
We selected sixteen physical nodes on Planetlab in various
areas, and each physical node is used to simulate several to
hundreds of Chord nodes, where each Chord node shares
one relational database. 1
We use real life DBLP      dataset to generate 82 relational
databases by dividing the whole dataset according to dif-
ferent bibliography types such as inproceedings,   articles,
books, etc..      Figure 8 shows the schema of the databases
storing inproceedings papers.    The schemas of other bibli-
ography types are similar. There is no overlap between dif-
ferent generated databases.     The average number of tuples
per database is 46735, and the average number of distinct
keywords extracted from each database is 19817, after re-
moving stop words and stemming. The numbers of tuples
of diﬀerent databases are similar. Keyword queries are com-
posed of randomly selected keywords from the databases.
We tested with a set of 112 queries in total, which consists
of 30 2-keyword queries, 34 3-keyword queries, 21 4-keyword
queries, and 27 5-keyword queries.
       We use MySQL² to store all the databases and generate
KR-summaries for them.

  Conferences   Papers (pId,   AuthorOf
  (cId name)    title, year; cId)  (pId ald)

                 Citations     Authors
                 (pIdL, pId2)  (ald, name)
Figure 8: Schema of the databases storing inpro-
ceedings papers of DBLP dataset

4.1  Effectiveness of the KR-summary

    To evaluate the eﬀectiveness of KR-summary on relational
databases selection, we compare our method with the brute
force selection, that is, sending the given query to all the
source databases, which process the query and return top-
K results, in order that we can get the “real” score of each
database based on Equation 2-1.      Note that the execution
time of such a brute force selection is orders of magnitude
longer than that of the summary-based selection. With the
real score, we deﬁne the real ranking    of the databases as

1http://dblp.uni-trier.de/
2http://www.mysql.com/

real_rank(DBi) &lt; real_rank(DBj) ⇔ real_score(Q, DBi) ≥ real_score(Q, DBj).

Our algorithm for processing keyword query on a relational database is implemented based on the approach of the DISCOVER project [13, 14] and [21].

To compare our estimated ranking with real ranking, we use the metrics defined in IR for evaluating text data source selection algorithms [12, 26], which is in the same style as the well known precision and recall definitions. The recall is defined as

recall(l) =

∑DB∈T op(S) score(Q, DB)

l

∑DB∈T opl(R) score(Q, DB)

where S and R denote summary-based rankings and real rankings of all the source databases respectively, while T opₗ(S) and T opₗ(R) represent the l databases with highest ranks in S and R. Note that score(Q, DB) is the real score generated according to formula 2-1. This recall definition compares the accumulated score of the top l databases selected based on the summaries of the source databases against the total available score when we select top l databases according to the real ranking. The precision measure is defined as

precision(l) =

|{DB ∈ T op(S)|score(Q, DB) &gt; 0}|

l

|T op(R)|

l

It measures the fraction of the top l selected databases with non-zero real scores, which have results with acceptable quality (controlled by K) to the query.

We also compare the effectiveness of our KR-summary against the keyword frequency summary, which is typically used as the summary of textual document collection for text data source selection in IR [12], denoted as KF-summary. The KF-summary of each relational database is a list of keywords that appear in the database associated with their frequencies, i.e., the number of tuples that contain the keyword. Based on the KF-summary, we estimate the score of a database DB for a given query Q = {k₁, k₂,· · · , kq} in two ways. One is by summing the frequencies of all query keywords in DB, i.e.,

kf_scoresum(Q, DB) =

∑i=1q freq(ki)

The other is to take the product of the frequencies, i.e.,

kf_scoreprod(Q, DB) =

∏i=1q freq(ki)

We study the effectiveness of our method along three dimensions. First, we examine the impact of δ on the ranking quality by comparing the precision and recall of the rankings generated with different values of δ. Second, we compare the ranking effectiveness for queries with different number of keywords. Third, we compare the performance of the four different estimations, MIN, MAX, SUM, and PROD, which correspond to the formulas 3-3, 3-4, 3-5, and 3-6, for measuring the relationship on multiple keywords.

# 4.1.1 Effects of δ

Figure 9 shows the average precisions and recalls of 2-keyword queries with KR-summary when δ is set to 0, 1, 2, 3, and 4, separately, and with KF-summary. We have the following three observations with regard to the effects of δ. First, the selection performance of KR-summaries generally gets better when δ grows larger. When δ = 4, both precision and recall stay close to 1. Second, the precision and recall performance for different values of δ tends to cluster into groups. We can see that the precisions and recalls of KR-summaries when δ = 0 and δ = 1 are in a group and belong to another group when δ is set to 2 and 3. Third, there are big gaps in both precisions and recalls between KR-summaries when 0 ≤ δ ≤ 1 and when δ is greater.

These phenomena should all be related to the sizes of the KR-summaries with different δ values, i.e., the numbers of keyword pairs in the summaries. When δ is larger, there will be more keyword pairs and thus the KR-summary can capture more relationships between keywords, which results in better performance. However, it is not true that increasing δ will always result in an increase of the size of KR-summary. On the contrary, the size is largely dependent on the structure of the databases. With our data set, the sizes of KR-summaries with δ equals to 0 and 1 do not vary much, likewise for KR-summaries with δ set to 2 and 3. However, when δ is increased from 1 to 2, there is a big increase of the size of KR-summaries. To explain this, let’s refer to the schema shown in Figure 8. The 2-distance joining sequences include the results of Papers ./ AuthorOf ./ Authors, Papers ./ Citations ./ Papers, Papers ./ Conferences ./ Papers, and Authors ./ AuthorOf ./ Authors, all which will lead to lots of keyword pairs as the tables Papers, Conferences, and Authors are all text-rich. This explains the similarities of the performance between δ = 0 and δ = 1, between δ = 2 and δ = 3, and also the big jump in the performance between δ = 1 and when δ is set higher.

In addition, we can see from Figure 9 that KF-summary with production estimation (formula 4-8) outperforms that with summation estimation (formula 4-7). However, comparing the performance of KR-summary and KF-summary, we find that the former can do much better. For example, when l = 3, KR-summary with δ = 2 and δ = 3 outperforms KF-summary 67% in precision and 28% in recall, while KR-summary with δ = 4 improves 43% over KF-summary in recall. As we have explained, the inferior performance of KF-summary is due to the existence of many “false positives” in its results, since it cannot identify unrelated keywords in the databases.

Another notable phenomena is that in Figure 9(a), the recall of KR-summary when δ = 2 and δ = 3 declines as l increases, while the recall of KF-summary increases, such that it outperforms KR-summary (δ = 2 and δ = 3) slightly when l is greater than 8. This shows that KR-summary (δ = 2 and δ = 3) tends to rank databases with higher scores below those with lower scores when l is larger. This should be attributed to insufficient keyword relationship information in the KR-summary for small δ, and hence it underestimates the scores of some databases. However, it can still identify databases with very good scores, which is revealed in its high recall when l is small. This is because very relevant databases tend to contain results of small sizes, which has already been captured in the KR-summary with smaller δ.

We next perform the same test with keyword queries consisting of more keywords. Figure 10 shows the results of queries with 3 to 5 keywords. Similar to Figure 9, the curves of δ = 0 and δ = 1 still group together, likewise for those of δ = 2 and δ = 3. In addition, it is interesting to note that the precision of KR-summary when δ = 2 and δ = 3 is better than that when δ = 4, which means that more

# Figure 9: Recall and precision of 2-keyword queries using KR-summaries at different values of δ and KF-summaries (KF-prod and KF-sum denote production and summation estimation)

|Recall (a)|δ=4|δ=3|δ=2| | |
|---|---|---|---|---|---|
|0.9|0.9|0.9| | | |
|0.8|0.8|0.8| | | |
|0.7|0.7|0.7| | | |
|0.6|KF-prod|0.6|KF-prod|0.6| |
|0.5| |0.5| |0.5| |
|0.4| |0.4| |0.4| |
|0.3| |0.3| |0.3| |
|0.2| |0.2| |0.2| |
|0.1| |0.1| |0.1| |
|0|Number of selected top ranked databases (l)| | | | |

# Figure 10: Recall and precision of queries with 3-5 number of keywords with KR-summaries at different values of δ (with SUM estimation)

|Precision (b)|δ=4|δ=3|δ=2| | |
|---|---|---|---|---|---|
|0.9|0.9|0.9| | | |
|0.8|0.8|0.8| | | |
|0.7|0.7|0.7| | | |
|0.6|KF-prod|0.6|KF-prod|0.6| |
|0.5| |0.5| |0.5| |
|0.4| |0.4| |0.4| |
|0.3| |0.3| |0.3| |
|0.2| |0.2| |0.2| |
|0.1| |0.1| |0.1| |
|0|Number of selected top ranked databases (l)| | | | |

“false positives” are selected with δ = 4 than with δ = 2 keyword queries. Between 3-keyword and 4-keyword queries, the former is generally better. It is surprising however to see that 5-keyword queries yield better recall than 3-keyword and 4-keyword queries, and also better than 2-keyword queries when δ = 3. It is natural to expect that the performance should degrade when the number of query keywords increases because it becomes harder to estimate the relationships among the keywords.

We also note that KR-summary still greatly outperforms KF-summary when number of keywords are more than 2. In fact, we found that the superiority of KR-summary performance over that of KF-summary is more obvious when the number of query keywords is increased. The experiments of this section provide us guidelines in choosing a good value of δ to achieve satisfied performance. Ideally, δ should be chosen based on the schema of the database, such that the connections of tables with rich textual information can be revealed in the summary. For example, δ = 3 is a proper value for the schema shown in Figure 8.

When δ = 4, more distant relationships between keywords from tables are included, where the pairs of tables the keyword pairs appear in have already been summarized at lower distance. Such information tends to overestimate the usefulness of the databases when it is used to estimate multiple-keyword relationships in them. The problem of constructing an effective model for deriving an “optimal” δ value based on specific database schemas is complex and large by itself. We will address it in our future work.

# 4.1.2 Effects of the number of query keywords

Next, we compare the performance of KR-summary for queries with different number of keywords. Figure 11 and 12 show the results when δ is set to 3 and 4, respectively. From the figures, we found that the performance of 2-keyword queries is generally better than that of 3-keyword and 4-keyword queries.

We can see that SUM and PROD methods have very similar behavior, and they consistently outperform the other two methods. This shows that it is more effective to take into account the relationship information of every pair of keywords in the query when estimating the overall score of the databases to the query. We also note that the different estimation methods affect recall more than precision, which means that SUM and PROD methods are more effective in improving recall.

# 4.2 Performance in P2P settings

This is because more results are returned when δ is larger, which incur more transmission time.

# 4.2.1 Cost of indexing KR-summary for each database

We first look at the cost for distributing the KR-summary of each database over the Chord [28] structure varying the number of nodes from 1000 to 10000. Figure 15 shows the number of messages transmitted over the network. From the figure, we see that when the number of nodes in the network gets larger, the number of messages increases slightly, due to the fact that the keyword pairs from a single database will be distributed over more Chord nodes. Also, not surprisingly, we can see that when δ is larger, more messages are used since the size of KR-summary increases.

Correspondingly, Figure 16 shows the actual elapsed time for indexing a database when the number of nodes varies. The increase in number of messages causes longer indexing time when the number of nodes increases, or when δ is larger. Generally, the increase in time is linear to the number of nodes, and therefore the indexing method is feasible.

# 4.2.2 Cost of query processing

We evaluate the cost for processing each query with the Chord-based index in this section. Figure 17 shows the average number of messages required for processing a query. We used four pairs of queries each consisting of 2, 3, 4 and 5 keywords respectively making eight queries in total. We can see that the number of messages increases very gradually with the increase of nodes, since more nodes must be accessed to answer the queries. Figure 18 reports the average elapsed time for processing each query.

|d|#entries|size on disk (compressed)|size (compressed)|% of n2|
|---|---|---|---|---|
|1|61765|0.17MB|0.64MB|0.002|
|2|4500687|3.77MB|22.89MB|0.16|
|3|21788108|13.77MB|124.50MB|0.80|
|4|41898415|36.04MB|322.22MB|1.54|

Table 1: Size of the tables for storing tuple relationship matrices at different distances (d)

# 5. RELATED WORK

# 5.1 Keyword search in relational databases

Keyword search over relational databases has been studied extensively recently [1, 2, 3, 13, 14, 19, 21]. All these works focus on efficiently and effectively generating (approximate) top-K results for a given keyword query in a single relational database. They differ from each other in their specific search algorithms, and the ranking functions for returning most relevant top-K results. The DISCOVER approach generates tuple trees by enumerating and evaluating Candidate Networks (CN), which represent join expressions that can generate potential answers, based on the schema graph of the database. The BANKS system represents all the tuples in a database as a graph where the nodes are tuples and links between nodes denote references between corresponding tuples. The answers are generated by searching Steiner trees in the tuple graph that contains all the query keywords. Our proposed summary-based database selection technique complements these search engines on a single database, in order that keyword search to large numbers of distributed databases can be effectively supported.

# 5.2 Data sources selection in data integration

The problem of data source selection is also studied in the data integration literature [20, 24], but with very different settings. A typical data integration system consists of a set of heterogeneous data sources containing data, a global virtual schema exposed to users, and a set of mappings between each of the source schema and the global schema. The set of schema mappings is essentially the descriptions of the sources, with which the system will generate a query execution plan that can access multiple useful data sources, given a query issued against the global schema. [20] presents a way to declaratively describe the content and capabilities of data sources in terms of the global schema, which is later formulated as Local-as-View (LAV) approach. [24] studies the coverage problem of information sources, and proposes a completeness model to measure the usefulness of data sources. While such data integration systems aim to support integrated access of heterogeneous data sources via a structured global interface, our approach is for providing free-and-easy keyword search capability to various data sources. The advantage of our approach is that all the operations are fully automatic. In contrast, the mappings needed in data integration systems can only be built manually or semi-automatically, which limits its applicability to large-scale and dynamic data sources.

# 5.3 Selection of unstructured text data sources

There have been many summary-based solutions developed in IR literature for selection of unstructured text data sources [5, 12, 29, 30]. Most summary techniques are based on keyword frequency statistics for estimating the usefulness of each data source in answering a given keyword query, e.g., GLOSS [12] and CVV [30]. CORI [5] summary also relies on keyword frequency statistics, together with the ICF (Inverse Collection Frequency) value, which is the inverse of the number of data sources that contain a particular keyword, to rank databases in a way similar to the standard TF.IDF measure for ranking documents in a single source. The ICF statistics could help identify the importance of a keyword across different collections, but it cannot capture the structure information that is necessary for measuring the ability of structured data sources in answering a keyword query. These selection algorithms are examined and compared extensively in [9, 26] with various datasets. In addition, [29] proposes a summary technique for document collections where linkages among documents are available (e.g., web pages), and therefore documents with more references should be ranked higher. It thus incorporates the rank of documents in the summary to achieve better performance.

# Table 2: Size of KR-summaries with different

|δ|#entries|size on disk (compressed)|% of m2|
|---|---|---|---|
|0|207037|0.64MB|0.047|
|1|212176|0.65MB|0.048|
|2|6270482|15.03MB|1.42|
|3|6275887|15.06MB|1.42|
|4|25622178|57.62MB|5.83|

The matrices are still very sparse. As intermediate results, the tuple relationship matrices can be deleted after the KR-summary is generated to save storage space. However, they can also be kept for efficient updating. As mentioned earlier, the increase in the size of KR-summary is less smooth as δ increases, which can be seen from Table 2. The sizes of KR-summaries are similar when δ = 0 and δ = 1 and likewise for δ = 2 and δ = 3. We also see that the number of keyword pairs included in KR-summary is a small portion of all possible combinations of keyword pairs. Note that the size of the KR-summary is mostly related to the number of keywords in the source database, not the original size of the database.

# 5.4 Capturing keyword dependence for information retrieval

There have been research works [6, 11, 23] on capturing the dependence relationships between keywords for improving the effectiveness document retrieval tasks, considering that words occurring in a sentence are not independent in our natural language. For example, there is some degree of dependence between the occurrences of the keywords “computer” and “programming”. Such relationships among keywords can be discovered by directly collecting information on co-occurrences of keywords from corpus, or by manually building thesauri to recognize synonyms, compound terms, etc., such as WordNet [10]. While such relationship captures the dependences of keywords in natural language, the keyword relationship defined in our work describes associations of keywords specific to a particular relational databases based on references between tuples, which may or may not be related to their dependence in natural language.

# 6. CONCLUSION AND FUTURE WORK

In this paper, we introduce a novel summary technique for relational databases for enabling keyword-based selection of distributed data sources. Different from traditional summary used in IR for text databases that mainly relies on keyword frequency information, our summary exploits the structure of the relational database and contains pairs of keywords with scores indicating the strength of their relationship, which are measured based on the references between tuples. We also propose an estimation method for ranking the usefulness of databases in answering a keyword query with our KR-summary. Our experimental results with real dataset demonstrate the effectiveness of our proposed summary approach. Further, our evaluation of the distributed indexing mechanism for the KR-summaries implemented over PlanetLab [7] confirms its feasibility, scalability and efficiency over a real distributed environment. Indeed, unlike traditional data integration techniques, our free-and-easy keyword based selection method requires no human intervention, hereby enabling scalability over a large network of distributed relational data sources.

Our summary technique can be extended in two directions. First, we can further incorporate IR-based weighting methods and weightings based on link structure into the KR-summary. For example, the D matrix could include the weighting of each keyword in the tuples it appears in, and the T matrix could use real numbers to indicate the importance of different links, instead of binary values. Second, we can exploit some sampling-based methods for constructing the KR-summary more efficiently and making it more compact.

# 7. REFERENCES

|[1]|S. Agrawal, S. Chaudhuri, and G. Das. DBXplorer: A system for keyword-based search over relational databases. In ICDE, 2002.|
|---|---|
|[2]|A. Balmin, V. Hristidis, and Y. Papakonstantinou. ObjectRank: Authority-based keyword search in databases. In VLDB, 2004.|
|[3]|G. Bhalotia, A. Hulgeri, C. Nakhe, S. Chakrabarti, and S. Sudarshan. Keyword searching and browsing in databases using BANKS. In ICDE, 2002.|
|[4]|J. Callan and M. Connell. Query-based sampling of text databases. ACM TOIS, 19(2):97–130, 2001.|
|[5]|J. P. Callan, Z. Lu, and W. B. Croft. Searching distributed collections with inference networks. In SIGIR, 1995.|
|[6]|G. Cao, J.-Y. Nie, and J. Bai. Integrating word relationships into language models. In SIGIR, 2005.|
|[7]|B. Chun, D. Culler, T. Roscoe, A. Bavier, L. Peterson, M. Wawrzoniak, and M. Bowman. Planetlab: an overlay testbed for broad-coverage services. SIGCOMM Computer Communication Review, 33(3):3–12, 2003.|
|[8]|P. Domingos and M. Pazzani. Beyond independence: Conditions for the optimality of the simple Bayesian classifier. In Proc. 1996 Int. Conf. Machine Learning (ML’96), pages 105–112, 1996.|
|[9]|D. D’Souza, J. Thom, and J. Zobel. Collection selection for managed distributed document databases. Information Processing & Management, 40:527–546, 2004.|
|[10]|C. Fellbaum, editor. WordNet: An Electronic Lexical Database. Bradford Books, 1998.|
|[11]|J. Gao, J.-Y. Nie, G. Wu, and G. Cao. Dependence language model for information retrieval. In SIGIR, 2004.|
|[12]|L. Gravano, H. García-Molina, and A. Tomasic. GlOSS: text-source discovery over the Internet. ACM Transactions on Database Systems, 24(2):229–264, 1999.|
|[13]|V. Hristidis, L. Gravano, and Y. Papakonstantinou. Efficient IR-style keyword search over relational databases. In VLDB, 2003.|
|[14]|V. Hristidis and Y. Papakonstantinou. DISCOVER: Keyword search in relational databases. In VLDB, 2002.|
|[15]|F. K. Hwang, D. S. Richards, and P. Winter. The Steiner Tree Problem. Annals of Discrete Mathematics. North-Holland, 1992.|
|[16]|P. G. Ipeirotis, E. Agichtein, P. Jain, and L. Gravano. To search or to crawl?: towards a query optimizer for text-centric tasks. In SIGMOD, 2006.|
|[17]|P. G. Ipeirotis and L. Gravano. Distributed search over the hidden web: Hierarchical database sampling and selection. In VLDB, 2002.|
|[18]|H. V. Jagadish, B. C. Ooi, and Q. H. Vu. Baton: a balanced tree structure for peer-to-peer networks. In VLDB, 2005.|
|[19]|B. Kimelfeld and Y. Sagiv. Finding and approximating top-k answers in keyword proximity search. In PODS, 2006.|
|[20]|A. Y. Levy, A. Rajaraman, and J. J. Ordille. Querying heterogeneous information sources using source descriptions. In VLDB, 1996.|
|[21]|F. Liu, C. Yu, W. Meng, and A. Chowdhury. Effective keyword search in relational databases. In SIGMOD, 2006.|
|[22]|W. Meng, C. Yu, and K.-L. Liu. Building efficient and effective metasearch engines. ACM Computer Survey, 34(1):48–89, 2002.|
|[23]|R. Nallapati and J. Allan. Capturing term dependencies using a language model based on sentence trees. In CIKM, 2002.|
|[24]|F. Naumann, J.-C. Freytag, and U. Leser. Completeness of integrated information sources. Information Systems, 29(7):583–615, 2004.|
|[25]|W. S. Ng, B. C. Ooi, and K. L. Tan. BestPeer: A self-configurable peer-to-peer system. In ICDE, 2002. Poster Paper.|
|[26]|A. L. Powell and J. C. French. Comparing the performance of collection selection algorithms. ACM Transactions on Information Systems, 21(4):412–456, 2003.|
|[27]|A. Singhal. Modern information retrieval: A brief overview. IEEE Data Engineering Bulletin, 24(4):35–43, 2001.|
|[28]|I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan. Chord: A scalable peer-to-peer lookup service for internet applications. In SIGCOMM, 2001.|
|[29]|C. Yu, W. Meng, W. Wu, and K.-L. Liu. Efficient and effective metasearch for text databases incorporating linkages among documents. In SIGMOD, 2001.|
|[30]|B. Yuwono and D. L. Lee. Server ranking for distributed text retrieval systems on the Internet. In Proceedings of the Fifth International Conference on Database Systems for Advanced Applications (DASFAA), 1997.|

