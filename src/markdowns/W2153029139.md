# Using Continuous Biometric Verification to Protect Interactive Login Sessions

Sandeep Kumar        Terence Sim        Rajkumar Janakiraman          Sheng Zhang

School of Computing, National University of Singapore

3 Science Drive 2, Singapore 117543

{skumar, tsim, janakira, zhangshe}@comp.nus.edu.sg

# Abstract

In this paper we describe the theory, architecture, implementation, and performance of a multi-modal passive biometric verification system that continually verifies the presence/participation of a logged-in user. We assume that the user logged in using strong authentication prior to the starting of the continuous verification process. While the implementation described in the paper combines a digital camera-based face verification with a mouse-based fingerprint reader, the architecture is generic enough to accommodate additional biometric devices with different accuracy of classifying a given user from an imposter. The main thrust of our work is to build a multi-modal biometric feedback mechanism into the operating system so that verification failure can automatically lock up the computer within some estimate of the time it takes to subvert the computer. This must be done with low false positives in order to realize a usable system. We show through experimental results that combining multiple suitably chosen modalities in our theoretical framework can effectively do that with currently available off-the-shelf components.

Biometric verification is appealing because several of them that are easy to incorporate in ordinary computer use are passive, and they obviate the need to carry extra devices for authentication. In a sense, they are always on one’s “person”, and perhaps a little safer than using external devices which can be separated from their carrier more easily. However, biometric verification can be construed as a matching problem and usually makes a probabilistic judgment in its classification. This makes it error prone. Furthermore, when used passively like we are attempting to do, it can result in time periods with no samples or poor quality samples; for example, when the user is not looking directly into the camera, or when the surrounding light is poor. To avoid both these pitfalls, researchers have used multiple modalities, say, fingerprint and face images simultaneously. This makes classification more robust and is also the approach that we have taken in this work. Even when some modalities may be very accurate, they might be inherently limited in their sampling rate, so combining them with faster (albeit less accurate) modalities helps to fill gaps between successive samples of the better modality. However, the use of multiple modalities presupposes independent sampling so that not all modalities fail to generate a sample.

# 1. Introduction

By continuous verification we mean that the identity of the human operating the computer is continually verified. Verification is computationally simpler than identification and attempts to determine how “close” an observation is to a known value, rather than finding the closest match in a set of known values. Verification is a realistic operation in the normal usage of a computer system because we can assume that the user’s identity has been incontrovertibly established by a preceding strong authentication mechanism. It is also appealing because it can conceivably be offloaded to a hardware device that is properly initialized with user specific data upon successful login.

valid sample at the same time.1

Building an effective reactive biometric verification system consists of many aspects. Not only must the verification results be integrated into the operating system, it can be critical to balance several conflicting metrics: namely, accuracy of detection, system overhead incurred during the verification, and reaction time i.e., the vulnerability window within which the system must respond when it detects that the authorized user is no longer present. This relationship is especially important when all these aspects are performed in software on the same machine that is being protected from unauthorized use.

In the rest of the paper we describe the theoretical underpinnings of our multi-modal biometric verification system, our implementation architecture, the OS kernel changes needed to make the system reactive to verification failures, and the performance impact of such a system on ordinary computer use. The goal is to render a computer system ineffective within a certain time period of verification failure. This time should be a conservative estimate of the time it would take someone to cause information loss (confidentiality, integrity, or availability[11]) on the system.

# 2. Biometrics in Brief

We begin with a brief introduction of some of the important concepts in biometrics and verification. Readers familiar with these concepts may skip ahead; while readers wanting more details can refer to[5].

# 2.1. Basic concepts

Biometrics is generally taken to mean the measurement of some physical characteristic of the human body for the purpose of identifying the person. Common types of biometrics include fingerprint, face image, and iris/retina pattern. A more inclusive notion of biometrics also includes the behavioral characteristics, such as gait, speech pattern, and keyboard typing dynamics.

When a biometric is used to verify a person, the typical process is as shown in Figure 1. The user first presents her biometric (e.g. the thumb) to the sensor device, which captures it as raw biometric data (for example a fingerprint image). This data is then preprocessed to reduce noise, enhance image contrast, etc. Features are then extracted from the raw data. In the case of fingerprints, these would typically be minutiae and bifurcations in the ridge patterns. These features are then used to match against the corresponding user’s features taken from the database (retrieved based on the claimed identity of the user). The result of the match is called a Score, S, typically a real number between 0 and 1, where 0 means “most dissimilar” and 1 means “most similar”. The final step is to compare S to a predefined threshold T, and output:

- a decision of “Accept” (when S ≥ T), meaning the Verifier considers the user as legitimate, or
- “Reject” (when S < T), meaning the Verifier thinks that the user is an imposter.

Some verification systems also output “Unsure”, to indicate that the sample cannot be reliably classified one way or the other. In this case, the user may be asked to re-present her biometric.

Of course, the user’s biometric features must first be entered into the database. This is done in an earlier one-off phase called enrollment. The process of enrollment is usually similar, consisting also of biometric data capture, preprocessing, and feature extraction. However, to increase robustness, multiple biometric samples are usually acquired (e.g. multiple images of the same finger), so that the verifier can “learn” the natural variation present in the user’s biometric.

How accurate is biometric verification? There are two types of errors that a Verifier can make: a False Accept, or a False Reject. The False Accept Rate (FAR) is the probability that the Verifier incorrectly classifies an imposter as a legitimate user. This is a security breach. On the other hand, the False Reject Rate (FRR) is the probability that the Verifier incorrectly decides that the true user is an imposter. This is an inconvenience to the user, since she must usually resort to another means of verifying herself. In general, while a small FRR can be accepted as an inconvenience, a large FRR value can impact availability and may be construed as indirectly impacting the security of the system[11].

In an ideal Verifier, both the FAR and FRR are zero. In practice, there is usually a tradeoff between the FAR and FRR: a lower rate for one type of error is achievable only at the expense of a higher rate for the other. This tradeoff is usually described using the Receiver Operating Characteristic.

1Face and fingerprint may not be totally uncorrelated in that sense. However, that’s not the thrust of this paper; rather this paper focuses on integrating multiple biometrics within an OS.

|User presents biometric|Sensor data|Pre-processing, Feature extraction|
|---|---|---|
|Claimed identity|Database|Claimed identity's features|
|User's features|Enrollment|Decision|
|Accept or Reject|Accept or Reject| |

Figure 1. A typical biometric verification process.

a balance between load and accuracy, especially when all biometric related computation is done in software on the same machine that is used for computing needs.

For example, in one set of measurements that we took for face verification, the CPU needed for our operating environment was nearly .2s per image, mostly incurred in locating the face in the whole image. This figure could be reduced to .1s by employing heuristics such as remembering the location of the face in the image, and using that as the starting point of face detection for the next image. The upshot is that processing about 10 frames per second would saturate the CPU. Adding multiple samples to increase accuracy of this biometric would seriously impact performance (about 10% for each extra frame rate). The alternative is to combine face verification with another, different biometric which has much higher accuracy.

# 2.2. Operational issues

Usability versus Security. We consider the FRR of a biometric system as a measure of the system’s usability, and its FAR as a measure of its security. With a higher false reject rate, the verification system deduces more frequently (but incorrectly) that the system is under attack and reacts by freezing or delaying the currently logged-in user’s processes. This would unnecessarily delay the user’s time-to-completion of ordinary tasks and may make the system frustrating to use. There is evidence that system response time is correlated to user productivity.

The Power of a Veriﬁer is defined as the area under its ROC curve, and that is a useful measure of the Veriﬁer’s overall accuracy in a way that combines both its FAR and FRR. The greater the area, the better the Veriﬁer. In general, fingerprint verification is considered more powerful than face verification.

False rejects can be reduced by adjusting the decision threshold T of a biometric Veriﬁer, but with a concomitant increase in the false accept rate. This could be disastrous from a security perspective. A usable system must balance its FAR against its FRR. Using at least one biometric with high accuracy can sharply distinguish a valid user from an imposter and can strike a good balance between the two choices. Higher accuracy can also be achieved at the cost of more samples but that increases the computational overhead, which impacts usability.

# Figure 2. ROC Curves.

|FAR|ROC|ROC| |
|---|---|---|
| |Ideal ROC|Typical ROC|
|0.0|0.1|0.2|
|0.3|0.4|0.5|
|0.6|0.7|0.8|
|0.9|1.0| |

When using multiple biometrics, individual classification results must be combined into a composite result. Computational overhead related to biometric processing must be balanced to get the desired tradeoff between usability, security and remaining computational power available for useful work. We describe these issues next.

Choice of biometrics. For our design objective we need biometrics that are both passive and accurate. Passive biometrics do not require active participation by the user, (as opposed to active ones, such as those that use speech) and therefore do not intrude into the normal activity of the user by requiring them to periodically perform biometric related tasks that are not part of their normal activity. Such a requirement can be distracting and result in low system usability. Recently available computer peripherals such as the Secugen mouse incorporates an optical fingerprint scanner at the place.

# 3. Multimodal Biometrics

We use two modalities of observations: fingerprint and face images. The challenge is to integrate these observations across modality and over time. To do this, we devised the integration scheme shown in Figure 5. Our system currently uses the face verifier and a fingerprint verifier; other modalities are possible in the future. Each verifier computes a score from its input biometric data (fingerprint or face images), which is then integrated (fused) by the Integrator. In the following sections, we describe in turn how we compute the score for each modality and how we fuse them into a single estimate.

# 3.1. Fingerprint Verifier

We acquire fingerprint images using the SecureGen mouse (Figure 3). The mouse comes with a software development kit (SDK) that matches fingerprints, i.e., given two images, it computes a similarity score between 0 (very low similarity) and 1 (identical).

# Figure 4. Combining multiple biometric modalities.

# Figure 5. Integration scheme

Attacked. A Safe state implies that the logged-in user is still present at the computer console, while Attacked means that an imposter has taken over control. The result of the fusion is the calculation of Psafe, the probability that the system is still in the Safe state. This value can then be compared to a pre-defined threshold Tsafe set by the security administrator, below which appropriate action may be taken. A key feature of our method is that we can compute Psafe at any point in time, whether or not there are biometric observations. In the absence of observations, there is a built-in mechanism to decay Psafe reflecting the increasing uncertainty that the system is still Safe.

Using multiple modalities. There is general agreement in the biometric research community, also supported by theory, see for example [13], that using multiple types (modalities) of biometrics (with an appropriate combination rule) can yield a higher classification accuracy than using only a single modality. In the context of our work here, combining face and fingerprint modalities is useful because there are frequent situations in which one modality is missing, e.g. when the user is looking away from the camera, or when the user is not using the mouse. Finally, attempting to thwart a multi-modal system is a much harder task than fooling a single-modality system.

There are two general ways of combining biometric data samples that are coming from different biometric modalities at different times [1]:

1. (Time-first) Combining samples of each modality first across time, and then combining them across modalities. In Figure 4, this scheme would first combine samples a, b, c (= u) for face, and d, e, f, g (= v) for fingerprint, then combine u and v.
2. (Modality-first) Combining across modality first, then across time. This would first combine samples in the order a, d at the end of t1, b, e at the end of t2 etc., and then combine across the different times.

Recently we proposed a technique that combines the two approaches in whatever order the biometric data is made available [19]. This paper presents performance results using that technique of multi-modal fusion. The technique is based on Bayesian probability (see Section 3.3) and models the computer system as being in one of two states: Safe or Attacked.

There is a possible Absent state, to model the situation in which the user has left the console but has not logged out. Because we are assuming a high-risk environment, it is justifiable to make Absent ≡ Attacked.

dissimilar) and 199 (identical). Unfortunately, the matching algorithm is proprietary and is not disclosed by the vendor. Nevertheless, we’ve obtained good results using the score generated by this algorithm.

First we collect 1000 training fingerprint images from each of four users. Then, for each user we divide the training images into two sets: those belonging to the user (intra-class images), and those belonging to others (inter-class images). For each set, we calculate the pairwise image similarity using the proprietary algorithm, and determine the histogram of the resulting scores. That is, for each user, we compute two probability density functions (pdf) – the intra-class and inter-class pdfs (represented by histograms). Figure 6(a) shows the pairwise pdfs for a typical user. If we denote the similarity score by s, the intra-class set by ΩU, and the inter-class set by ΩI, then these pdfs are P(s | ΩU) and P(s | ΩI). Note that the pdfs do not overlap much, indicating that fingerprint verification is reliable (high verification accuracy).

Given a new fingerprint image and a claimed identity, the image is matched against the claimed identity’s template (captured at enrollment time) to produce a score s. From this we compute P(s | ΩU) and P(s | ΩI). These values are then used by the Integrator to arrive at the overall decision. Section 3.3 has more details.

# 3.2. Face Verification

To train the face Verifier, we first capture 500 images of each of the four users under different head poses using a Canon VCC4 video camera and applying the Viola-Jones face detector on the image [18]. About 1200 face images are also collected of sundry students on campus to model as imposters. For each user, we construct training images from two sets: those belonging to the user, and those belonging to the imposter. All face images are resized to 28 × 35 pixels. For each set we calculate the pairwise image distance using the Lp norm (described below). This constitutes the biometric feature that we extract from the image and is similar to the ARENA method [14]. If we denote the similarity score by s, the set of legitimate users by ΩU, and the set of imposters by ΩI, then these pdfs are P(s | ΩU) and P(s | ΩI). We can now determine the histogram of the resulting scores. Figure 6(b) shows a pair of pdfs for one user.

The Lp norm is defined as Lp(a) ≡ (|ai|)p, where the sum is taken over all pixels of the image a. Thus the distance between images u and v is Lp(u−v). As in ARENA, we found that p = 0.5 works better than p = 2 (Euclidean). Given a new face image and a claimed identity, we compute the smallest Lp distance between the image and the intra-class set of the claimed identity. This distance is then used as a score s to compute P(s | ΩU) and P(s | ΩI), which in our Markov assumptions, we note that P(zt | xt, Zt−1) =

# 3.3. Holistic Fusion

The heart of our technique is in the integration of biometric observations across modalities and time. This is done using a Hidden Markov Model (HMM) (Figure 7 (a)), which is a sequence of states xt that “emit” observations zt (face or fingerprint), for time t = 1, 2, . . . Each state can assume one of two values: {Safe, Attacked}. The goal is now to infer the state from the observations.

Let Zt = {z1, . . . , zt} denote the history of observations up to time t. From a Bayesian perspective, we want to determine the state xt that maximizes the posterior probability P(xt | Zt). Our decision is the greater of P(xt = Safe | Zt) and P(xt = Attacked | Zt). Using a little algebra, we may write:

P(x | Zt) ∝ P(zt | xt, Zt−1) · P(xt | Zt−1) (1)

and

∑ P(xt | Zt−1) = ∑ P(xt | xt−1, Zt−1) · P(xt−1 | Zt−1) (2)

This is a recursive formulation that leads to efficient computation. The base case is P(x0 = Safe) = 1, because we know that the system is Safe immediately upon successful login. Observe that the state variable xt has the effect of summarizing all previous observations.

# 4. Integrating biometric feedback into the OS

Having considered some issues in the use of biometrics for security, we now consider design issues relating to its integration into the operating system to make the whole system reactive. We consider two mechanisms for reaction: delaying processes when Psafe &lt; Tsafe, or suspending them entirely, as in Somayaji’s work [16].

Our model of protection is intended for single computer use to which users login through a bitmapped display (usually the console) that is directly connected to it. We also assume that biometric sensors feed data directly to the computer thereby insuring the integrity of both capturing and forwarding of the data for processing. Our current design affords continuous authentication protection to the “interactive” processes started by the user after logging in. This allows processes started upon system boot to be exempt from monitoring, and for privileged processes started after user login (such as executing setuid programs) to remain within the purview of continuous authentication.

The value of p is governed by domain knowledge: if there is no observation for a long period of time, we would like p to be small, indicating that we are less certain that the user is still safe (and thus more likely to have been attacked). To achieve this effect, we define p = ek∆t, where ∆t is the time interval between the current time and the last observation, and k is a free parameter that controls the rate of decay, which the security administrator can define. In general, any decay function may be used to specify p, with a suitable rate of decay.

# Identifying interactive sessions

For us, an interactive session consists of all processes derived from the initial console login. In Unix-based operating systems, there is usually a focal point in the form of a display manager (akin to getty), such as the KDE kdm program, that collects the user name and password for authentication before starting the user’s X session. By tagging this process and every process derived from it through a fork()-like inheritance mechanism, we can tag all processes belonging to a session.

However, it is possible for the same user to login more than once (at different times, therefore different sessions) and still have processes from an earlier session running, so we must decide whether later logins also authenticate processes started in earlier interactive sessions, or whether each login session is considered as distinct. The former choice can be easily implemented by using a user id-based mechanism for process monitoring. In such a mechanism, only a process’s uid field is examined to determine whether it is subject to continuous authentication. This would necessitate that the same uid not be used for both login sessions and for doing background activity because user logout would result in delaying or freezing such processes.

Figure 6. (a) Fingerprint intra-class and inter-class histograms for a typical user. (b) Face intra-class and inter-class histograms for a typical user. There is greater overlap in these histograms than in fingerprint, indicating that face verification is less reliable than fingerprint verification.

|Fingerprint matching score|Fingerprint matching score|Frequency|
|---|---|
|Intra class|Inter class| |
|0|50|100|
|150|200|250|
|20|40|60|
|80|100|120|
|140|160|180|
|200|1000|2000|
|3000|4000|5000|
|6000|7000|8000|

A useful service that would be impacted is the use of cron and at job processing which may happen at any time, even when the user is not currently logged in. A more general approach would be to identify the entire process tree derived from the initial display manager as belonging to a session. This would enable daemons such as cron and at to work without being subjected to continuous authentication.

# 5. Implementation Architecture

Figure 8 depicts the various elements of our implementation and how they are integrated into the operating system. We have implemented this architecture on the Linux 2.4.26 kernel with the KDE graphical environment running on the Redhat 9.0 distribution. For face image capture, we use the Euresys Picolo capture card and the Canon VCC4 camera. The captured images have a resolution of 768 × 576 pixels and are 24-bit deep. The fingerprint images are captured using the Secugen OptiMouse III. All experiments were performed on an Intel Pentium 2.4 Ghz machine with 512MB RAM. The details of the various elements of the architecture are described below under task-related groupings for ease of understanding.

Starting continuous verification. When a user logs in at the console using the kdm session manager, kdm authenticates the user using a password. Additionally, it starts the face and fingerprint verifiers and initializes the monitor with the user-id of the user that has logged in. We achieve this non-invasively by using PAM to realize the side effect. To do this we added an entry in /etc/pam.d/kde of the form:

session   optional    pam_contauth.so

which is invoked during the kdm execution. kdm, being PAM aware, calls the PAM login authentication routine. This results in calling pam_contauth which starts the face, fingerprint and monitor components of Figure 8, and sets the session number of the kdm process to be the value of a kernel maintained integer ca_global_session. This is done through a newly added system call. A “session” conceptualizes an interactive login session, and in order to tag all the processes started by the user in a given session, we maintain an integer variable in every process’s task_struct that denotes its session. Because all the components of the K Desktop Environment are forked off kdm, the value of this variable is automatically inherited across process forks and remains intact across execs. The ca_global_session is a counter in the kernel that is incremented after every successful kdm login.

Once the monitor has the user-id of the logged in user, it loads the biometric profile (the biometric features to be used for verification) corresponding to the user and starts biometric data capture using the video and fingerprint boxes in Figure 8. The arrows in the diagram denote the direction of...

# Control Flow

# Data Flow

|KDM|Fingerprint|VIDEO|Monitor| | |
|---|---|---|---|---|---|
|User|Kernel|y|x|z|DRIVER|

Figure 8. Architecture of a face verification system integrated with the operating system.

The monitor is the central coordinating entity in the architecture that performs the following tasks:

1. It controls the rate at which biometric data is captured by querying each biometric device and runs the modality-specific verifier for that sample (Section 3.2).
2. It combines the verification results from different modalities obtained at different times into Psafe, the probability that the computer system is still Safe (Section 3.3).
3. It periodically communicates P (indirectly, it actually computes and communicates the delay value in jiffies) to the kernel so that the kernel can appropriately freeze or delay processes.

# Controlling processes

To support the controlling of processes, we modified the Linux kernel as depicted in Figure 8. When a user process makes a system call, it traps into the OS kernel and eventually executes the code that implements the system call [8]. We introduced control processing just before the system call is dispatched. To do this, we add a kernel global variable (contauth_cb), which is a function pointer to code that implements the processing. This allows the processing code to be dynamically added to a running kernel and also serves to localize kernel changes. This function is invoked for every process on every system call.

The total change in the Linux kernel amounts to three lines of assembly code in arch/i386/kernel/entry.S, about 100 lines in a newly added C file contauth.c and miscellaneous code including adding system calls to get and set the kernel variable ca_global_session, and to set a process’s session_id adding to another 50 lines. Currently we have only one callback point in the kernel and that is where a system call is dispatched. In the future we will probably add more callback points in the kernel for finer process control, for example at the point where a process is context switched. The performance impact of this change is described in our micro benchmarks in Section 6.1.

As used in line 4, each process has a “session id” in its task_struct denoted by the field ca_sessid. A value of 0 means that the process is not rooted at any interactive session. Such processes are not controlled in any way as specified by the action in line 5. In the kernel, the variable ca_global_session identifies the session id of the current.

1   double x = current_biometric_classification;
2   boolean below_thresh  = (x < threshold);
3   if(current->ca_sessid == 0)
4      do_nothing;
5   else if(current->ca_sessid == ca_global_session)
6   {
7      if(syscall is critical && below_thresh)
8          freeze yourself;
9      else if(syscall is !critical && below_thresh)
10         delay yourself by [e(1/S−1/T) − 1] jiffies
11         //!below_thresh ⇒  do_nothing;
12   }
13   else if(current->ca_sessid < ca_global_session)
14         unconditionally freeze yourself;

interactive session if it is in progress, or the session id of a good sample is obtained, the system ought not to penalize processes that are currently being delayed and wait until their duration of delay has ended. Because the exponential function can produce very large delay values as Psafe → 0; to ensure a rapid recovery once the monitor regains confidence in user presence, the driver issues a wakeup call to all processes that were delayed.

# 6. Performance

We describe results of both micro and macro benchmarks.

# 6.1. Micro benchmarks

To assess the performance impact of our Linux kernel changes, we ran the lmbench suite to determine the overhead introduced in the system call path. The results are shown in Figure 9.

The percent overhead on the y-axis is the percent increase in time for executing a system call with our modifications for stopping and delaying processes when compared with a standard 2.4.26 Linux kernel that can be downloaded from www.kernel.org. The overhead is dependent on the system call exercised. The overhead is as low as .4% for the fork+execve combination to a 3.75% overhead for read. We believe this to be acceptable.

# 6.2. Macro benchmarks

For macro benchmark tests we assessed the performance impact on compiling the Linux (2.4.26) kernel. The compilation generates about 1200 object files. We chose the Linux kernel compilation because it pollutes the cache and its processor utilization is significant. The face biometric is sampled twice per second while the fingerprint biometric is sampled once in two seconds. The numbers in Figure 9 are averages over three runs. The overhead is about 25% for our operating environment.

|(a) Micro benchmarks|Real|User|Sys|
|---|---|---|---|
|without contauth verification|276|258|16|
|with contauth verification|346|263|17|
|Overhead|≈ 25%|≈ 25%|≈ 25%|

# (b) Macro benchmarks

Figure 9. Performance benchmarks.

When Psafe exceeds Tsafe, all frozen processes in the current interactive session are “unfrozen”, and delayed processes are made runnable. This is practically important and affects system usability because if the user looks away from the camera and does not have his finger against the mouse, the system may start delaying his processes. But as soon as the user returns, the system should resume normal operation.

A standard metric for assessing the usability of a biometric is its FRR. In our system, false rejects result in process delays, so one way to measure usability is the delay that ordinary tasks suffer in their time-to-completion. If the overhead (reflected as delay) introduced by the normal use of biometrics is x% (see Section 6), then we are interested in determining how much further ordinary tasks are delayed under normal use of the system. We ran some simple operations that ordinary users might perform in their use of a computer to assess this difference.

1. ls -R /usr/src/linux-2.4.26 results in a “real” time overhead of 36%, about an 11% increase.

# 2.

ls -R /usr/local results in a “real” time overhead of 37%.

# 3.

grep -R &lt;key&gt; /usr/src/linux-2.4.26 results in a “real” time overhead of 44%.

All times are averages of 5 runs. So the impact on usability of using the system in practice is an extra 10-20% degradation. While the biometric verification can conceivably be offloaded to extra hardware, the delays resulting from FRR errors cannot.

For our operating environment, our security goals seem to be met although that is a qualitative judgment at this point. We have tried to switch users suddenly and execute rm /tmp/foo, but the system freezes before the command is fully typed. A caveat is that key strokes by the imposter may not be delivered to the application (shell) but only because it is not executing. When the correct user comes back, these key strokes would be delivered and damaging action performed. To be totally secure, the tty/pty driver or the X server must somehow be made to discard all user input when a process is delayed or frozen.

# 8. Conclusion and Future Work

We believe that the reactive system that we set out to build works reasonably well at this point. Biometric verification is the main bottleneck in the computation and we are looking into how to offload that into an FPGA-based implementation. We are also investigating how to derive a mathematical basis for computing the “sweet spot” of the system that maximizes a utility function, such as U(u) + S(s) given the various parameters of the system. u is the raw fractional delay overhead in using the system and U(·) maps it to a utility value. Similarly s is a security metric, e.g., the FAR of the system, and S(·) maps it to a utility value. u and s in turn are functions of the biometric modalities, their ROC curves, the number of samples used for each biometric decision, and the multi-modality fusion method.

The thrust of this paper is less towards biometrics per se, although our multi-modal combination technique is new; rather it is about how to integrate biometrics as a useful general abstraction into the operating system so that all processes can gain from it, with the aim of enhancing the security of the system. Now that newer biometric devices are commonly appearing that can permit passive biometrics to be integrated into normal computer use, such abstractions can be useful to investigate at a lower layer so that computer response can be provided in a more general and encompassing manner.

# Acknowledgements

This work was funded by the National University of Singapore, project no. R-252-146-112. The anonymous reviewers gave excellent feedback that has helped improve the presentation of the paper.

# References

1. A. Altinok and M. Turk. Temporal Integration for Continuous Multimodal Biometrics. Proceedings of the Workshop on Multimodal User Authentication, December 2003.
2. M. Bernaschi, E. Gabrielli, and L. V. Mancini. REMUS: A Security-Enhanced Operating System. ACM Transactions on Information and System Security, 5(1):36–61, 2002.
3. N. Crook. The kdm Handbook. Available at http://docs.kde.org/en/3.1/kdebase/kdm/.
4. D. E. Denning. An Intrusion-Detection Model. IEEE Transactions on Software Engineering, 13(2), February 1987.
5. R. Duda, P. Hart, and D. Stork. Pattern Classification, 2nd edition. John Wiley and Sons, 2000.
6. J. Kittler, M. Hatef, R. P. W. Duin, and J. Matas. On combining classifiers. IEEE Trans. on PAMI, 20(3):226–239, Mar. 1998.
7. G. N. Lambert. A comparative study of system response time on program developer productivity. IBM Systems Journal, 23(1):36–43, 1984.
8. R. Love. Linux Kernel Development. SAMS, 2003.
9. L. McVoy and C. Staelin. lmbench: Portable Tools for Performance Analysis. USENIX 1996 Annual Technical Conference, January 1996.
10. A. G. Morgan. The Linux-PAM System Administrators’ Guide. Documentation distributed with Linux-PAM. Available at http://www.kernel.org/pub/linux/libs/pam/pre/library/.
11. C. P. Pflueger. Security in Computing. Prentice Hall, 2nd edition, 1996.
12. N. Provos. Improving Host Security with System Call Policies. 12th USENIX Security Symposium, August 2003.
13. A. Ross and A. K. Jain. Information fusion in biometrics. Pattern Recognition Letters, 24(13):2115–2125, 2003.
14. T. Sim, R. Sukthankar, M. Mullin, and S. Baluja. Memory-based Face Recognition for Visitor Identification. In Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition, 2000.
15. S. B. Solutions. Secugen optimouse iii. http://www.secugen.com/products/po.htm.
16. A. Somayaji. Operating System Stability and Security through Process Homeostasis. PhD thesis, University of New Mexico, Department of Computer Science, July 2002.
17. The Linux Kernel Archives. http://www.kernel.org/.
18. P. Viola and M. Jones. Robust real-time object detection. International Journal of Computer Vision, 2002.
19. S. Zhang, R. Janakiraman, T. Sim, and S. Kumar. Continuous Verification Using Multimodal Biometrics. In The 2nd International Conference on Biometrics, 2006.

