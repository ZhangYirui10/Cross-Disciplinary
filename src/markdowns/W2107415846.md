# An Effective Approach to Detect Lesions in Color Retinal Images¹

# Huan Wang, Wynne Hsu, Kheng Guan Goh, Mong Li Lee

# School of Computing

# National University of Singapore

{wangh, whsu, gohkg, leeml} @comp.nus.edu.sg

# Abstract

Diabetic-related eye diseases are the most common cause of blindness in the world. So far the most effective treatment for these eye diseases is early detection through regular screenings. During the screenings, color retinal images are obtained using fundus camera. However, this results in a large number of fundus images being produced that require manual analysis and diagnosis. In other words, medical professionals have to spend a great deal of time and energy to review these photographs. It would be more cost effective if the initial task of analyzing the retinal photographs can be automated so that only the abnormal retinal images need to be reviewed by the medical professionals each year.

With this motivation in mind, we have developed a system to automate the preliminary analysis and diagnosis of retinal eye images. This system combines digital image processing and pattern recognition with machine learning techniques to analyze diabetic retinal images. Through this system, the retinal images will be classified into normal or abnormal ones. Figure 1 shows an example of a healthy fundus image.

# 1. Introduction

Diabetic‑related eye diseases are the most common cause of blindness in the world. For example, there are approximately 16 million Americans who have either Type I (juvenile onset) or Type II (adult onset) diabetes. All are at risk of developing sight‑threatening eye diseases that are common complications of diabetes. In Singapore, more than half of all newly registered blindness are caused by retinal diseases, and diabetic retinopathy is one of the main contributors [1].

An unhealthy abnormal fundus images usually exhibit some abnormalities, one of which is the presence of exudates/lesions. Exudates/lesions are typically manifested as random whitish/yellowish patches of varying sizes, shapes and locations. In this paper, we focus on one of the abnormal signs: the presence of exudates/lesions in the retinal images.

# Figure 1. Healthy normal retinal image.

1 This project is funded by research funds PS964770 and RP991613.

focus on how to detect the presence of retinal lesions center of class i (cluster i) in the k‑dimensional feature accurately using a novel approach that combines brightness adjustment procedure with statistical classification method and local‑feature‑based verification strategy. Experiments have been carried out on 154 images (54 abnormal images, 100 normal images). The results indicate that our approach is able to achieve 100% accuracy in terms of identifying the all the retinal images with exudates while maintaining a 70% accuracy in correctly classifying the truly normal retinal images as normal.

Given a specified pixel x with feature vector X, we classify pixel x as belonging to class i if Di(X) is the maximum along all Dj(X), where j=1,2,…N and j≠i. Two issues need to be resolved before we can apply the above statistical classification to the detection of lesions. The first issue is the selection of a suitable feature space so that exudates and other similar retinal lesions can have clearly distinct characteristics from other objects and background. The second issue is to derive an appropriate discriminant function D(X) that classifies each pixel in a retinal image into class “lesions” or class “others”.

# 1.1 Related Work

Current research has demonstrated that features such as size, shape, texture and orientation, etc. are not sufficient to identify lesions in retinal images [2]. On the other hand, color information has shown to be effective for lesions detection under certain conditions. If the background color of a good quality retinal image is sufficiently uniform (e.g. reddish or dark reddish), then a simple and effective method to separate hard lesions from such background can be easily applied by selecting a proper threshold [3,4]. Furthermore, some dynamic thresholding algorithms containing the compensation of irregularities of illumination were also proposed to detect exudates in different surroundings [2, 5]. However, the limitation of these thresholding techniques is that they typically only work well for the training images, but once an unseen image comes along, they may not be able to accurately detect the exudates. This is because the processing steps require different threshold parameters for different types of retinal images and need user’s intervention on a case by case basis. As a result, these thresholding‑based algorithms are not scalable for analyzing large number of retinal images.

In contrast, we develop a simple but effective method, based on statistical classification [6, 7], to identify lesions in retinal images.

# 2. Exudates Detection Using Statistical Classification

Objects in an image usually can be described in terms of some features f1, f2, …, fk such as color, size, shape, texture and other more complex characteristics. These features, f1, f2, …, fk, form a k‑dimensional feature space, F. Ideally, we would like to find a space F such that different objects map to different, non‑intersecting clusters in this feature space. If this condition is satisfied, we can easily identify different objects and classify them into corresponding classes (clusters) by certain rules. Suppose we have N different objects/classes to be identified in an image. Let Ci(fi1, fi2, …, fik) denote the probability of measurement vector X belonging to event i (class i). If P(Ci/X) is greater than P(Cj/X), where j=1,2,…N, and j≠i, then we should conclude that X belongs to event i (class i). According to Bayes’ theory, P(Ci/X) can be expressed as:

P(Ci/X)=P(Ci)P(X/Ci)/P(X) (1)

Here, P( Ci) is the priori probability of class i in the separate algorithms to automatically identify and label the image to be classified. P( X/Ci) is the conditional probability of X given class C. In other words, the discriminant factor can be defined as a posterior probability:

Di(X)=P(Ci/X)=P(Ci)P(X/Ci)/P(X) (2)

Since P(X) is independent of any class, it will not affect the discriminating power of Di(X), so it can be safely ignored/discarded. Then, it is reasonable to approximate P(X/Ci) to a normal distribution:

P(X/Ci) = 1/|Σi|1/2 exp(−(X−Ci)TΣi−1(X−Ci)) (3)

Finally we further assume that the covariance matrix Σi (i=1,2,…,N) in (3) is almost identity for all classes and that P(Ci) is almost equally likely for i=1, 2, …,N. Applying logarithmic operator to formula (2), we obtain the following:

Ignoring the negative sign in (4), we obtain (5) which is also called the “minimum distance discriminant (MDD).”

Di(X) = (X−Ci)T(X − Ci) (5)

Applying Di(X) as defined in (5) to the problem of detecting presence of exudates in retinal images, we now define only two classes—yellowish patches (lesions) and reddish/dark reddish background. The feature centers of lesions and background, Clesion(fL, fθ, fϕ) and Cbkgrnd(fL, fθ, fϕ), can be obtained and trained by selecting small windows inside exudates patches and background regions respectively in a set of typical sample images. The means of exudates and background are then computed and stored as feature centers for the two classes respectively.

For each pixel X(xL, xθ, xϕ) from the retinal image, the discriminant Dlesion(X) and Dbkgrnd(X) are calculated. If Dlesion(X) is less than Dbkgrnd(X), then pixel X is classified as lesion otherwise it is being classified as background. In this way, exudates or other yellowish lesions can be quickly detected. Our simple and fast algorithm is able to achieve good accuracy in the detection of exudates in color fundus images. Figure 2 shows an example of output from the algorithm.

From Figure 2, we see that though our classifier detects the lesion regions correctly, it mis-classifies the optic disc region (a spherical region that appears brighter than the rest of the choroids) due to its similar color to exudates/lesions. With regard to this, we have developed a brightness adjustment procedure. In this procedure, only the darker regions have their brightness enhanced. Those regularly illuminated regions remain unchanged by this adjustment procedure. This is achieved using a brightness transform function as shown below:

# 4. Verification of Presence of Lesions

While the brightness adjustment function enhances the brightness of lesion patches that are scattered in the darker color retinal images or some darker regions of images, it also enhances the brightness of some background pixels so that these pixels would now be wrongly identified as class “lesion”. To keep this error rate to a minimum, we need to verify the MDD classification output so that only the true lesion information is retained while the false lesion points (pixels) are rejected. One observation about the false lesion points is that these points typically belong to a larger area where the color (or brightness) distribution gradually changes from brighter to darker without distinct edge boundary. However, for exudates, there is always a distinct edge or boundary caused by obvious color changes between the lesion pixels and its immediate surroundings. By analyzing the color changes within a small local neighborhood, we are able to verify whether the white pixel (lesion pixel) in MDD classification map is indeed a true or false lesion pixel.

Applying this brightness adjustment procedure to the color retinal images, we are able to detect even those dim lesions that are distributed in the darker regions using our Bayes MDD classifier (see Figure 4).

Consider a small sub-image that is either completely inside or completely outside the yellowish lesion patch. Generally, within such a local sub-image, color is uniform without sudden changes. But in a sub-image that contains both lesion patch and background, there is always a significant contrast between the high intensity lesion pixels and the low intensity background pixels. Based on this observation, we perform a second pass through the image using a MxM local window to distinguish whether there are true lesion points within this local window.

First, we apply an initial smoothing step (taking a NxN local average, e.g. N = 3, 5 or 7) to reduce and suppress the interference of scattered noise points in the original image. Next, the whole original retinal image is scanned, pixels by pixels. For each pixel x that was already classified as class “lesion” by our MDD classifier, we define Wᵐ(x) to be the MxM local window centered at x. Within each local window Wᵐ(x), let gₘₐₓ₁ and g min1 denote the highest and the lowest color values in Wᵐ(x), Dmaxmin be difference between gmax1 and gmin1, kₘₐₓ and kmin are the weights of gₘₐₓ₁ and gmin1 respectively. g max2 and gmin2 be the weighted maximum and minimum in Wᵐ(x):

gmax2 = gmax1 − Dmaxmin * kmax

gmin2 = gmin1 + Dmaxmin * kmin

Then the average maximum and average minimum in Wᵐ(x) are expressed as:

Figure 4. (Top) Original image containing small dim lesions. (Bottom Left) MDD classification map without prior brightness adjustment. Dim lesions are missed. (Bottom Right) Classification map of brightness adjusted retinal image. Dim lesions can be detected.

g min = g min2 ∗ ∑ g

∑ x g g = g min1

g = g min1

g max = g max1 * ∑ g

∑ x g g = g max2

g = g max2

We can define a local measure D as follows:

D = gmax − gmin (1)

If D is greater than a given threshold DT, it means there is a high likelihood of having two contrasting objects within this local window. Hence, for each Wm(x) whose D'&gt;DT, if pixel x falls on the brightness range [gmax2, gmax1] in the original smoothed color retinal image, it will remain classified as “lesion”, otherwise x will be re‑classified as “background”;

If D is less than DT in Wm(x), this may mean one of the following two situations:

- Wm(x) may fall on the inside region of background, in which case, pixel x should belong to background but has been wrongly classified as a lesion point by the MDD classifier. So, based on our criterion of D, x will be re‑classified as "background";
- Wm(x) may fall completely within a lesion patch, in which case, some true lesion point x in such windows may be reconfirmed as a “background” point. However this will not affect our results since our focus is to detect the presence of exudates, and not the exact sizes and shapes of the exudates.

Figure 5 shows the result of applying this verification technique.

# 5. Performance Study

We perform two sets of experiments to test the effectiveness of our proposed approach. In all the experiments, we set the parameters as follows: In the brightness adjustment procedure: we have inmax=195, 135, 95 and α=0.2, 0.2, 0.25 for R, G, B planes respectively. For the verification strategy, we set the local average size to be 5 × 5, the local sub‑window size to be 19 × 19, kmax=0.75, kmin=0.5, and the local threshold for lesion verification DT=15, 30, 15 for R, G, B planes respectively.

In our first experiment, the objective is to ensure that our approach will not wrongly classify an abnormal image as normal. All 54 known cases of abnormal images are used in this experiment. These images are of varying qualities. Each image is processed twice. The first time, it is processed using the MDD classifier alone (MDD). The second time, it is processed using the brightness adjustment, MDD classifier, and lesion verification method (Enhanced MDD). Table 1 shows the result using the two methods.

as Detected Detected as Accuracy darker background would not be missed and would not be regarded as background. Finally, a local window feature D is used to verify the classification result. With this, we are able to achieve 100% accuracy in terms of identifying all the retinal images with lesions while maintaining a 70% accuracy in correctly classifying the truly normal retinal images as normal. This translates to a huge amount of savings in terms of the number of retinal images that need to be manually reviewed by the medical professionals each year.

# 1. Experiment Results for First Experiment

| |Detected|Detected as|Accuracy|
|---|---|---|---|
|MDD|36|18|66%|
|Enhanced MDD|54|0|100%|

We see that the MDD method will miss out the abnormal lesions in 18 of the images. Clearly, this is unacceptable. However, with our Enhanced MDD method, we are able to correctly identify all the abnormal lesions in all the 54 images, thus achieving 100% accuracy.

# 2. Experiment Results for Second Experiment

| |Detected|Detected as|Accuracy|
|---|---|---|---|
|MDD|78|22| |
|Enhanced MDD|70|30|70%|

We see that there is a slight drop of accuracy in terms of identifying the truly normal images as normal for the Enhanced MDD method. This is because in order to ensure 100% accuracy in detecting the abnormal images, we have set very stringent conditions on any suspicious looking pixels. Thus, we will rather sound an alarm on suspicious looking pixels even though they may, in fact, just be some noise or non‑lesion points in the images. As a result, the accuracy drops a little. However, this is not a major problem as we can still achieve a savings of 70% in terms of the number of images that need to be manually reviewed by medical professionals.

# 3. Conclusions

On the basis of color information, the presence of lesions can be preliminarily detected by using MDD classifier based on statistical pattern recognition techniques. To deal with the problem of non‑uniform illumination in the retinal images, an effective pre‑processing step, the brightness adjustment procedure, is proposed to ensure dim lesion patches that are scattered in.

# References

1. Lim K. H., “Registration of New Blindness in Singapore for 1985-1995”, Singapore Medical Journal, Vol.40, No.2, Feb. 1999.
2. Leistritz, Dietrich Schweitzer, “Automated Detection and Quantification of Exudates in Retinal Images”, SPIE, Vol.2298, 1994.
3. Ward, Nicholas P., Tomlinson, Stephen, et al., “Analysis of Fundus Photographs”, Ophthalmology, Vol.96, No.1, Jan. 1989.
4. Philips, R. P., Spencer, T., et al., “Diabetic Maculopathy by Digital Imaging of the Fundus Eye, Vol.5, 130-137, 1991.
5. Ressell Philips, John Forrester, et al., “Automated Detection and Quantification of Retinal Exudates”, Graefe’s Archive for Clinical & Experimental Ophthamology, Vol.231, 90-94, 1993.
6. Young, Tzay Y., Calvert, Thomas W., “Classification, Estimation, and Pattern Recognition”, New York, American Elsevier Pub. Co., 1974.
7. Mirkin, Boris, “Mathematical Classification and Clustering”, Kluwer Academic Publishers, 1996.
8. Kasson, J. K., Pluffe, W., “An Analysis of Selected Computer Interchange Color Space”, ACM Trans. Graphics, Vol.11, 373-405, 1992.
9. Katz, Norman, Goldbaum, Michael, et al., “An Image Processing System for Automatic Retina Diagnosis”, SPIE, Vol.902, 1988.
10. Goldbaum, Michael, Katz, Norman, et al., “The Discrimination of Similar Colored Objects in Computer Images of the Ocular Fundus”, Investigative Opthalmology & Visual Science, Vol.31, No.4, Apr. 1990.
11. Goh KG, Hsu W, Lee ML, “Automatic Diabetic Retinal Image Screening Using Image Processing and Machine Learning Algorithms” Medical Imaging 2000, SPIE, Feb 2000, California, USA.

